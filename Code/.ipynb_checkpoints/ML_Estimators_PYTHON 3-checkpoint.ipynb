{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26eb87a",
   "metadata": {},
   "source": [
    "## Core Functions\n",
    "These handle importing necessary libraries, preparation of the feature arrays for Machine Learning, and execution of Machine Learning training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f008279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.26/04\n",
      "\n",
      "Ready! 2022/12/31 10:15:52\n"
     ]
    }
   ],
   "source": [
    "from ML_Python.ML_Python_Build_FeatureArrays_FromROOT import Build_FeatureArrays_FromROOT\n",
    "from ML_Python.ML_Python_TrainTest import (\n",
    "    Build_FeatureArrays_FromCSV,\n",
    "    Write_MLResults_ToCSV,\n",
    "    Write_MLWeights_ToCSV,\n",
    "    Train_All_Estimators,\n",
    "    Train_LinearRegression,\n",
    "    Train_RandomForestRegression,\n",
    "    Train_MLPRegression,\n",
    "    Test_Estimator,\n",
    "    Test_All_Estimators)\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def Build_SelectFeatureArray(\n",
    "    X_features,\n",
    "    feature_index\n",
    "    ) :\n",
    "    \"\"\"\n",
    "    Builds training and testing data sets\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Selecting data from master array...\")\n",
    "    \n",
    "    X_features_select = []\n",
    "    for i in range(len(X_features)):\n",
    "        X_temp = []\n",
    "        for j in range(len(feature_index)):\n",
    "            X_temp.append(X_features[i][feature_index[j]])\n",
    "        X_features_select.append(X_temp)\n",
    "        \n",
    "    print(\"Data ready. Feature array length:\", len(X_features_select), \"\\n\")\n",
    "    \n",
    "    return X_features_select\n",
    "\n",
    "    \n",
    "\n",
    "def TestAndSave_LinearRegression(\n",
    "    feature_label,    # Array of labels corresponding to each feature\n",
    "    feature_index,    # Array of indices for each feature used in X_train\n",
    "    lr_pipeline,      # Trained Linear Regression Pipeline\n",
    "    lr_coeffs,        # Array of coefficient values from trained linear regression pipeline\n",
    "    X_test_select,    # Array of testing data features\n",
    "    y_test,           # Array of testing data targets\n",
    "    sc_test,          # Array of testing data simple corrections\n",
    "    pt_test_min,      # Float of min pT to test with\n",
    "    pt_test_max,      # Float of max pT to test with\n",
    "    output_filename,  # Directory path + name for output csv file\n",
    "    use_scaler = True # If true, rescales data\n",
    "    ) :\n",
    "    \n",
    "    X_test_temp  = []\n",
    "    y_test_temp  = []\n",
    "    sc_test_temp = []\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] > pt_test_min and y_test[i] < pt_test_max:\n",
    "            X_test_temp.append(X_test_select[i])\n",
    "            y_test_temp.append(y_test[i])\n",
    "            sc_test_temp.append(sc_test[i])\n",
    "        else: continue\n",
    "    \n",
    "    # Tests estimator\n",
    "    \n",
    "    print(type(lr_pipeline))\n",
    "    \n",
    "    lr_results, lr_results_delta = Test_Estimator(\n",
    "        lr_pipeline,\n",
    "        X_test_temp, \n",
    "        y_test_temp\n",
    "        )\n",
    "    \n",
    "    # Writes outputs to a csv file\n",
    "    Write_MLResults_ToCSV(\n",
    "        output_filename,\n",
    "        y_test_temp,\n",
    "        sc_test_temp,\n",
    "        lr_results,\n",
    "        X_test_temp,\n",
    "        feature_label\n",
    "        )\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def TrainTestPlot_All_Estimators(\n",
    "    feature_label,    # Array of labels corresponding to each feature\n",
    "    feature_index,    # Array of indices for each feature used in X_train\n",
    "    X_train,          # Array of training data features\n",
    "    y_train,          # Array of training data targets\n",
    "    sc_train,         # Array of training data simple correction values\n",
    "    X_test,           # Array of testing data features\n",
    "    y_test,           # Array of testing data targets\n",
    "    sc_test,          # Array of testing data simple corrections\n",
    "    output_file_path, # File path for outputs\n",
    "    use_scaler = True,\n",
    "    use_lr = True,\n",
    "    use_rf = True,\n",
    "    use_mlp = True,\n",
    "    ) :\n",
    "    \n",
    "    # Builds training data set\n",
    "    print(\"Selecting training data...\")\n",
    "    X_train_select = []\n",
    "    for i in range(len(X_train)):\n",
    "        X_temp = []\n",
    "        for j in range(len(feature_index)):\n",
    "            X_temp.append(X_train[i][feature_index[j]])\n",
    "        X_train_select.append(X_temp)\n",
    "    print(\"Training data ready. X/Y length:\", len(X_train_select), len(y_train), \"/n\")\n",
    "    \n",
    "    # Builds pipelines from selected training features\n",
    "    print(\"Building estimator pipelines...\")\n",
    "    lr_pipeline, rf_pipeline, mlp_pipeline, lr_coeffs, rf_features = Train_All_Estimators(\n",
    "        X_train_select, y_train, feature_label, \n",
    "        use_StandardScaler = use_scaler,\n",
    "        use_LinearRegression = use_lr,\n",
    "        use_RandomForest = use_rf,\n",
    "        use_MLP = use_mlp)\n",
    "    print(\"Pipelines built./n\")\n",
    "    \n",
    "    print(\"Selecting testing data...\")\n",
    "    X_test_select = []\n",
    "    for i in range(len(X_test)):\n",
    "        X_temp = []\n",
    "        for j in range(len(feature_index)):\n",
    "            X_temp.append(X_test[i][feature_index[j]])\n",
    "        X_test_select.append(X_temp)\n",
    "    print(\"Testing data ready. X/Y length:\", len(X_test_select), len(y_test), \"/n\")\n",
    "    \n",
    "    # Test estimators\n",
    "    print(\"Testing all estimators...\")\n",
    "    lr_results, lr_results_delta, rf_results, rf_results_delta, mlp_results, mlp_results_delta = Test_All_Estimators(\n",
    "        X_test_select, \n",
    "        y_test, \n",
    "        lr_pipeline,\n",
    "        rf_pipeline,\n",
    "        mlp_pipeline)\n",
    "    print(\"Estimator testing complete!/n\")\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nReady!\", dt_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3495115a",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Sets up input directories/files for training and testing. Creates initial training data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61026866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exists\n",
      "Input file accessed successfully. Output file generated.\n",
      "Accessing input tree...\n",
      "Input tree accessed successfully.\n",
      "Creating .csv backup file...\n",
      "Backup file started.\n",
      "Preparing to collect data from TTree...\n",
      "Jet: 10000 | pTraw: 62.258 | pTcorr:  8.813 | pTtrue:  11.416\n",
      "Jet: 20000 | pTraw: 64.764 | pTcorr:  10.686 | pTtrue:  14.582\n",
      "Jet: 30000 | pTraw: 74.677 | pTcorr:  15.376 | pTtrue:  10.248\n",
      "Jet: 40000 | pTraw: 77.999 | pTcorr:  14.600 | pTtrue:  10.555\n",
      "Jet: 50000 | pTraw: 67.386 | pTcorr:  12.472 | pTtrue:  13.537\n",
      "Jet: 60000 | pTraw: 57.465 | pTcorr:  4.565 | pTtrue:  19.211\n",
      "Jet: 70000 | pTraw: 82.745 | pTcorr:  24.559 | pTtrue:  12.792\n",
      "Jet: 80000 | pTraw: 54.911 | pTcorr:  10.610 | pTtrue:  10.957\n",
      "Jet: 90000 | pTraw: 86.909 | pTcorr:  19.999 | pTtrue:  19.625\n",
      "Jet: 100000 | pTraw: 54.377 | pTcorr: -1.509 | pTtrue:  11.781\n",
      "Jet: 110000 | pTraw: 35.099 | pTcorr: -2.911 | pTtrue:  10.075\n",
      "Jet: 120000 | pTraw: 57.615 | pTcorr:  2.611 | pTtrue:  10.821\n",
      "Jet: 130000 | pTraw: 56.397 | pTcorr: -0.533 | pTtrue:  10.865\n",
      "Jet: 140000 | pTraw: 37.332 | pTcorr:  5.419 | pTtrue:  16.518\n",
      "Jet: 150000 | pTraw: 74.359 | pTcorr:  15.640 | pTtrue:  17.545\n",
      "Jet: 160000 | pTraw: 76.029 | pTcorr:  22.663 | pTtrue:  13.445\n",
      "Jet: 170000 | pTraw: 61.289 | pTcorr:  9.451 | pTtrue:  10.803\n",
      "Jet: 180000 | pTraw: 51.460 | pTcorr: -1.657 | pTtrue:  10.932\n",
      "Jet: 190000 | pTraw: 92.442 | pTcorr:  32.604 | pTtrue:  10.806\n",
      "Jet: 200000 | pTraw: 69.933 | pTcorr:  25.999 | pTtrue:  17.124\n",
      "Jet: 210000 | pTraw: 84.763 | pTcorr:  21.722 | pTtrue:  12.796\n",
      "Jet: 220000 | pTraw: 51.297 | pTcorr: -0.400 | pTtrue:  11.744\n",
      "Jet: 230000 | pTraw: 5.918 | pTcorr:  0.320 | pTtrue:  11.434\n",
      "Jet: 240000 | pTraw: 76.671 | pTcorr:  20.906 | pTtrue:  16.318\n",
      "Jet: 250000 | pTraw: 51.516 | pTcorr:  3.732 | pTtrue:  12.942\n",
      "Jet: 260000 | pTraw: 78.463 | pTcorr:  26.546 | pTtrue:  33.505\n",
      "Jet: 270000 | pTraw: 14.659 | pTcorr:  2.570 | pTtrue:  12.984\n",
      "Jet: 280000 | pTraw: 65.291 | pTcorr:  18.240 | pTtrue:  21.733\n",
      "Jet: 290000 | pTraw: 75.288 | pTcorr:  9.325 | pTtrue:  13.979\n",
      "Jet: 300000 | pTraw: 45.057 | pTcorr:  19.755 | pTtrue:  13.415\n",
      "Jet: 310000 | pTraw: 78.311 | pTcorr:  24.315 | pTtrue:  12.287\n",
      "Jet: 320000 | pTraw: 76.886 | pTcorr:  11.021 | pTtrue:  12.034\n",
      "Jet: 330000 | pTraw: 62.284 | pTcorr:  7.451 | pTtrue:  10.853\n",
      "Jet: 340000 | pTraw: 84.417 | pTcorr:  21.945 | pTtrue:  20.529\n",
      "Jet: 350000 | pTraw: 59.668 | pTcorr:  6.586 | pTtrue:  17.371\n",
      "Jet: 360000 | pTraw: 76.428 | pTcorr:  20.467 | pTtrue:  10.145\n",
      "Jet: 370000 | pTraw: 53.504 | pTcorr:  7.829 | pTtrue:  14.263\n",
      "Jet: 380000 | pTraw: 59.802 | pTcorr:  7.181 | pTtrue:  10.461\n",
      "Jet: 390000 | pTraw: 61.422 | pTcorr:  5.208 | pTtrue:  10.972\n",
      "Jet: 400000 | pTraw: 102.564 | pTcorr:  36.521 | pTtrue:  21.917\n",
      "Jet: 410000 | pTraw: 69.600 | pTcorr:  23.373 | pTtrue:  11.068\n",
      "Jet: 420000 | pTraw: 65.440 | pTcorr:  2.757 | pTtrue:  14.076\n",
      "Jet: 430000 | pTraw: 73.753 | pTcorr:  9.935 | pTtrue:  14.486\n",
      "Jet: 440000 | pTraw: 99.446 | pTcorr:  33.196 | pTtrue:  16.959\n",
      "Jet: 450000 | pTraw: 89.372 | pTcorr:  24.914 | pTtrue:  13.134\n",
      "Jet: 460000 | pTraw: 62.848 | pTcorr:  3.323 | pTtrue:  11.183\n",
      "Jet: 470000 | pTraw: 82.797 | pTcorr:  23.378 | pTtrue:  17.851\n",
      "Jet: 480000 | pTraw: 62.945 | pTcorr:  7.170 | pTtrue:  14.520\n",
      "Jet: 490000 | pTraw: 79.913 | pTcorr:  17.999 | pTtrue:  23.549\n",
      "Jet: 500000 | pTraw: 85.177 | pTcorr:  20.312 | pTtrue:  15.287\n",
      "Jet: 510000 | pTraw: 69.607 | pTcorr:  7.344 | pTtrue:  13.854\n",
      "Jet: 520000 | pTraw: 39.476 | pTcorr:  2.089 | pTtrue:  10.756\n",
      "Jet: 530000 | pTraw: 77.392 | pTcorr:  18.275 | pTtrue:  10.297\n",
      "Jet: 540000 | pTraw: 76.801 | pTcorr:  23.020 | pTtrue:  19.999\n",
      "Backup .csv file closed.\n",
      "All data transferred to array. Testing with 542699 jets.\n",
      "\n",
      "Data set lengths: 542699 / 542699 / 542699\n",
      "Input file closed.\n",
      "Input file accessed successfully. Output file generated.\n",
      "Accessing input tree...\n",
      "Input tree accessed successfully.\n",
      "Creating .csv backup file...\n",
      "Backup file started.\n",
      "Preparing to collect data from TTree...\n",
      "Jet: 10000 | pTraw: 69.039 | pTcorr:  18.488 | pTtrue:  32.134\n",
      "Jet: 20000 | pTraw: 127.286 | pTcorr:  63.938 | pTtrue:  62.960\n",
      "Jet: 30000 | pTraw: 88.468 | pTcorr:  49.245 | pTtrue:  41.243\n",
      "Jet: 40000 | pTraw: 108.331 | pTcorr:  48.412 | pTtrue:  67.764\n",
      "Jet: 50000 | pTraw: 56.171 | pTcorr:  20.612 | pTtrue:  24.684\n",
      "Jet: 60000 | pTraw: 116.375 | pTcorr:  67.730 | pTtrue:  65.163\n",
      "Jet: 70000 | pTraw: 77.024 | pTcorr:  18.067 | pTtrue:  16.547\n",
      "Jet: 80000 | pTraw: 82.198 | pTcorr:  20.911 | pTtrue:  20.457\n",
      "Jet: 90000 | pTraw: 6.586 | pTcorr:  1.012 | pTtrue:  30.058\n",
      "Jet: 100000 | pTraw: 5.084 | pTcorr:  1.787 | pTtrue:  41.968\n",
      "Jet: 110000 | pTraw: 147.600 | pTcorr:  84.335 | pTtrue:  83.597\n",
      "Jet: 120000 | pTraw: 101.184 | pTcorr:  45.700 | pTtrue:  36.231\n",
      "Jet: 130000 | pTraw: 42.130 | pTcorr: -2.780 | pTtrue:  11.632\n",
      "Jet: 140000 | pTraw: 69.807 | pTcorr:  20.396 | pTtrue:  10.456\n",
      "Jet: 150000 | pTraw: 72.611 | pTcorr:  28.516 | pTtrue:  33.147\n",
      "Jet: 160000 | pTraw: 114.413 | pTcorr:  55.683 | pTtrue:  58.552\n",
      "Jet: 170000 | pTraw: 6.067 | pTcorr:  3.729 | pTtrue:  64.201\n",
      "Jet: 180000 | pTraw: 5.268 | pTcorr: -0.666 | pTtrue:  11.268\n",
      "Jet: 190000 | pTraw: 113.384 | pTcorr:  68.602 | pTtrue:  50.329\n",
      "Jet: 200000 | pTraw: 43.105 | pTcorr: -5.418 | pTtrue:  11.074\n",
      "Jet: 210000 | pTraw: 86.852 | pTcorr:  46.326 | pTtrue:  45.210\n",
      "Jet: 220000 | pTraw: 84.977 | pTcorr:  25.088 | pTtrue:  23.813\n",
      "Jet: 230000 | pTraw: 76.167 | pTcorr:  17.895 | pTtrue:  29.428\n",
      "Jet: 240000 | pTraw: 91.251 | pTcorr:  32.077 | pTtrue:  40.520\n",
      "Jet: 250000 | pTraw: 41.423 | pTcorr:  4.856 | pTtrue:  10.461\n",
      "Jet: 260000 | pTraw: 115.987 | pTcorr:  59.987 | pTtrue:  71.616\n",
      "Jet: 270000 | pTraw: 68.511 | pTcorr:  19.510 | pTtrue:  18.286\n",
      "Jet: 280000 | pTraw: 6.626 | pTcorr: -2.536 | pTtrue:  18.856\n",
      "Jet: 290000 | pTraw: 68.990 | pTcorr:  14.917 | pTtrue:  38.751\n",
      "Jet: 300000 | pTraw: 108.671 | pTcorr:  49.896 | pTtrue:  61.761\n",
      "Jet: 310000 | pTraw: 74.655 | pTcorr:  28.436 | pTtrue:  24.154\n",
      "Jet: 320000 | pTraw: 69.683 | pTcorr:  25.138 | pTtrue:  36.670\n",
      "Jet: 330000 | pTraw: 93.152 | pTcorr:  35.499 | pTtrue:  19.547\n",
      "Jet: 340000 | pTraw: 7.790 | pTcorr:  0.700 | pTtrue:  12.054\n",
      "Jet: 350000 | pTraw: 8.535 | pTcorr:  7.307 | pTtrue:  14.253\n",
      "Jet: 360000 | pTraw: 61.232 | pTcorr:  13.894 | pTtrue:  21.734\n",
      "Jet: 370000 | pTraw: 82.290 | pTcorr:  41.242 | pTtrue:  36.992\n",
      "Jet: 380000 | pTraw: 44.184 | pTcorr:  18.945 | pTtrue:  17.229\n",
      "Jet: 390000 | pTraw: 95.230 | pTcorr:  26.661 | pTtrue:  27.909\n",
      "Jet: 400000 | pTraw: 26.673 | pTcorr:  5.367 | pTtrue:  26.602\n",
      "Jet: 410000 | pTraw: 92.897 | pTcorr:  43.129 | pTtrue:  45.306\n",
      "Jet: 420000 | pTraw: 95.345 | pTcorr:  38.516 | pTtrue:  33.139\n",
      "Jet: 430000 | pTraw: 61.067 | pTcorr:  17.383 | pTtrue:  14.365\n",
      "Jet: 440000 | pTraw: 83.100 | pTcorr:  27.756 | pTtrue:  41.430\n",
      "Jet: 450000 | pTraw: 105.815 | pTcorr:  53.023 | pTtrue:  74.527\n",
      "Jet: 460000 | pTraw: 64.682 | pTcorr:  18.262 | pTtrue:  12.452\n",
      "Jet: 470000 | pTraw: 66.550 | pTcorr:  21.230 | pTtrue:  11.457\n",
      "Jet: 480000 | pTraw: 127.972 | pTcorr:  78.960 | pTtrue:  80.049\n",
      "Jet: 490000 | pTraw: 145.235 | pTcorr:  92.814 | pTtrue:  81.108\n",
      "Jet: 500000 | pTraw: 88.608 | pTcorr:  30.484 | pTtrue:  31.445\n",
      "Jet: 510000 | pTraw: 136.925 | pTcorr:  67.604 | pTtrue:  78.909\n",
      "Jet: 520000 | pTraw: 48.063 | pTcorr:  7.543 | pTtrue:  14.113\n",
      "Jet: 530000 | pTraw: 81.147 | pTcorr:  35.922 | pTtrue:  27.254\n",
      "Jet: 540000 | pTraw: 58.696 | pTcorr:  13.545 | pTtrue:  16.049\n",
      "Jet: 550000 | pTraw: 79.383 | pTcorr:  52.233 | pTtrue:  44.204\n",
      "Jet: 560000 | pTraw: 58.840 | pTcorr:  12.771 | pTtrue:  12.128\n",
      "Jet: 570000 | pTraw: 90.020 | pTcorr:  35.001 | pTtrue:  38.028\n",
      "Jet: 580000 | pTraw: 75.468 | pTcorr:  27.000 | pTtrue:  23.093\n",
      "Jet: 590000 | pTraw: 77.934 | pTcorr:  39.766 | pTtrue:  32.228\n",
      "Jet: 600000 | pTraw: 81.486 | pTcorr:  26.093 | pTtrue:  13.921\n",
      "Jet: 610000 | pTraw: 58.356 | pTcorr:  12.509 | pTtrue:  18.070\n",
      "Jet: 620000 | pTraw: 111.868 | pTcorr:  51.304 | pTtrue:  66.223\n",
      "Jet: 630000 | pTraw: 100.727 | pTcorr:  40.321 | pTtrue:  41.123\n",
      "Jet: 640000 | pTraw: 139.898 | pTcorr:  80.163 | pTtrue:  75.664\n",
      "Jet: 650000 | pTraw: 51.710 | pTcorr:  10.932 | pTtrue:  19.471\n",
      "Jet: 660000 | pTraw: 73.985 | pTcorr:  22.260 | pTtrue:  19.774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jet: 670000 | pTraw: 137.986 | pTcorr:  84.921 | pTtrue:  74.864\n",
      "Jet: 680000 | pTraw: 60.335 | pTcorr:  23.807 | pTtrue:  19.029\n",
      "Jet: 690000 | pTraw: 5.798 | pTcorr: -0.322 | pTtrue:  14.576\n",
      "Jet: 700000 | pTraw: 96.868 | pTcorr:  57.531 | pTtrue:  67.429\n",
      "Jet: 710000 | pTraw: 65.482 | pTcorr:  23.698 | pTtrue:  33.125\n",
      "Jet: 720000 | pTraw: 89.073 | pTcorr:  27.160 | pTtrue:  28.951\n",
      "Jet: 730000 | pTraw: 75.409 | pTcorr:  3.495 | pTtrue:  21.793\n",
      "Jet: 740000 | pTraw: 5.075 | pTcorr: -4.520 | pTtrue:  11.066\n",
      "Jet: 750000 | pTraw: 77.485 | pTcorr:  31.165 | pTtrue:  19.686\n",
      "Jet: 760000 | pTraw: 74.166 | pTcorr:  22.251 | pTtrue:  30.539\n",
      "Jet: 770000 | pTraw: 113.546 | pTcorr:  72.085 | pTtrue:  78.752\n",
      "Jet: 780000 | pTraw: 85.929 | pTcorr:  36.962 | pTtrue:  22.683\n",
      "Jet: 790000 | pTraw: 128.616 | pTcorr:  74.256 | pTtrue:  83.493\n",
      "Jet: 800000 | pTraw: 101.842 | pTcorr:  51.454 | pTtrue:  37.574\n",
      "Jet: 810000 | pTraw: 63.034 | pTcorr:  4.317 | pTtrue:  20.618\n",
      "Jet: 820000 | pTraw: 6.279 | pTcorr: -1.590 | pTtrue:  20.514\n",
      "Jet: 830000 | pTraw: 155.298 | pTcorr:  90.479 | pTtrue:  86.724\n",
      "Jet: 840000 | pTraw: 103.090 | pTcorr:  35.785 | pTtrue:  41.665\n",
      "Jet: 850000 | pTraw: 6.695 | pTcorr:  0.127 | pTtrue:  13.205\n",
      "Jet: 860000 | pTraw: 104.200 | pTcorr:  50.452 | pTtrue:  55.375\n",
      "Jet: 870000 | pTraw: 59.585 | pTcorr:  16.746 | pTtrue:  16.462\n",
      "Jet: 880000 | pTraw: 36.253 | pTcorr:  8.073 | pTtrue:  11.153\n",
      "Jet: 890000 | pTraw: 73.882 | pTcorr:  15.869 | pTtrue:  19.547\n",
      "Jet: 900000 | pTraw: 62.375 | pTcorr:  5.113 | pTtrue:  13.942\n",
      "Jet: 910000 | pTraw: 88.922 | pTcorr:  35.412 | pTtrue:  46.598\n",
      "Jet: 920000 | pTraw: 103.236 | pTcorr:  51.600 | pTtrue:  60.620\n",
      "Jet: 930000 | pTraw: 86.816 | pTcorr:  20.133 | pTtrue:  20.741\n",
      "Jet: 940000 | pTraw: 135.434 | pTcorr:  69.355 | pTtrue:  60.442\n",
      "Jet: 950000 | pTraw: 126.891 | pTcorr:  78.207 | pTtrue:  69.983\n",
      "Jet: 960000 | pTraw: 90.520 | pTcorr:  29.180 | pTtrue:  43.058\n",
      "Backup .csv file closed.\n",
      "All data transferred to array. Testing with 961713 jets.\n",
      "\n",
      "Data set lengths: 961713 / 961713 / 961713\n",
      "Input file closed.\n",
      "\n",
      "Ready! 2022/12/31 10:17:39\n"
     ]
    }
   ],
   "source": [
    "file_directory   = \"../Files/Comparison_Trial2/Data/\"\n",
    "\n",
    "train_file_name  = \"ML_Prep_Train_B0_10_90_N500000.root\"\n",
    "train_tree_name  = \"Jet_ML_Train_B0_10_90_N500000\"\n",
    "train_file_path  = file_directory + train_file_name\n",
    "train_csv_path   = file_directory + train_file_name[0:-5] + \"_Backup.csv\"\n",
    "train_range      = (10., 90.)\n",
    "\n",
    "test_file_name   = \"ML_Prep_Test_B8_10_90_N500000.root\"\n",
    "test_tree_name   = \"Jet_ML_Test_B8_10_90_N500000\"\n",
    "test_file_path   = file_directory + test_file_name\n",
    "test_csv_path    = file_directory + test_file_name[0:-5] + \"_Backup.csv\"\n",
    "test_range       = (10., 90.)\n",
    "\n",
    "output_csv_name  = file_directory + \"ML_Results/20GeV_Bins/Train_B0\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(file_directory + \"ML_Results/20GeV_Bins\")\n",
    "except:\n",
    "    print(\"directory already exists\")\n",
    "\n",
    "# Builds feature and target arrays from ROOT file\n",
    "X_train, y_train, sc_train = Build_FeatureArrays_FromROOT(\n",
    "    train_file_path, train_tree_name, train_csv_path, train_range[0], train_range[1])\n",
    "X_test, y_test, sc_test = Build_FeatureArrays_FromROOT(\n",
    "    test_file_path,  test_tree_name,  test_csv_path,  test_range[0],  test_range[1])\n",
    "\n",
    "# # Rebuilds feature and target arrays from csv file (MUCH faster if csv has been made already)\n",
    "# X_train, y_train, sc_train = Build_FeatureArrays_FromCSV(train_csv_path)\n",
    "# X_test,  y_test,  sc_test  = Build_FeatureArrays_FromCSV(test_csv_path)\n",
    "\n",
    "\n",
    "\n",
    "# Set Features to train with\n",
    "# X_values[\n",
    "#    0  jet_pt_raw,      1  jet_pt_corr,     2  jet_mass,        3  jet_area, \n",
    "#    4  jet_area_err,    5  jet_const_n,     6  const_pt_mean,   7  const_pt_median, \n",
    "#    8  const_1_pt,      9  const_2_pt,      10 const_3_pt,      11 const_4_pt,\n",
    "#    12 const_5_pt,      13 const_6_pt,      14 const_7_pt,      15 const_8_pt,\n",
    "#    16 const_9_pt,      17 const_10_pt,     18 jet_y,           19 jet_phi,\n",
    "#    20 jet_rho]\n",
    "\n",
    "# Training with 1 feature\n",
    "feature_label_1feat = [\n",
    "    \"jet_pt_raw\"]\n",
    "feature_index_1feat = [0]\n",
    "\n",
    "# Training with 3 features\n",
    "feature_label_3feat = [\n",
    "    \"jet_pt_raw\", \"jet_area\", \"jet_rho\"]\n",
    "feature_index_3feat = [0, 3, 20]\n",
    "\n",
    "# Training with 12 features\n",
    "feature_label_12feat = [\n",
    "    \"jet_pt_raw\",    \"jet_pt_corr\",    \"jet_mass\",      \"jet_area\", \n",
    "    \"jet_const_n\",   \"const_pt_mean\",  \"const_1_pt\",    \"const_2_pt\",\n",
    "    \"const_3_pt\",    \"const_4_pt\",     \"jet_y\",         \"jet_rho\"]\n",
    "feature_index_12feat = [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 18, 20]\n",
    "\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nReady!\", dt_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4130c",
   "metadata": {},
   "source": [
    "## Training & Testing\n",
    "1 Feature: pt_raw ONLY\n",
    "\n",
    "3 Features: pt_raw, jet_area, jet_rho\n",
    "\n",
    "12 Features: jet_pt_raw, jet_pt_corr, jet_mass, jet_area, jet_const_n, const_pt_mean, const_1_pt, const_2_pt, const_3_pt, const_4_pt, jet_y, jet_rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe20d7c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 542699 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 961713 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 1.32688560728391\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 1 features on 18-22 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 1 features on 28-32 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 1 features on 38-42 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 1 features on 48-52 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 1 features on 58-62 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 1 features on 68-72 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 1 features on 78-82 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 542699 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 961713 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 4.5743242574997165\n",
      "jet_area -3.5552317745548168\n",
      "jet_rho -1.0615083365068747\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 3 features on 18-22 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 3 features on 28-32 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 3 features on 38-42 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 3 features on 48-52 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 3 features on 58-62 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 3 features on 68-72 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 3 features on 78-82 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 542699 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 961713 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 4.682613308322785\n",
      "jet_pt_corr 0.34279268173154276\n",
      "jet_mass 4.720020240126473\n",
      "jet_area -1.7446660369818285\n",
      "jet_const_n -7.171576965180127\n",
      "const_pt_mean 0.04784882199742949\n",
      "const_1_pt 0.6519903437202861\n",
      "const_2_pt 0.2710913208210744\n",
      "const_3_pt 0.3351270280259916\n",
      "const_4_pt -0.5999641030446586\n",
      "jet_y 0.012443861525556649\n",
      "jet_rho -0.19104253831204204\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 18-22 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 12 features on 28-32 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 12 features on 38-42 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 12 features on 48-52 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 12 features on 58-62 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 12 features on 68-72 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 12 features on 78-82 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Complete! 2022/12/31 10:18:42\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "#                                               #\n",
    "#  TRAIN ML ON ONE BIN, WITH 1, 3, 12 FEATURES  #\n",
    "#                                               #\n",
    "#################################################\n",
    "\n",
    "\n",
    "test_min_max_array = [  # Array of min and max for pT ranges to test on\n",
    "    [18,22], [28,32], [38,42], [48,52], \n",
    "    [58,62], [68,72], [78,82]\n",
    "    ]\n",
    "feature_bundle = [\n",
    "    [feature_label_1feat,  feature_index_1feat], \n",
    "    [feature_label_3feat,  feature_index_3feat],\n",
    "    [feature_label_12feat, feature_index_12feat]\n",
    "    ]\n",
    "train_bundle = [ # This may be implemented later to iterate through multiple training sets\n",
    "    [X_train, y_train, sc_train]\n",
    "    ]\n",
    "\n",
    "for feature_set in feature_bundle:\n",
    "    feature_label = feature_set[0]\n",
    "    feature_index = feature_set[1]\n",
    "    \n",
    "    output_csv_name_2 = output_csv_name + \"_F\" + str(len(feature_label)) + \"_\" + str(int(train_range[0])) + \"_\" + str(int(train_range[1]))\n",
    "    \n",
    "    # Builds training and testing arrays\n",
    "    print(\"\\nBuilding training and testing selected feature arrays...\")\n",
    "    X_train_select = Build_SelectFeatureArray(X_train, feature_index)\n",
    "    X_test_select  = Build_SelectFeatureArray(X_test, feature_index)\n",
    "\n",
    "    # Trains estimator\n",
    "    print(\"\\nTraining linear regression estimator...\")\n",
    "    lr_pipeline, lr_coeffs = Train_LinearRegression(\n",
    "        X_train_select, \n",
    "        y_train, \n",
    "        feature_label, \n",
    "        use_scaler = True)\n",
    "    print(type(lr_pipeline))\n",
    "    \n",
    "    Write_MLWeights_ToCSV(\n",
    "        output_csv_name_2 + \"_LR_Coeffs.csv\",\n",
    "        lr_coeffs, \n",
    "        feature_label\n",
    "        )\n",
    "\n",
    "    # Tests estimator and saves results\n",
    "\n",
    "    for min_max in test_min_max_array:\n",
    "        \n",
    "        output = \"\\nTesting \" + str(len(feature_index)) + \" features on \" + str(min_max[0]) + \"-\" + str(min_max[1]) + \" GeV...\"\n",
    "        print(output)\n",
    "        \n",
    "        csv_path = output_csv_name_2 + \"_Test_\" + str(int(min_max[0])) + \"_\" + str(int(min_max[1])) + \".csv\"\n",
    "        \n",
    "        TestAndSave_LinearRegression(\n",
    "            feature_label,\n",
    "            feature_index, \n",
    "            lr_pipeline, \n",
    "            lr_coeffs,\n",
    "            X_test_select,\n",
    "            y_test, \n",
    "            sc_test,\n",
    "            min_max[0],\n",
    "            min_max[1],   \n",
    "            csv_path,\n",
    "            use_scaler = True\n",
    "            )\n",
    "        \n",
    "        print(\"Test and save complete!\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nComplete!\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cac4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#                                               #\n",
    "#  TRAIN ML OVER 20 GeV BINS, USES 12 FEATURES  #\n",
    "#                                               #\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "test_min_max_array = [  # Array of min and max for pT ranges to test on\n",
    "    [18,22], [28,32], [38,42], [48,52], \n",
    "    [58,62], [68,72], [78,82]\n",
    "    ]\n",
    "training_bundle = [\n",
    "    [10.,30.], [20.,40.], [30.,50.], [40.,60.],\n",
    "    [50.,70.], [60.,80.], [70.,90.]\n",
    "]\n",
    "\n",
    "# ONLY runs 12 features\n",
    "for training_range in training_bundle:\n",
    "    train_min = training_range[0]\n",
    "    train_max = training_range[1]\n",
    "    \n",
    "    output_csv_name_2 = output_csv_name + \"_F\" + str(len(feature_label_12feat)) + \"_\" + str(int(train_min)) + \"_\" + str(int(train_max))\n",
    "    \n",
    "    X_train_cut = []\n",
    "    y_train_cut = []\n",
    "    sc_train_cut = []\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        if (y_train[i] > train_min) and (y_train[i] < train_max):\n",
    "            X_train_cut.append(X_train[i])\n",
    "            y_train_cut.append(y_train[i])\n",
    "            sc_train_cut.append(sc_train[i])\n",
    "    \n",
    "    X_test_cut = []\n",
    "    y_test_cut = []\n",
    "    sc_test_cut = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        if (y_test[i] > train_min) and (y_test[i] < train_max):\n",
    "            X_test_cut.append(X_test[i])\n",
    "            y_test_cut.append(y_test[i])\n",
    "            sc_test_cut.append(sc_test[i])\n",
    "    \n",
    "    # Builds training and testing arrays\n",
    "    print(\"\\nBuilding training and testing selected feature arrays...\")\n",
    "    X_train_select = Build_SelectFeatureArray(X_train_cut, feature_index_12feat)\n",
    "    X_test_select  = Build_SelectFeatureArray(X_test_cut, feature_index_12feat)\n",
    "\n",
    "    # Trains estimator\n",
    "    print(\"\\nTraining linear regression estimator...\")\n",
    "    lr_pipeline, lr_coeffs = Train_LinearRegression(\n",
    "        X_train_select, \n",
    "        y_train_cut, \n",
    "        feature_label_12feat, \n",
    "        use_scaler = True)\n",
    "    print(type(lr_pipeline))\n",
    "    \n",
    "    Write_MLWeights_ToCSV(\n",
    "        output_csv_name_2 + \"_LR_Coeffs.csv\",\n",
    "        lr_coeffs, \n",
    "        feature_label_12feat\n",
    "        )\n",
    "\n",
    "    # Tests estimator and saves results\n",
    "    output = \"\\nTesting \" + str(len(feature_index_12feat)) + \" features on \" + str(train_min) + \"-\" + str(train_max) + \" GeV...\"\n",
    "    print(output)\n",
    "\n",
    "    csv_path = output_csv_name_2 + \"_Test_\" + str(int(train_min)) + \"_\" + str(int(train_max)) + \".csv\"\n",
    "\n",
    "    TestAndSave_LinearRegression(\n",
    "        feature_label_12feat,\n",
    "        feature_index_12feat, \n",
    "        lr_pipeline, \n",
    "        lr_coeffs,\n",
    "        X_test_select,\n",
    "        y_test_cut, \n",
    "        sc_test_cut,\n",
    "        train_min,\n",
    "        train_max,   \n",
    "        csv_path,\n",
    "        use_scaler = True\n",
    "        )\n",
    "\n",
    "    print(\"Test and save complete!\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nComplete!\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da5e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#                                               #\n",
    "#  TRAIN ML OVER 30 GeV BINS, USES 12 FEATURES  #\n",
    "#                                               #\n",
    "#################################################\n",
    "\n",
    "training_bundle = [\n",
    "    [10.,40.], [20.,50.], [30.,60.], [40.,70.],\n",
    "    [50.,80.], [60.,90.]\n",
    "]\n",
    "\n",
    "# ONLY runs 12 features\n",
    "for training_range in training_bundle:\n",
    "    train_min = training_range[0]\n",
    "    train_max = training_range[1]\n",
    "    \n",
    "    output_csv_name_2 = output_csv_name + \"_F\" + str(len(feature_label_12feat)) + \"_\" + str(int(train_min)) + \"_\" + str(int(train_max))\n",
    "    \n",
    "    X_train_cut = []\n",
    "    y_train_cut = []\n",
    "    sc_train_cut = []\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        if (y_train[i] > train_min) and (y_train[i] < train_max):\n",
    "            X_train_cut.append(X_train[i])\n",
    "            y_train_cut.append(y_train[i])\n",
    "            sc_train_cut.append(sc_train[i])\n",
    "    \n",
    "    X_test_cut = []\n",
    "    y_test_cut = []\n",
    "    sc_test_cut = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        if (y_test[i] > train_min) and (y_test[i] < train_max):\n",
    "            X_test_cut.append(X_test[i])\n",
    "            y_test_cut.append(y_test[i])\n",
    "            sc_test_cut.append(sc_test[i])\n",
    "    \n",
    "    # Builds training and testing arrays\n",
    "    print(\"\\nBuilding training and testing selected feature arrays...\")\n",
    "    X_train_select = Build_SelectFeatureArray(X_train_cut, feature_index_12feat)\n",
    "    X_test_select  = Build_SelectFeatureArray(X_test_cut, feature_index_12feat)\n",
    "\n",
    "    # Trains estimator\n",
    "    print(\"\\nTraining linear regression estimator...\")\n",
    "    lr_pipeline, lr_coeffs = Train_LinearRegression(\n",
    "        X_train_select, \n",
    "        y_train_cut, \n",
    "        feature_label_12feat, \n",
    "        use_scaler = True)\n",
    "    print(type(lr_pipeline))\n",
    "    \n",
    "    Write_MLWeights_ToCSV(\n",
    "        output_csv_name_2 + \"_LR_Coeffs.csv\",\n",
    "        lr_coeffs, \n",
    "        feature_label_12feat\n",
    "        )\n",
    "\n",
    "    # Tests estimator and saves results\n",
    "    output = \"\\nTesting \" + str(len(feature_index_12feat)) + \" features on \" + str(train_min) + \"-\" + str(train_max) + \" GeV...\"\n",
    "    print(output)\n",
    "\n",
    "    csv_path = output_csv_name_2 + \"_Test_\" + str(int(train_min)) + \"_\" + str(int(train_max)) + \".csv\"\n",
    "\n",
    "    TestAndSave_LinearRegression(\n",
    "        feature_label_12feat,\n",
    "        feature_index_12feat, \n",
    "        lr_pipeline, \n",
    "        lr_coeffs,\n",
    "        X_test_select,\n",
    "        y_test_cut, \n",
    "        sc_test_cut,\n",
    "        train_min,\n",
    "        train_max,   \n",
    "        csv_path,\n",
    "        use_scaler = True\n",
    "        )\n",
    "\n",
    "    print(\"Test and save complete!\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nComplete!\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e227f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
