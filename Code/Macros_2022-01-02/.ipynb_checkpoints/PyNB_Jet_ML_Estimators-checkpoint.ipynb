{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26eb87a",
   "metadata": {},
   "source": [
    "## Core Functions\n",
    "These handle importing necessary libraries, preparation of the feature arrays for Machine Learning, and execution of Machine Learning training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f008279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exists\n",
      "Input file accessed successfully. Output file generated.\n",
      "Accessing input tree...\n",
      "Input tree accessed successfully.\n",
      "Creating .csv backup file...\n",
      "Backup file started.\n",
      "Preparing to collect data from TTree...\n",
      "Jet: 10000 | pTraw: 94.586 | pTcorr:  27.827 | pTtrue:  20.277\n",
      "Jet: 20000 | pTraw: 129.452 | pTcorr:  79.065 | pTtrue:  67.456\n",
      "Jet: 30000 | pTraw: 133.441 | pTcorr:  84.407 | pTtrue:  81.975\n",
      "Jet: 40000 | pTraw: 114.348 | pTcorr:  51.083 | pTtrue:  47.653\n",
      "Jet: 50000 | pTraw: 80.998 | pTcorr:  24.839 | pTtrue:  22.685\n",
      "Jet: 60000 | pTraw: 113.554 | pTcorr:  56.293 | pTtrue:  36.947\n",
      "Jet: 70000 | pTraw: 61.468 | pTcorr:  15.503 | pTtrue:  22.712\n",
      "Jet: 80000 | pTraw: 156.366 | pTcorr:  104.205 | pTtrue:  77.724\n",
      "Jet: 90000 | pTraw: 115.208 | pTcorr:  56.829 | pTtrue:  51.045\n",
      "Jet: 100000 | pTraw: 82.505 | pTcorr:  17.530 | pTtrue:  39.483\n",
      "Jet: 110000 | pTraw: 131.879 | pTcorr:  70.023 | pTtrue:  78.585\n",
      "Jet: 120000 | pTraw: 84.898 | pTcorr:  29.525 | pTtrue:  22.154\n",
      "Jet: 130000 | pTraw: 72.890 | pTcorr:  28.249 | pTtrue:  22.219\n",
      "Jet: 140000 | pTraw: 135.729 | pTcorr:  70.380 | pTtrue:  85.030\n",
      "Jet: 150000 | pTraw: 117.496 | pTcorr:  62.802 | pTtrue:  69.103\n",
      "Jet: 160000 | pTraw: 107.234 | pTcorr:  50.388 | pTtrue:  42.336\n",
      "Jet: 170000 | pTraw: 131.135 | pTcorr:  80.631 | pTtrue:  78.255\n",
      "Jet: 180000 | pTraw: 104.895 | pTcorr:  46.991 | pTtrue:  44.955\n",
      "Jet: 190000 | pTraw: 72.385 | pTcorr:  7.175 | pTtrue:  14.541\n",
      "Jet: 200000 | pTraw: 62.958 | pTcorr: -0.436 | pTtrue:  10.133\n",
      "Jet: 210000 | pTraw: 154.817 | pTcorr:  88.132 | pTtrue:  88.394\n",
      "Jet: 220000 | pTraw: 80.385 | pTcorr:  37.268 | pTtrue:  29.418\n",
      "Jet: 230000 | pTraw: 65.136 | pTcorr:  2.164 | pTtrue:  15.710\n",
      "Jet: 240000 | pTraw: 118.376 | pTcorr:  65.995 | pTtrue:  72.791\n",
      "Jet: 250000 | pTraw: 134.058 | pTcorr:  81.331 | pTtrue:  84.359\n",
      "Jet: 260000 | pTraw: 121.719 | pTcorr:  67.265 | pTtrue:  69.855\n",
      "Jet: 270000 | pTraw: 123.837 | pTcorr:  57.478 | pTtrue:  59.480\n",
      "Jet: 280000 | pTraw: 125.391 | pTcorr:  80.992 | pTtrue:  74.690\n",
      "Jet: 290000 | pTraw: 160.251 | pTcorr:  99.921 | pTtrue:  85.413\n",
      "Jet: 300000 | pTraw: 72.549 | pTcorr:  25.528 | pTtrue:  41.321\n",
      "Jet: 310000 | pTraw: 83.573 | pTcorr:  28.351 | pTtrue:  32.272\n",
      "Jet: 320000 | pTraw: 136.039 | pTcorr:  69.300 | pTtrue:  59.076\n",
      "Jet: 330000 | pTraw: 120.423 | pTcorr:  51.522 | pTtrue:  67.099\n",
      "Jet: 340000 | pTraw: 115.174 | pTcorr:  48.883 | pTtrue:  50.459\n",
      "Jet: 350000 | pTraw: 119.256 | pTcorr:  49.790 | pTtrue:  54.910\n",
      "Jet: 360000 | pTraw: 130.254 | pTcorr:  62.603 | pTtrue:  67.099\n",
      "Jet: 370000 | pTraw: 96.666 | pTcorr:  44.879 | pTtrue:  44.680\n",
      "Jet: 380000 | pTraw: 63.073 | pTcorr:  19.969 | pTtrue:  15.510\n",
      "Jet: 390000 | pTraw: 68.410 | pTcorr:  30.376 | pTtrue:  22.385\n",
      "Jet: 400000 | pTraw: 76.934 | pTcorr:  29.335 | pTtrue:  39.455\n",
      "Jet: 410000 | pTraw: 144.521 | pTcorr:  80.312 | pTtrue:  85.687\n",
      "Jet: 420000 | pTraw: 116.636 | pTcorr:  70.095 | pTtrue:  78.896\n",
      "Jet: 430000 | pTraw: 82.382 | pTcorr:  16.457 | pTtrue:  32.202\n",
      "Jet: 440000 | pTraw: 136.601 | pTcorr:  83.540 | pTtrue:  71.244\n",
      "Jet: 450000 | pTraw: 111.926 | pTcorr:  51.652 | pTtrue:  43.376\n",
      "Jet: 460000 | pTraw: 83.626 | pTcorr:  18.439 | pTtrue:  11.582\n",
      "Jet: 470000 | pTraw: 109.319 | pTcorr:  39.356 | pTtrue:  41.375\n",
      "Jet: 480000 | pTraw: 105.654 | pTcorr:  49.520 | pTtrue:  69.853\n",
      "Jet: 490000 | pTraw: 106.033 | pTcorr:  56.630 | pTtrue:  58.621\n",
      "Jet: 500000 | pTraw: 68.372 | pTcorr:  14.376 | pTtrue:  11.029\n",
      "Jet: 510000 | pTraw: 69.341 | pTcorr:  7.696 | pTtrue:  26.924\n",
      "Jet: 520000 | pTraw: 144.704 | pTcorr:  77.601 | pTtrue:  74.206\n",
      "Jet: 530000 | pTraw: 81.813 | pTcorr:  21.243 | pTtrue:  15.794\n",
      "Jet: 540000 | pTraw: 75.493 | pTcorr:  14.483 | pTtrue:  26.736\n",
      "Jet: 550000 | pTraw: 129.957 | pTcorr:  73.646 | pTtrue:  69.982\n",
      "Jet: 560000 | pTraw: 126.631 | pTcorr:  75.778 | pTtrue:  75.356\n",
      "Jet: 570000 | pTraw: 122.704 | pTcorr:  65.414 | pTtrue:  78.503\n",
      "Jet: 580000 | pTraw: 124.614 | pTcorr:  61.885 | pTtrue:  62.930\n",
      "Jet: 590000 | pTraw: 78.846 | pTcorr:  18.719 | pTtrue:  19.066\n",
      "Jet: 600000 | pTraw: 130.570 | pTcorr:  78.747 | pTtrue:  67.781\n",
      "Jet: 610000 | pTraw: 152.311 | pTcorr:  93.011 | pTtrue:  81.776\n",
      "Jet: 620000 | pTraw: 113.740 | pTcorr:  68.036 | pTtrue:  64.524\n",
      "Jet: 630000 | pTraw: 92.667 | pTcorr:  38.330 | pTtrue:  51.475\n",
      "Jet: 640000 | pTraw: 121.521 | pTcorr:  67.570 | pTtrue:  74.363\n",
      "Jet: 650000 | pTraw: 132.296 | pTcorr:  76.488 | pTtrue:  66.154\n",
      "Jet: 660000 | pTraw: 100.519 | pTcorr:  42.031 | pTtrue:  52.783\n",
      "Jet: 670000 | pTraw: 138.905 | pTcorr:  88.600 | pTtrue:  87.182\n",
      "Jet: 680000 | pTraw: 74.500 | pTcorr:  14.163 | pTtrue:  22.268\n",
      "Jet: 690000 | pTraw: 134.295 | pTcorr:  74.515 | pTtrue:  70.820\n",
      "Jet: 700000 | pTraw: 132.588 | pTcorr:  80.271 | pTtrue:  77.649\n",
      "Jet: 710000 | pTraw: 75.550 | pTcorr:  21.399 | pTtrue:  19.169\n",
      "Jet: 720000 | pTraw: 80.310 | pTcorr:  11.591 | pTtrue:  10.539\n",
      "Jet: 730000 | pTraw: 104.359 | pTcorr:  49.300 | pTtrue:  39.102\n",
      "Jet: 740000 | pTraw: 125.668 | pTcorr:  66.138 | pTtrue:  59.035\n",
      "Jet: 750000 | pTraw: 126.526 | pTcorr:  78.169 | pTtrue:  75.286\n",
      "Backup .csv file closed.\n",
      "All data transferred to array. Testing with 753551 jets.\n",
      "\n",
      "Data set lengths: 753551 / 753551 / 753551\n",
      "Input file closed.\n",
      "Preparing to collect data from csv backup file...\n",
      "Jet: 10000 | pTraw: 99.816 | pTcorr:  46.005 | pTtrue:  59.353\n",
      "Jet: 20000 | pTraw: 115.335 | pTcorr:  56.343 | pTtrue:  62.068\n",
      "Jet: 30000 | pTraw: 79.254 | pTcorr:  31.005 | pTtrue:  28.460\n",
      "Jet: 40000 | pTraw: 77.490 | pTcorr:  42.024 | pTtrue:  51.999\n",
      "Jet: 50000 | pTraw: 79.566 | pTcorr:  41.248 | pTtrue:  32.932\n",
      "Jet: 60000 | pTraw: 51.234 | pTcorr:  4.836 | pTtrue:  11.893\n",
      "Jet: 70000 | pTraw: 78.734 | pTcorr:  25.365 | pTtrue:  29.864\n",
      "Jet: 80000 | pTraw: 94.327 | pTcorr:  40.248 | pTtrue:  39.140\n",
      "Jet: 90000 | pTraw: 88.963 | pTcorr:  47.720 | pTtrue:  56.450\n",
      "Jet: 100000 | pTraw: 57.919 | pTcorr:  10.966 | pTtrue:  19.670\n",
      "Jet: 110000 | pTraw: 86.842 | pTcorr:  34.123 | pTtrue:  23.253\n",
      "Jet: 120000 | pTraw: 59.762 | pTcorr:  3.946 | pTtrue:  11.165\n",
      "Jet: 130000 | pTraw: 73.252 | pTcorr:  20.334 | pTtrue:  13.470\n",
      "Jet: 140000 | pTraw: 75.934 | pTcorr:  32.335 | pTtrue:  35.678\n",
      "Jet: 150000 | pTraw: 112.442 | pTcorr:  58.249 | pTtrue:  76.417\n",
      "Jet: 160000 | pTraw: 67.933 | pTcorr:  11.197 | pTtrue:  14.621\n",
      "Jet: 170000 | pTraw: 133.931 | pTcorr:  76.133 | pTtrue:  74.635\n",
      "Jet: 180000 | pTraw: 33.849 | pTcorr:  8.622 | pTtrue:  10.657\n",
      "Jet: 190000 | pTraw: 56.914 | pTcorr:  11.118 | pTtrue:  16.649\n",
      "Jet: 200000 | pTraw: 89.023 | pTcorr:  12.842 | pTtrue:  20.771\n",
      "Jet: 210000 | pTraw: 62.115 | pTcorr:  14.842 | pTtrue:  13.416\n",
      "Jet: 220000 | pTraw: 106.977 | pTcorr:  52.022 | pTtrue:  54.849\n",
      "Jet: 230000 | pTraw: 91.301 | pTcorr:  38.980 | pTtrue:  49.163\n",
      "Jet: 240000 | pTraw: 66.917 | pTcorr:  9.123 | pTtrue:  14.066\n",
      "Jet: 250000 | pTraw: 90.170 | pTcorr:  19.223 | pTtrue:  18.770\n",
      "Jet: 260000 | pTraw: 63.618 | pTcorr:  11.554 | pTtrue:  12.306\n",
      "Jet: 270000 | pTraw: 86.839 | pTcorr:  23.058 | pTtrue:  30.763\n",
      "Jet: 280000 | pTraw: 111.376 | pTcorr:  39.310 | pTtrue:  48.533\n",
      "Jet: 290000 | pTraw: 102.703 | pTcorr:  38.751 | pTtrue:  37.308\n",
      "Jet: 300000 | pTraw: 68.408 | pTcorr:  17.686 | pTtrue:  12.052\n",
      "Jet: 310000 | pTraw: 132.997 | pTcorr:  70.453 | pTtrue:  88.138\n",
      "Jet: 320000 | pTraw: 64.921 | pTcorr:  0.000 | pTtrue:  13.245\n",
      "Jet: 330000 | pTraw: 64.654 | pTcorr:  7.295 | pTtrue:  21.649\n",
      "Jet: 340000 | pTraw: 72.283 | pTcorr:  15.809 | pTtrue:  27.505\n",
      "Jet: 350000 | pTraw: 125.932 | pTcorr:  74.416 | pTtrue:  78.330\n",
      "Jet: 360000 | pTraw: 67.705 | pTcorr:  16.892 | pTtrue:  16.191\n",
      "Jet: 370000 | pTraw: 121.562 | pTcorr:  73.297 | pTtrue:  56.724\n",
      "Jet: 380000 | pTraw: 86.776 | pTcorr:  36.512 | pTtrue:  29.775\n",
      "Jet: 390000 | pTraw: 72.658 | pTcorr:  30.195 | pTtrue:  34.962\n",
      "Jet: 400000 | pTraw: 126.149 | pTcorr:  51.801 | pTtrue:  58.570\n",
      "Jet: 410000 | pTraw: 132.634 | pTcorr:  52.387 | pTtrue:  69.598\n",
      "Jet: 420000 | pTraw: 97.674 | pTcorr:  37.308 | pTtrue:  37.016\n",
      "Jet: 430000 | pTraw: 145.981 | pTcorr:  87.986 | pTtrue:  83.840\n",
      "Jet: 440000 | pTraw: 81.793 | pTcorr:  27.569 | pTtrue:  25.756\n",
      "Jet: 450000 | pTraw: 139.602 | pTcorr:  77.123 | pTtrue:  75.644\n",
      "Jet: 460000 | pTraw: 130.127 | pTcorr:  76.611 | pTtrue:  64.636\n",
      "Jet: 470000 | pTraw: 114.033 | pTcorr:  52.045 | pTtrue:  46.923\n",
      "Jet: 480000 | pTraw: 139.537 | pTcorr:  85.020 | pTtrue:  87.916\n",
      "Jet: 490000 | pTraw: 116.936 | pTcorr:  59.175 | pTtrue:  42.754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jet: 500000 | pTraw: 50.057 | pTcorr:  3.176 | pTtrue:  11.809\n",
      "Jet: 510000 | pTraw: 140.771 | pTcorr:  82.600 | pTtrue:  86.668\n",
      "Jet: 520000 | pTraw: 113.060 | pTcorr:  56.081 | pTtrue:  59.225\n",
      "Jet: 530000 | pTraw: 107.227 | pTcorr:  36.932 | pTtrue:  29.370\n",
      "Jet: 540000 | pTraw: 115.388 | pTcorr:  65.942 | pTtrue:  59.544\n",
      "Jet: 550000 | pTraw: 127.401 | pTcorr:  64.032 | pTtrue:  82.112\n",
      "Jet: 560000 | pTraw: 61.743 | pTcorr:  3.662 | pTtrue:  11.740\n",
      "Jet: 570000 | pTraw: 97.437 | pTcorr:  32.444 | pTtrue:  24.643\n",
      "Jet: 580000 | pTraw: 129.455 | pTcorr:  87.953 | pTtrue:  89.743\n",
      "Jet: 590000 | pTraw: 50.018 | pTcorr:  8.318 | pTtrue:  13.509\n",
      "Jet: 600000 | pTraw: 109.059 | pTcorr:  40.736 | pTtrue:  55.587\n",
      "Jet: 610000 | pTraw: 57.724 | pTcorr: -4.254 | pTtrue:  15.480\n",
      "Jet: 620000 | pTraw: 63.374 | pTcorr:  17.767 | pTtrue:  26.256\n",
      "Jet: 630000 | pTraw: 141.039 | pTcorr:  86.182 | pTtrue:  72.406\n",
      "Jet: 640000 | pTraw: 86.987 | pTcorr:  46.515 | pTtrue:  25.880\n",
      "Jet: 650000 | pTraw: 69.871 | pTcorr:  24.687 | pTtrue:  11.924\n",
      "Jet: 660000 | pTraw: 56.904 | pTcorr: -1.878 | pTtrue:  12.741\n",
      "Backup .csv file closed.\n",
      "All data transferred to array. Testing with 661476 jets.\n",
      "\n",
      "Data set lengths: 661476 / 661476 / 661476\n",
      "\n",
      "Ready! 2023/01/18 15:57:46\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from Scripts_Python.ML_Python_Build_FeatureArrays_FromROOT import Build_FeatureArrays_FromROOT\n",
    "from Scripts_Python.ML_Python_TrainTest import (\n",
    "    Build_FeatureArrays_FromCSV,\n",
    "    Write_MLResults_ToCSV,\n",
    "    Write_MLWeights_ToCSV,\n",
    "    Train_All_Estimators,\n",
    "    Train_LinearRegression,\n",
    "    Train_RandomForestRegression,\n",
    "    Train_MLPRegression,\n",
    "    Test_Estimator,\n",
    "    Test_All_Estimators)\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "def Build_SelectFeatureArray(\n",
    "    X_features,\n",
    "    feature_index\n",
    "    ) :\n",
    "    \"\"\"\n",
    "    Builds training and testing data sets\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Selecting data from master array...\")\n",
    "    \n",
    "    X_features_select = []\n",
    "    for i in range(len(X_features)):\n",
    "        X_temp = []\n",
    "        for j in range(len(feature_index)):\n",
    "            X_temp.append(X_features[i][feature_index[j]])\n",
    "        X_features_select.append(X_temp)\n",
    "        \n",
    "    print(\"Data ready. Feature array length:\", len(X_features_select), \"\\n\")\n",
    "    \n",
    "    return X_features_select\n",
    "\n",
    "    \n",
    "\n",
    "def TestAndSave_LinearRegression(\n",
    "    feature_label,    # Array of labels corresponding to each feature\n",
    "    feature_index,    # Array of indices for each feature used in X_train\n",
    "    lr_pipeline,      # Trained Linear Regression Pipeline\n",
    "    lr_coeffs,        # Array of coefficient values from trained linear regression pipeline\n",
    "    X_test_select,    # Array of testing data features\n",
    "    y_test,           # Array of testing data targets\n",
    "    sc_test,          # Array of testing data simple corrections\n",
    "    pt_test_min,      # Float of min pT to test with\n",
    "    pt_test_max,      # Float of max pT to test with\n",
    "    output_filename,  # Directory path + name for output csv file\n",
    "    use_scaler = True # If true, rescales data\n",
    "    ) :\n",
    "    \n",
    "    X_test_temp  = []\n",
    "    y_test_temp  = []\n",
    "    sc_test_temp = []\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] > pt_test_min and y_test[i] < pt_test_max:\n",
    "            X_test_temp.append(X_test_select[i])\n",
    "            y_test_temp.append(y_test[i])\n",
    "            sc_test_temp.append(sc_test[i])\n",
    "        else: continue\n",
    "    \n",
    "    # Tests estimator\n",
    "    \n",
    "    print(type(lr_pipeline))\n",
    "    \n",
    "    lr_results, lr_results_delta = Test_Estimator(\n",
    "        lr_pipeline,\n",
    "        X_test_temp, \n",
    "        y_test_temp\n",
    "        )\n",
    "    \n",
    "    # Writes outputs to a csv file\n",
    "    Write_MLResults_ToCSV(\n",
    "        output_filename,\n",
    "        y_test_temp,\n",
    "        sc_test_temp,\n",
    "        lr_results,\n",
    "        X_test_temp,\n",
    "        feature_label\n",
    "        )\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def TrainTestPlot_All_Estimators(\n",
    "    feature_label,    # Array of labels corresponding to each feature\n",
    "    feature_index,    # Array of indices for each feature used in X_train\n",
    "    X_train,          # Array of training data features\n",
    "    y_train,          # Array of training data targets\n",
    "    sc_train,         # Array of training data simple correction values\n",
    "    X_test,           # Array of testing data features\n",
    "    y_test,           # Array of testing data targets\n",
    "    sc_test,          # Array of testing data simple corrections\n",
    "    output_file_path, # File path for outputs\n",
    "    use_scaler = True,\n",
    "    use_lr = True,\n",
    "    use_rf = True,\n",
    "    use_mlp = True,\n",
    "    ) :\n",
    "    \n",
    "    # Builds training data set\n",
    "    print(\"Selecting training data...\")\n",
    "    X_train_select = []\n",
    "    for i in range(len(X_train)):\n",
    "        X_temp = []\n",
    "        for j in range(len(feature_index)):\n",
    "            X_temp.append(X_train[i][feature_index[j]])\n",
    "        X_train_select.append(X_temp)\n",
    "    print(\"Training data ready. X/Y length:\", len(X_train_select), len(y_train), \"/n\")\n",
    "    \n",
    "    # Builds pipelines from selected training features\n",
    "    print(\"Building estimator pipelines...\")\n",
    "    lr_pipeline, rf_pipeline, mlp_pipeline, lr_coeffs, rf_features = Train_All_Estimators(\n",
    "        X_train_select, y_train, feature_label, \n",
    "        use_StandardScaler = use_scaler,\n",
    "        use_LinearRegression = use_lr,\n",
    "        use_RandomForest = use_rf,\n",
    "        use_MLP = use_mlp)\n",
    "    print(\"Pipelines built./n\")\n",
    "    \n",
    "    print(\"Selecting testing data...\")\n",
    "    X_test_select = []\n",
    "    for i in range(len(X_test)):\n",
    "        X_temp = []\n",
    "        for j in range(len(feature_index)):\n",
    "            X_temp.append(X_test[i][feature_index[j]])\n",
    "        X_test_select.append(X_temp)\n",
    "    print(\"Testing data ready. X/Y length:\", len(X_test_select), len(y_test), \"/n\")\n",
    "    \n",
    "    # Test estimators\n",
    "    print(\"Testing all estimators...\")\n",
    "    lr_results, lr_results_delta, rf_results, rf_results_delta, mlp_results, mlp_results_delta = Test_All_Estimators(\n",
    "        X_test_select, \n",
    "        y_test, \n",
    "        lr_pipeline,\n",
    "        rf_pipeline,\n",
    "        mlp_pipeline)\n",
    "    print(\"Estimator testing complete!/n\")\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "#                                         #\n",
    "#     DATA PREPARATION - CHANGE BELOW     #\n",
    "#                                         #\n",
    "###########################################\n",
    "\n",
    "\n",
    "\n",
    "file_directory   = \"../../Files/Comparison_Test_4/Data/\"\n",
    "\n",
    "train_base_name  = \"Train_B8_10_90_N500000\" # Cut off 'ML_Prep_' and '.root' parts of input file names\n",
    "train_bias       = \"B8\"\n",
    "train_range      = (10., 90.) # pT min/max of training file\n",
    "\n",
    "test_base_name   = \"Test_B8_10_90_N500000\" # Cut off 'ML_Prep_' and '.root' parts of input file names\n",
    "test_range       = (10., 90.) # pT min/max of testing file\n",
    "\n",
    "\n",
    "\n",
    "##### ANYTHING BELOW THIS SHOULDN'T NEED TO CHANGE #####\n",
    "\n",
    "train_file_name  = \"Full_\" + train_base_name + \"_ML_Prep.root\"\n",
    "# train_file_name  = \"Full_Train_TopInRange_B8_10_90_N500000_ML_Prep.root\"\n",
    "train_tree_name  = \"ML_\" + train_base_name\n",
    "train_file_path  = file_directory + train_file_name\n",
    "train_csv_path   = file_directory + \"ML_Prep_\" + train_base_name + \"_Backup.csv\"\n",
    "# train_csv_path   = file_directory + \"ML_Prep_Train_TopInRange_B8_10_90_N500000_Backup.csv\"\n",
    "\n",
    "test_file_name   = \"Full_\" + test_base_name + \"_ML_Prep.root\"\n",
    "test_tree_name   = \"ML_\" + test_base_name\n",
    "test_file_path   = file_directory + test_file_name\n",
    "test_csv_path    = file_directory + \"ML_Prep_\" + test_base_name + \"_Backup.csv\"\n",
    "\n",
    "# Builds ML output directories\n",
    "output_directory = file_directory + \"ML_Results/\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_directory)\n",
    "    print(\"made 'ML_Results' directory\")\n",
    "except:\n",
    "    print(\"directory already exists\")\n",
    "\n",
    "# Rebuilds feature and target arrays from csv file, or rebuilds them if csv doesn't exist\n",
    "\n",
    "# Training data\n",
    "if os.path.exists(train_csv_path):\n",
    "    X_train, y_train, sc_train = Build_FeatureArrays_FromCSV(train_csv_path)\n",
    "else:\n",
    "    X_train, y_train, sc_train = Build_FeatureArrays_FromROOT(\n",
    "        train_file_path, train_tree_name, train_csv_path, train_range[0], train_range[1])\n",
    "\n",
    "# Testing data\n",
    "if os.path.exists(test_csv_path):\n",
    "    X_test,  y_test,  sc_test  = Build_FeatureArrays_FromCSV(test_csv_path)\n",
    "else:\n",
    "    X_test, y_test, sc_test = Build_FeatureArrays_FromROOT(\n",
    "        test_file_path,  test_tree_name,  test_csv_path,  test_range[0],  test_range[1])\n",
    "\n",
    "# Set Features to train with\n",
    "# X_values[\n",
    "#    0  jet_pt_raw,      1  jet_pt_corr,     2  jet_mass,        3  jet_area, \n",
    "#    4  jet_area_err,    5  jet_const_n,     6  const_pt_mean,   7  const_pt_median, \n",
    "#    8  const_1_pt,      9  const_2_pt,      10 const_3_pt,      11 const_4_pt,\n",
    "#    12 const_5_pt,      13 const_6_pt,      14 const_7_pt,      15 const_8_pt,\n",
    "#    16 const_9_pt,      17 const_10_pt,     18 jet_y,           19 jet_phi,\n",
    "#    20 jet_rho]\n",
    "\n",
    "# Training with 1 feature\n",
    "feature_label_1feat = [\n",
    "    \"jet_pt_raw\"]\n",
    "feature_index_1feat = [0]\n",
    "\n",
    "# Training with 3 features\n",
    "feature_label_3feat = [\n",
    "    \"jet_pt_raw\", \"jet_area\", \"jet_rho\"]\n",
    "feature_index_3feat = [0, 3, 20]\n",
    "\n",
    "# Training with 12 features\n",
    "feature_label_12feat = [\n",
    "    \"jet_pt_raw\",    \"jet_pt_corr\",    \"jet_mass\",      \"jet_area\", \n",
    "    \"jet_const_n\",   \"const_pt_mean\",  \"const_1_pt\",    \"const_2_pt\",\n",
    "    \"const_3_pt\",    \"const_4_pt\",     \"jet_y\",         \"jet_rho\"]\n",
    "feature_index_12feat = [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 18, 20]\n",
    "\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nReady!\", dt_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4130c",
   "metadata": {},
   "source": [
    "## Training & Testing\n",
    "1 Feature: pt_raw ONLY\n",
    "\n",
    "3 Features: pt_raw, jet_area, jet_rho\n",
    "\n",
    "12 Features: jet_pt_raw, jet_pt_corr, jet_mass, jet_area, jet_const_n, const_pt_mean, const_1_pt, const_2_pt, const_3_pt, const_4_pt, jet_y, jet_rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe20d7c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made directory\n",
      "made subdirectories\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 753551 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 661476 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "49.00813326631894\n",
      "[ 2.06653645e+01  5.19999535e+00  1.11085701e+00 -4.31725440e-01\n",
      " -8.18801576e+00 -3.24574353e-01  2.13031202e-02  1.24057552e-01\n",
      "  1.96540253e-01  1.98312957e-01  6.64943849e-03 -1.27301071e-01]\n",
      "[ 2.06653645e+01  5.19999535e+00  1.11085701e+00 -4.31725440e-01\n",
      " -8.18801576e+00 -3.24574353e-01  2.13031202e-02  1.24057552e-01\n",
      "  1.96540253e-01  1.98312957e-01  6.64943849e-03 -1.27301071e-01\n",
      "  4.90081333e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 20.665364538591003\n",
      "jet_pt_corr 5.199995349311128\n",
      "jet_mass 1.1108570084742324\n",
      "jet_area -0.4317254404076082\n",
      "jet_const_n -8.188015762639203\n",
      "const_pt_mean -0.3245743534990213\n",
      "const_1_pt 0.02130312022160064\n",
      "const_2_pt 0.12405755200929189\n",
      "const_3_pt 0.19654025315707005\n",
      "const_4_pt 0.1983129566704021\n",
      "jet_y 0.006649438486092645\n",
      "jet_rho -0.12730107139075128\n",
      "lr_intercept 49.00813326631894\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 18-22 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 12 features on 28-32 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 12 features on 38-42 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 12 features on 48-52 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 12 features on 58-62 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 12 features on 68-72 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 12 features on 78-82 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "made directory\n",
      "made subdirectories\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 219592 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 338176 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "18.630127534370715\n",
      "[ 3.46256223  1.07430047  2.59724357 -0.17622227 -4.7783947  -0.50469188\n",
      "  0.24390442  0.27165079  0.21426032  0.12211455  0.01324811 -0.06024497]\n",
      "[ 3.46256223e+00  1.07430047e+00  2.59724357e+00 -1.76222269e-01\n",
      " -4.77839470e+00 -5.04691880e-01  2.43904424e-01  2.71650790e-01\n",
      "  2.14260320e-01  1.22114551e-01  1.32481100e-02 -6.02449689e-02\n",
      "  1.86301275e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 3.462562229273495\n",
      "jet_pt_corr 1.0743004680660282\n",
      "jet_mass 2.5972435700411878\n",
      "jet_area -0.1762222688274012\n",
      "jet_const_n -4.778394701798436\n",
      "const_pt_mean -0.504691879516836\n",
      "const_1_pt 0.24390442376310448\n",
      "const_2_pt 0.27165079023252897\n",
      "const_3_pt 0.2142603199801342\n",
      "const_4_pt 0.12211455109464324\n",
      "jet_y 0.01324810999228295\n",
      "jet_rho -0.060244968934513296\n",
      "lr_intercept 18.630127534370715\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 10_30 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 167442 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 189055 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "29.636836359557584\n",
      "[ 4.43905753  0.45051664  0.4222224  -0.37883269 -3.15689363 -0.39110565\n",
      "  0.15342401  0.18560417  0.17933203  0.06400871 -0.0107048  -0.31857824]\n",
      "[ 4.43905753e+00  4.50516638e-01  4.22222402e-01 -3.78832692e-01\n",
      " -3.15689363e+00 -3.91105646e-01  1.53424006e-01  1.85604170e-01\n",
      "  1.79332033e-01  6.40087131e-02 -1.07047978e-02 -3.18578239e-01\n",
      "  2.96368364e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 4.439057529247369\n",
      "jet_pt_corr 0.4505166376687668\n",
      "jet_mass 0.42222240249875376\n",
      "jet_area -0.37883269221179183\n",
      "jet_const_n -3.156893634049246\n",
      "const_pt_mean -0.3911056461644559\n",
      "const_1_pt 0.1534240059444871\n",
      "const_2_pt 0.18560417028115975\n",
      "const_3_pt 0.17933203288158542\n",
      "const_4_pt 0.0640087131241503\n",
      "jet_y -0.010704797814134174\n",
      "jet_rho -0.31857823897226567\n",
      "lr_intercept 29.636836359557584\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 20_40 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 160204 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 134982 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "40.04970017911992\n",
      "[ 4.36863343e+00  4.63297763e-01 -3.47154118e-01 -2.72264888e-01\n",
      " -2.45317530e+00 -1.81221973e-01  8.58903616e-02  9.04469877e-02\n",
      "  7.72963778e-02  4.94289042e-02 -3.56469008e-03 -2.46815946e-01]\n",
      "[ 4.36863343e+00  4.63297763e-01 -3.47154118e-01 -2.72264888e-01\n",
      " -2.45317530e+00 -1.81221973e-01  8.58903616e-02  9.04469877e-02\n",
      "  7.72963778e-02  4.94289042e-02 -3.56469008e-03 -2.46815946e-01\n",
      "  4.00497002e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 4.36863342856182\n",
      "jet_pt_corr 0.4632977627628909\n",
      "jet_mass -0.34715411824999387\n",
      "jet_area -0.2722648881491438\n",
      "jet_const_n -2.4531752959654503\n",
      "const_pt_mean -0.1812219731247291\n",
      "const_1_pt 0.08589036160564299\n",
      "const_2_pt 0.09044698772822549\n",
      "const_3_pt 0.07729637780448427\n",
      "const_4_pt 0.04942890417155654\n",
      "jet_y -0.0035646900801875377\n",
      "jet_rho -0.2468159460871175\n",
      "lr_intercept 40.04970017911992\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 30_50 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 166688 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 110347 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "50.18158349125324\n",
      "[ 4.41636076  0.3493732  -0.45747535 -0.29329201 -2.34005692 -0.12496594\n",
      "  0.03026514  0.01918012  0.07118813  0.06481298 -0.00727992 -0.3039825 ]\n",
      "[ 4.41636076e+00  3.49373200e-01 -4.57475349e-01 -2.93292015e-01\n",
      " -2.34005692e+00 -1.24965937e-01  3.02651385e-02  1.91801190e-02\n",
      "  7.11881255e-02  6.48129791e-02 -7.27991930e-03 -3.03982497e-01\n",
      "  5.01815835e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 4.41636075681215\n",
      "jet_pt_corr 0.3493731996940962\n",
      "jet_mass -0.4574753489833887\n",
      "jet_area -0.2932920146292911\n",
      "jet_const_n -2.3400569172839436\n",
      "const_pt_mean -0.12496593702218743\n",
      "const_1_pt 0.030265138459314108\n",
      "const_2_pt 0.019180118968054338\n",
      "const_3_pt 0.07118812554795538\n",
      "const_4_pt 0.06481297913458385\n",
      "jet_y -0.007279919295192918\n",
      "jet_rho -0.3039824965011272\n",
      "lr_intercept 50.18158349125324\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 40_60 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 177226 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 98214 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "60.20660910193599\n",
      "[ 4.26399604  0.37849419 -0.21679293 -0.22307307 -2.48912173 -0.09817032\n",
      " -0.01362956  0.01707158 -0.00636222  0.12206884  0.0187489  -0.29428055]\n",
      "[ 4.26399604e+00  3.78494193e-01 -2.16792935e-01 -2.23073068e-01\n",
      " -2.48912173e+00 -9.81703157e-02 -1.36295596e-02  1.70715775e-02\n",
      " -6.36222477e-03  1.22068845e-01  1.87489028e-02 -2.94280550e-01\n",
      "  6.02066091e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 4.263996039969224\n",
      "jet_pt_corr 0.3784941928061275\n",
      "jet_mass -0.2167929347792414\n",
      "jet_area -0.22307306790141812\n",
      "jet_const_n -2.4891217274623574\n",
      "const_pt_mean -0.0981703157075551\n",
      "const_1_pt -0.01362955960229868\n",
      "const_2_pt 0.017071577537611494\n",
      "const_3_pt -0.006362224765485069\n",
      "const_4_pt 0.1220688446008722\n",
      "jet_y 0.018748902810911072\n",
      "jet_rho -0.2942805498465767\n",
      "lr_intercept 60.20660910193599\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 50_70 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 187469 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 92537 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "70.16657037756707\n",
      "[ 4.04646361  0.51669244  0.01109762 -0.11554261 -2.69124525 -0.13135642\n",
      " -0.07063768 -0.04802975  0.08009636  0.13411165 -0.00700561 -0.22462852]\n",
      "[ 4.04646361e+00  5.16692442e-01  1.10976159e-02 -1.15542611e-01\n",
      " -2.69124525e+00 -1.31356415e-01 -7.06376810e-02 -4.80297512e-02\n",
      "  8.00963600e-02  1.34111646e-01 -7.00561025e-03 -2.24628516e-01\n",
      "  7.01665704e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 4.046463606742447\n",
      "jet_pt_corr 0.516692442233516\n",
      "jet_mass 0.01109761585408804\n",
      "jet_area -0.11554261137347474\n",
      "jet_const_n -2.6912452541221428\n",
      "const_pt_mean -0.13135641505623996\n",
      "const_1_pt -0.07063768100139757\n",
      "const_2_pt -0.04802975116042011\n",
      "const_3_pt 0.08009635999639342\n",
      "const_4_pt 0.13411164570647513\n",
      "jet_y -0.007005610253952509\n",
      "jet_rho -0.2246285164428756\n",
      "lr_intercept 70.16657037756707\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 60_80 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 196529 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 90104 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "80.15510277488276\n",
      "[ 3.23850602  1.24042284  0.19843111  0.11195423 -2.84140836 -0.2128458\n",
      " -0.08105302  0.01075404 -0.01674876  0.23187594 -0.01548847  0.15353366]\n",
      "[ 3.23850602e+00  1.24042284e+00  1.98431108e-01  1.11954234e-01\n",
      " -2.84140836e+00 -2.12845804e-01 -8.10530195e-02  1.07540362e-02\n",
      " -1.67487603e-02  2.31875938e-01 -1.54884707e-02  1.53533661e-01\n",
      "  8.01551028e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 3.2385060238846304\n",
      "jet_pt_corr 1.2404228352245006\n",
      "jet_mass 0.19843110768647004\n",
      "jet_area 0.1119542343301435\n",
      "jet_const_n -2.8414083614328414\n",
      "const_pt_mean -0.21284580438342338\n",
      "const_1_pt -0.08105301952696363\n",
      "const_2_pt 0.010754036242436515\n",
      "const_3_pt -0.016748760325453315\n",
      "const_4_pt 0.23187593760197764\n",
      "jet_y -0.01548847067097603\n",
      "jet_rho 0.15353366128438253\n",
      "lr_intercept 80.15510277488276\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 70_90 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "made directory\n",
      "made subdirectories\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 298877 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 413920 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "22.964329739582055\n",
      "[ 6.82476734  1.68932747  2.49378638 -0.41938485 -6.38935108 -0.64259822\n",
      "  0.31073546  0.35468058  0.32848824  0.10165283  0.01415332 -0.18409443]\n",
      "[ 6.82476734e+00  1.68932747e+00  2.49378638e+00 -4.19384854e-01\n",
      " -6.38935108e+00 -6.42598220e-01  3.10735456e-01  3.54680576e-01\n",
      "  3.28488241e-01  1.01652833e-01  1.41533242e-02 -1.84094429e-01\n",
      "  2.29643297e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 6.824767336998741\n",
      "jet_pt_corr 1.6893274695909755\n",
      "jet_mass 2.4937863840730197\n",
      "jet_area -0.4193848542407423\n",
      "jet_const_n -6.389351076943835\n",
      "const_pt_mean -0.6425982202899837\n",
      "const_1_pt 0.31073545632423705\n",
      "const_2_pt 0.3546805763238982\n",
      "const_3_pt 0.32848824132685406\n",
      "const_4_pt 0.10165283315625882\n",
      "jet_y 0.014153324212894444\n",
      "jet_rho -0.18409442934794862\n",
      "lr_intercept 22.964329739582055\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 10-40 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 248361 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 248293 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "34.65153670327965\n",
      "[ 7.97634359e+00  7.02982217e-01  1.07340689e-01 -5.64461796e-01\n",
      " -4.50759742e+00 -4.25607133e-01  1.79123290e-01  2.09242000e-01\n",
      "  2.19622494e-01  6.53997782e-02 -4.94943706e-03 -5.10149228e-01]\n",
      "[ 7.97634359e+00  7.02982217e-01  1.07340689e-01 -5.64461796e-01\n",
      " -4.50759742e+00 -4.25607133e-01  1.79123290e-01  2.09242000e-01\n",
      "  2.19622494e-01  6.53997782e-02 -4.94943706e-03 -5.10149228e-01\n",
      "  3.46515367e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 7.976343594068491\n",
      "jet_pt_corr 0.7029822171168141\n",
      "jet_mass 0.10734068885166408\n",
      "jet_area -0.5644617961834932\n",
      "jet_const_n -4.507597424857912\n",
      "const_pt_mean -0.42560713323226623\n",
      "const_1_pt 0.17912329035974683\n",
      "const_2_pt 0.20924199955099165\n",
      "const_3_pt 0.21962249374244752\n",
      "const_4_pt 0.06539977823774228\n",
      "jet_y -0.0049494370563082386\n",
      "jet_rho -0.5101492278571769\n",
      "lr_intercept 34.65153670327965\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 20-50 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 245973 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 186091 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "45.2779402740933\n",
      "[ 7.32001846  1.16955967 -0.61774542 -0.31673081 -3.8671262  -0.24500594\n",
      "  0.08427023  0.08733062  0.11187667  0.09705384 -0.00908732 -0.23357006]\n",
      "[ 7.32001846e+00  1.16955967e+00 -6.17745421e-01 -3.16730811e-01\n",
      " -3.86712620e+00 -2.45005945e-01  8.42702253e-02  8.73306172e-02\n",
      "  1.11876666e-01  9.70538418e-02 -9.08731688e-03 -2.33570060e-01\n",
      "  4.52779403e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 7.32001846332877\n",
      "jet_pt_corr 1.1695596688276164\n",
      "jet_mass -0.6177454207965479\n",
      "jet_area -0.31673081122306795\n",
      "jet_const_n -3.867126198876317\n",
      "const_pt_mean -0.24500594487318594\n",
      "const_1_pt 0.08427022534358893\n",
      "const_2_pt 0.08733061717193423\n",
      "const_3_pt 0.11187666578990063\n",
      "const_4_pt 0.0970538418303306\n",
      "jet_y -0.009087316879076312\n",
      "jet_rho -0.23357005982797213\n",
      "lr_intercept 45.2779402740933\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 30-60 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 258145 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 157452 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "55.44874259871741\n",
      "[ 7.63865100e+00  6.65866524e-01 -4.87416263e-01 -4.17257438e-01\n",
      " -3.87467537e+00 -1.63806839e-01  6.80916002e-03  3.51754627e-02\n",
      "  3.39622551e-02  1.51001987e-01  9.08179871e-03 -4.63204388e-01]\n",
      "[ 7.63865100e+00  6.65866524e-01 -4.87416263e-01 -4.17257438e-01\n",
      " -3.87467537e+00 -1.63806839e-01  6.80916002e-03  3.51754627e-02\n",
      "  3.39622551e-02  1.51001987e-01  9.08179871e-03 -4.63204388e-01\n",
      "  5.54487426e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 7.638651002556652\n",
      "jet_pt_corr 0.6658665238557866\n",
      "jet_mass -0.4874162632956398\n",
      "jet_area -0.417257437524718\n",
      "jet_const_n -3.874675369175862\n",
      "const_pt_mean -0.16380683938544813\n",
      "const_1_pt 0.006809160018768519\n",
      "const_2_pt 0.03517546273899639\n",
      "const_3_pt 0.03396225507170053\n",
      "const_4_pt 0.15100198657089678\n",
      "jet_y 0.009081798707548232\n",
      "jet_rho -0.46320438802165115\n",
      "lr_intercept 55.44874259871741\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 40-70 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 273238 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 143646 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "65.41947100204197\n",
      "[ 7.17851722  0.92924493 -0.17342621 -0.23419888 -4.08279003 -0.18248161\n",
      " -0.06823506 -0.02997275  0.07201824  0.18937139  0.01061282 -0.34132181]\n",
      "[ 7.17851722e+00  9.29244929e-01 -1.73426215e-01 -2.34198876e-01\n",
      " -4.08279003e+00 -1.82481614e-01 -6.82350622e-02 -2.99727480e-02\n",
      "  7.20182373e-02  1.89371388e-01  1.06128227e-02 -3.41321809e-01\n",
      "  6.54194710e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 7.178517220285646\n",
      "jet_pt_corr 0.9292449289516156\n",
      "jet_mass -0.17342621476272854\n",
      "jet_area -0.23419887623542782\n",
      "jet_const_n -4.082790033752724\n",
      "const_pt_mean -0.182481614414545\n",
      "const_1_pt -0.06823506215119729\n",
      "const_2_pt -0.029972748049193157\n",
      "const_3_pt 0.0720182372671904\n",
      "const_4_pt 0.1893713877015899\n",
      "jet_y 0.010612822732626289\n",
      "jet_rho -0.34132180879821644\n",
      "lr_intercept 65.41947100204197\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 50-80 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 287986 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 137209 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "75.35765649163785\n",
      "[ 6.1860009   1.7630722   0.18498211  0.048821   -4.36103294 -0.28797572\n",
      " -0.11227535 -0.02278685  0.04965619  0.28510778 -0.0132879   0.03673846]\n",
      "[ 6.18600090e+00  1.76307220e+00  1.84982108e-01  4.88210032e-02\n",
      " -4.36103294e+00 -2.87975722e-01 -1.12275350e-01 -2.27868512e-02\n",
      "  4.96561886e-02  2.85107776e-01 -1.32878957e-02  3.67384591e-02\n",
      "  7.53576565e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 6.186000902539561\n",
      "jet_pt_corr 1.7630721956620556\n",
      "jet_mass 0.18498210770234277\n",
      "jet_area 0.04882100320022731\n",
      "jet_const_n -4.361032938549455\n",
      "const_pt_mean -0.28797572166810786\n",
      "const_1_pt -0.11227534990161134\n",
      "const_2_pt -0.02278685115754983\n",
      "const_3_pt 0.049656188552153736\n",
      "const_4_pt 0.28510777595412456\n",
      "jet_y -0.013287895651311717\n",
      "jet_rho 0.03673845909722529\n",
      "lr_intercept 75.35765649163785\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 12 features on 60-90 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Complete! 2023/01/18 16:00:45\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "#                                               #\n",
    "#  TRAIN ML ON ONE BIN, WITH 1, 3, 12 FEATURES  #\n",
    "#                                               #\n",
    "#################################################\n",
    "\n",
    "# Builds outputs directories\n",
    "output_directory_alt = output_directory + \"/Test_4GeV_Bins/\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_directory_alt)\n",
    "    print(\"made directory\")\n",
    "except:\n",
    "    print(\"directory already exists\")\n",
    "try:\n",
    "    os.mkdir(output_directory_alt + \"Plots_Actual/\")\n",
    "    os.mkdir(output_directory_alt + \"Plots_Delta/\")\n",
    "    print(\"made subdirectories\")\n",
    "except:\n",
    "    print(\"directory already exists\")\n",
    "\n",
    "test_min_max_array = [  # Array of min and max for pT ranges to test on\n",
    "    [18,22], [28,32], [38,42], [48,52], \n",
    "    [58,62], [68,72], [78,82]\n",
    "    ]\n",
    "feature_bundle = [\n",
    "#     [feature_label_1feat,  feature_index_1feat], \n",
    "#     [feature_label_3feat,  feature_index_3feat],\n",
    "    [feature_label_12feat, feature_index_12feat]\n",
    "    ]\n",
    "train_bundle = [ # This may be implemented later to iterate through multiple training sets\n",
    "    [X_train, y_train, sc_train]\n",
    "    ]\n",
    "\n",
    "for feature_set in feature_bundle:\n",
    "    feature_label = feature_set[0]\n",
    "    feature_coeff_label = feature_set[0].copy()\n",
    "    feature_index = feature_set[1]\n",
    "    \n",
    "    output_csv_name = output_directory_alt + \"Train_\" + train_bias + \"_F\" + str(len(feature_label)) + \"_\" + str(int(train_range[0])) + \"_\" + str(int(train_range[1]))\n",
    "    \n",
    "    feature_coeff_label.append(\"lr_intercept\") # Adds field for linear regression y-intercept\n",
    "    \n",
    "    # Builds training and testing arrays\n",
    "    print(\"\\nBuilding training and testing selected feature arrays...\")\n",
    "    X_train_select = Build_SelectFeatureArray(X_train, feature_index)\n",
    "    X_test_select  = Build_SelectFeatureArray(X_test, feature_index)\n",
    "\n",
    "    # Trains estimator\n",
    "    print(\"\\nTraining linear regression estimator...\")\n",
    "    lr_pipeline, lr_coeffs = Train_LinearRegression(\n",
    "        X_train_select, \n",
    "        y_train, \n",
    "        feature_coeff_label, \n",
    "        use_scaler = True)\n",
    "    print(type(lr_pipeline))\n",
    "    \n",
    "    Write_MLWeights_ToCSV(\n",
    "        output_csv_name + \"_LR_Coeffs.csv\",\n",
    "        lr_coeffs, \n",
    "        feature_coeff_label\n",
    "        )\n",
    "\n",
    "    # Tests estimator and saves results\n",
    "\n",
    "    for min_max in test_min_max_array:\n",
    "        \n",
    "        output = \"\\nTesting \" + str(len(feature_index)) + \" features on \" + str(min_max[0]) + \"-\" + str(min_max[1]) + \" GeV...\"\n",
    "        print(output)\n",
    "        \n",
    "        csv_path = output_csv_name + \"_Test_\" + str(int(min_max[0])) + \"_\" + str(int(min_max[1])) + \".csv\"\n",
    "        \n",
    "        TestAndSave_LinearRegression(\n",
    "            feature_label,\n",
    "            feature_index, \n",
    "            lr_pipeline, \n",
    "            lr_coeffs,\n",
    "            X_test_select,\n",
    "            y_test, \n",
    "            sc_test,\n",
    "            min_max[0],\n",
    "            min_max[1],   \n",
    "            csv_path,\n",
    "            use_scaler = True\n",
    "            )\n",
    "        \n",
    "        print(\"Test and save complete!\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#################################################\n",
    "#                                               #\n",
    "#  TRAIN ML OVER 20 GeV BINS, USES 12 FEATURES  #\n",
    "#                                               #\n",
    "#################################################\n",
    "\n",
    "# Builds outputs directories\n",
    "output_directory_alt = output_directory + \"Train_20GeV_Bins/\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_directory_alt)\n",
    "    print(\"made directory\")\n",
    "except:\n",
    "    print(\"directory already exists\")\n",
    "try:\n",
    "    os.mkdir(output_directory_alt + \"Plots_Actual/\")\n",
    "    os.mkdir(output_directory_alt + \"Plots_Delta/\")\n",
    "    print(\"made subdirectories\")\n",
    "except:\n",
    "    print(\"directory already exists\")\n",
    "\n",
    "training_bundle = [\n",
    "    [10.,30.], [20.,40.], [30.,50.], [40.,60.],\n",
    "    [50.,70.], [60.,80.], [70.,90.]\n",
    "    ]\n",
    "\n",
    "# ONLY runs 12 features\n",
    "for training_range in training_bundle:\n",
    "    train_min = training_range[0]\n",
    "    train_max = training_range[1]\n",
    "    \n",
    "    output_csv_name = output_directory_alt + \"Train_\" + train_bias + \"_F12_\" + str(int(train_min)) + \"_\" + str(int(train_max))\n",
    "    \n",
    "    X_train_cut = []\n",
    "    y_train_cut = []\n",
    "    sc_train_cut = []\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        if (y_train[i] > train_min) and (y_train[i] < train_max):\n",
    "            X_train_cut.append(X_train[i])\n",
    "            y_train_cut.append(y_train[i])\n",
    "            sc_train_cut.append(sc_train[i])\n",
    "    \n",
    "    X_test_cut = []\n",
    "    y_test_cut = []\n",
    "    sc_test_cut = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        if (y_test[i] > train_min) and (y_test[i] < train_max):\n",
    "            X_test_cut.append(X_test[i])\n",
    "            y_test_cut.append(y_test[i])\n",
    "            sc_test_cut.append(sc_test[i])\n",
    "    \n",
    "    # Builds training and testing arrays\n",
    "    print(\"\\nBuilding training and testing selected feature arrays...\")\n",
    "    X_train_select = Build_SelectFeatureArray(X_train_cut, feature_index_12feat)\n",
    "    X_test_select  = Build_SelectFeatureArray(X_test_cut, feature_index_12feat)\n",
    "    \n",
    "    feature_coeff_label = feature_label_12feat.copy()\n",
    "    feature_coeff_label.append(\"lr_intercept\") # Adds field for linear regression y-intercept\n",
    "\n",
    "    # Trains estimator\n",
    "    print(\"\\nTraining linear regression estimator...\")\n",
    "    lr_pipeline, lr_coeffs = Train_LinearRegression(\n",
    "        X_train_select, \n",
    "        y_train_cut, \n",
    "        feature_coeff_label, \n",
    "        use_scaler = True)\n",
    "    print(type(lr_pipeline))\n",
    "    \n",
    "    Write_MLWeights_ToCSV(\n",
    "        output_csv_name + \"_LR_Coeffs.csv\",\n",
    "        lr_coeffs, \n",
    "        feature_coeff_label\n",
    "        )\n",
    "\n",
    "    # Tests estimator and saves results\n",
    "    output = \"\\nTesting \" + str(len(feature_index_12feat)) + \" features on \" + str(int(train_min)) + \"_\" + str(int(train_max)) + \" GeV...\"\n",
    "    print(output)\n",
    "\n",
    "    csv_path = output_csv_name + \"_Test_\" + str(int(train_min)) + \"_\" + str(int(train_max)) + \".csv\"\n",
    "\n",
    "    TestAndSave_LinearRegression(\n",
    "        feature_label_12feat,\n",
    "        feature_index_12feat, \n",
    "        lr_pipeline, \n",
    "        lr_coeffs,\n",
    "        X_test_select,\n",
    "        y_test_cut, \n",
    "        sc_test_cut,\n",
    "        train_min,\n",
    "        train_max,   \n",
    "        csv_path,\n",
    "        use_scaler = True\n",
    "        )\n",
    "\n",
    "    print(\"Test and save complete!\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#################################################\n",
    "#                                               #\n",
    "#  TRAIN ML OVER 30 GeV BINS, USES 12 FEATURES  #\n",
    "#                                               #\n",
    "#################################################\n",
    "\n",
    "# Builds outputs directories\n",
    "output_directory_alt = output_directory + \"Train_30GeV_Bins/\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_directory_alt)\n",
    "    print(\"made directory\")\n",
    "except:\n",
    "    print(\"directory already exists\")\n",
    "try:\n",
    "    os.mkdir(output_directory_alt + \"Plots_Actual/\")\n",
    "    os.mkdir(output_directory_alt + \"Plots_Delta/\")\n",
    "    print(\"made subdirectories\")\n",
    "except:\n",
    "    print(\"directory already exists\")\n",
    "\n",
    "training_bundle = [\n",
    "    [10.,40.], [20.,50.], [30.,60.], [40.,70.],\n",
    "    [50.,80.], [60.,90.]\n",
    "    ]\n",
    "\n",
    "# ONLY runs 12 features\n",
    "for training_range in training_bundle:\n",
    "    train_min = training_range[0]\n",
    "    train_max = training_range[1]\n",
    "    \n",
    "    output_csv_name = output_directory_alt + \"Train_\" + train_bias + \"_F12_\" + str(int(train_min)) + \"_\" + str(int(train_max))\n",
    "    \n",
    "    X_train_cut = []\n",
    "    y_train_cut = []\n",
    "    sc_train_cut = []\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        if (y_train[i] > train_min) and (y_train[i] < train_max):\n",
    "            X_train_cut.append(X_train[i])\n",
    "            y_train_cut.append(y_train[i])\n",
    "            sc_train_cut.append(sc_train[i])\n",
    "    \n",
    "    X_test_cut = []\n",
    "    y_test_cut = []\n",
    "    sc_test_cut = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        if (y_test[i] > train_min) and (y_test[i] < train_max):\n",
    "            X_test_cut.append(X_test[i])\n",
    "            y_test_cut.append(y_test[i])\n",
    "            sc_test_cut.append(sc_test[i])\n",
    "    \n",
    "    # Builds training and testing arrays\n",
    "    print(\"\\nBuilding training and testing selected feature arrays...\")\n",
    "    X_train_select = Build_SelectFeatureArray(X_train_cut, feature_index_12feat)\n",
    "    X_test_select  = Build_SelectFeatureArray(X_test_cut, feature_index_12feat)\n",
    "    \n",
    "    feature_coeff_label = feature_label_12feat.copy()\n",
    "    feature_coeff_label.append(\"lr_intercept\") # Adds field for linear regression y-intercept\n",
    "\n",
    "    # Trains estimator\n",
    "    print(\"\\nTraining linear regression estimator...\")\n",
    "    lr_pipeline, lr_coeffs = Train_LinearRegression(\n",
    "        X_train_select, \n",
    "        y_train_cut, \n",
    "        feature_coeff_label, \n",
    "        use_scaler = True)\n",
    "    print(type(lr_pipeline))\n",
    "    \n",
    "    Write_MLWeights_ToCSV(\n",
    "        output_csv_name + \"_LR_Coeffs.csv\",\n",
    "        lr_coeffs, \n",
    "        feature_coeff_label\n",
    "        )\n",
    "\n",
    "    # Tests estimator and saves results\n",
    "    output = \"\\nTesting \" + str(len(feature_index_12feat)) + \" features on \" + str(int(train_min)) + \"-\" + str(int(train_max)) + \" GeV...\"\n",
    "    print(output)\n",
    "\n",
    "    csv_path = output_csv_name + \"_Test_\" + str(int(train_min)) + \"_\" + str(int(train_max)) + \".csv\"\n",
    "\n",
    "    TestAndSave_LinearRegression(\n",
    "        feature_label_12feat,\n",
    "        feature_index_12feat, \n",
    "        lr_pipeline, \n",
    "        lr_coeffs,\n",
    "        X_test_select,\n",
    "        y_test_cut, \n",
    "        sc_test_cut,\n",
    "        train_min,\n",
    "        train_max,   \n",
    "        csv_path,\n",
    "        use_scaler = True\n",
    "        )\n",
    "\n",
    "    print(\"Test and save complete!\\n\")\n",
    "\n",
    "    \n",
    "    \n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nComplete!\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fff5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
