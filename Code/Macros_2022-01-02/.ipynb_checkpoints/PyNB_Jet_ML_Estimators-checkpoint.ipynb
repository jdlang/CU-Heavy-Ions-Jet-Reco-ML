{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26eb87a",
   "metadata": {},
   "source": [
    "## Core Functions\n",
    "These handle importing necessary libraries, preparation of the feature arrays for Machine Learning, and execution of Machine Learning training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f008279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ready! 2023/01/02 16:26:09\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from Scripts_Python.ML_Python_Build_FeatureArrays_FromROOT import Build_FeatureArrays_FromROOT\n",
    "from Scripts_Python.ML_Python_TrainTest import (\n",
    "    Build_FeatureArrays_FromCSV,\n",
    "    Write_MLResults_ToCSV,\n",
    "    Write_MLWeights_ToCSV,\n",
    "    Train_All_Estimators,\n",
    "    Train_LinearRegression,\n",
    "    Train_RandomForestRegression,\n",
    "    Train_MLPRegression,\n",
    "    Test_Estimator,\n",
    "    Test_All_Estimators)\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "def Build_SelectFeatureArray(\n",
    "    X_features,\n",
    "    feature_index\n",
    "    ) :\n",
    "    \"\"\"\n",
    "    Builds training and testing data sets\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Selecting data from master array...\")\n",
    "    \n",
    "    X_features_select = []\n",
    "    for i in range(len(X_features)):\n",
    "        X_temp = []\n",
    "        for j in range(len(feature_index)):\n",
    "            X_temp.append(X_features[i][feature_index[j]])\n",
    "        X_features_select.append(X_temp)\n",
    "        \n",
    "    print(\"Data ready. Feature array length:\", len(X_features_select), \"\\n\")\n",
    "    \n",
    "    return X_features_select\n",
    "\n",
    "    \n",
    "\n",
    "def TestAndSave_LinearRegression(\n",
    "    feature_label,    # Array of labels corresponding to each feature\n",
    "    feature_index,    # Array of indices for each feature used in X_train\n",
    "    lr_pipeline,      # Trained Linear Regression Pipeline\n",
    "    lr_coeffs,        # Array of coefficient values from trained linear regression pipeline\n",
    "    X_test_select,    # Array of testing data features\n",
    "    y_test,           # Array of testing data targets\n",
    "    sc_test,          # Array of testing data simple corrections\n",
    "    pt_test_min,      # Float of min pT to test with\n",
    "    pt_test_max,      # Float of max pT to test with\n",
    "    output_filename,  # Directory path + name for output csv file\n",
    "    use_scaler = True # If true, rescales data\n",
    "    ) :\n",
    "    \n",
    "    X_test_temp  = []\n",
    "    y_test_temp  = []\n",
    "    sc_test_temp = []\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] > pt_test_min and y_test[i] < pt_test_max:\n",
    "            X_test_temp.append(X_test_select[i])\n",
    "            y_test_temp.append(y_test[i])\n",
    "            sc_test_temp.append(sc_test[i])\n",
    "        else: continue\n",
    "    \n",
    "    # Tests estimator\n",
    "    \n",
    "    print(type(lr_pipeline))\n",
    "    \n",
    "    lr_results, lr_results_delta = Test_Estimator(\n",
    "        lr_pipeline,\n",
    "        X_test_temp, \n",
    "        y_test_temp\n",
    "        )\n",
    "    \n",
    "    # Writes outputs to a csv file\n",
    "    Write_MLResults_ToCSV(\n",
    "        output_filename,\n",
    "        y_test_temp,\n",
    "        sc_test_temp,\n",
    "        lr_results,\n",
    "        X_test_temp,\n",
    "        feature_label\n",
    "        )\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def TrainTestPlot_All_Estimators(\n",
    "    feature_label,    # Array of labels corresponding to each feature\n",
    "    feature_index,    # Array of indices for each feature used in X_train\n",
    "    X_train,          # Array of training data features\n",
    "    y_train,          # Array of training data targets\n",
    "    sc_train,         # Array of training data simple correction values\n",
    "    X_test,           # Array of testing data features\n",
    "    y_test,           # Array of testing data targets\n",
    "    sc_test,          # Array of testing data simple corrections\n",
    "    output_file_path, # File path for outputs\n",
    "    use_scaler = True,\n",
    "    use_lr = True,\n",
    "    use_rf = True,\n",
    "    use_mlp = True,\n",
    "    ) :\n",
    "    \n",
    "    # Builds training data set\n",
    "    print(\"Selecting training data...\")\n",
    "    X_train_select = []\n",
    "    for i in range(len(X_train)):\n",
    "        X_temp = []\n",
    "        for j in range(len(feature_index)):\n",
    "            X_temp.append(X_train[i][feature_index[j]])\n",
    "        X_train_select.append(X_temp)\n",
    "    print(\"Training data ready. X/Y length:\", len(X_train_select), len(y_train), \"/n\")\n",
    "    \n",
    "    # Builds pipelines from selected training features\n",
    "    print(\"Building estimator pipelines...\")\n",
    "    lr_pipeline, rf_pipeline, mlp_pipeline, lr_coeffs, rf_features = Train_All_Estimators(\n",
    "        X_train_select, y_train, feature_label, \n",
    "        use_StandardScaler = use_scaler,\n",
    "        use_LinearRegression = use_lr,\n",
    "        use_RandomForest = use_rf,\n",
    "        use_MLP = use_mlp)\n",
    "    print(\"Pipelines built./n\")\n",
    "    \n",
    "    print(\"Selecting testing data...\")\n",
    "    X_test_select = []\n",
    "    for i in range(len(X_test)):\n",
    "        X_temp = []\n",
    "        for j in range(len(feature_index)):\n",
    "            X_temp.append(X_test[i][feature_index[j]])\n",
    "        X_test_select.append(X_temp)\n",
    "    print(\"Testing data ready. X/Y length:\", len(X_test_select), len(y_test), \"/n\")\n",
    "    \n",
    "    # Test estimators\n",
    "    print(\"Testing all estimators...\")\n",
    "    lr_results, lr_results_delta, rf_results, rf_results_delta, mlp_results, mlp_results_delta = Test_All_Estimators(\n",
    "        X_test_select, \n",
    "        y_test, \n",
    "        lr_pipeline,\n",
    "        rf_pipeline,\n",
    "        mlp_pipeline)\n",
    "    print(\"Estimator testing complete!/n\")\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nReady!\", dt_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3495115a",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Sets up input directories/files for training and testing. Creates initial training data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61026866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made 'ML_Results' directory\n",
      "Preparing to collect data from csv backup file...\n",
      "Backup .csv file closed.\n",
      "All data transferred to array. Testing with 1093 jets.\n",
      "\n",
      "Data set lengths: 1093 / 1093 / 1093\n",
      "Preparing to collect data from csv backup file...\n",
      "Backup .csv file closed.\n",
      "All data transferred to array. Testing with 1093 jets.\n",
      "\n",
      "Data set lengths: 1093 / 1093 / 1093\n",
      "\n",
      "Ready! 2023/01/02 16:32:52\n"
     ]
    }
   ],
   "source": [
    "##### CHANGE THESE VALUES #####\n",
    "\n",
    "file_directory   = \"../../Files/Demo/Data/\"\n",
    "\n",
    "train_base_name  = \"Train_B0_10_90_N1000\" # Cut off 'ML_Prep_' and '.root' parts of input file names\n",
    "train_range      = (10., 90.) # pT min/max of training file\n",
    "\n",
    "test_base_name   = \"Test_B0_10_90_N1000\" # Cut off 'ML_Prep_' and '.root' parts of input file names\n",
    "test_range       = (10., 90.) # pT min/max of testing file\n",
    "\n",
    "\n",
    "\n",
    "##### ANYTHING BELOW THIS SHOULDN'T NEED TO CHANGE #####\n",
    "\n",
    "train_file_name  = \"ML_Prep_\" + train_base_name + \".root\"\n",
    "train_tree_name  = \"Jet_ML_\" + train_base_name\n",
    "train_file_path  = file_directory + train_file_name\n",
    "train_csv_path   = file_directory + \"ML_Prep_\" + train_base_name + \"_Backup.csv\"\n",
    "\n",
    "test_file_name   = \"ML_Prep_\" + test_base_name + \".root\"\n",
    "test_tree_name   = \"Jet_ML_\" + test_base_name\n",
    "test_file_path   = file_directory + test_file_name\n",
    "test_csv_path    = file_directory + \"ML_Prep_\" + train_base_name + \"_Backup.csv\"\n",
    "\n",
    "# Builds ML output directories\n",
    "output_directory = file_directory + \"ML_Results/\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_directory)\n",
    "    print(\"made 'ML_Results' directory\")\n",
    "except:\n",
    "    print(\"directory already exists\")\n",
    "\n",
    "# Rebuilds feature and target arrays from csv file, or rebuilds them if csv doesn't exist\n",
    "\n",
    "# Training data\n",
    "if os.path.exists(train_csv_path):\n",
    "    X_train, y_train, sc_train = Build_FeatureArrays_FromCSV(train_csv_path)\n",
    "else:\n",
    "    X_train, y_train, sc_train = Build_FeatureArrays_FromROOT(\n",
    "        train_file_path, train_tree_name, train_csv_path, train_range[0], train_range[1])\n",
    "\n",
    "# Testing data\n",
    "if os.path.exists(train_csv_path):\n",
    "    X_test,  y_test,  sc_test  = Build_FeatureArrays_FromCSV(test_csv_path)\n",
    "else:\n",
    "    X_test, y_test, sc_test = Build_FeatureArrays_FromROOT(\n",
    "        test_file_path,  test_tree_name,  test_csv_path,  test_range[0],  test_range[1])\n",
    "\n",
    "# Set Features to train with\n",
    "# X_values[\n",
    "#    0  jet_pt_raw,      1  jet_pt_corr,     2  jet_mass,        3  jet_area, \n",
    "#    4  jet_area_err,    5  jet_const_n,     6  const_pt_mean,   7  const_pt_median, \n",
    "#    8  const_1_pt,      9  const_2_pt,      10 const_3_pt,      11 const_4_pt,\n",
    "#    12 const_5_pt,      13 const_6_pt,      14 const_7_pt,      15 const_8_pt,\n",
    "#    16 const_9_pt,      17 const_10_pt,     18 jet_y,           19 jet_phi,\n",
    "#    20 jet_rho]\n",
    "\n",
    "# Training with 1 feature\n",
    "feature_label_1feat = [\n",
    "    \"jet_pt_raw\"]\n",
    "feature_index_1feat = [0]\n",
    "\n",
    "# Training with 3 features\n",
    "feature_label_3feat = [\n",
    "    \"jet_pt_raw\", \"jet_area\", \"jet_rho\"]\n",
    "feature_index_3feat = [0, 3, 20]\n",
    "\n",
    "# Training with 12 features\n",
    "feature_label_12feat = [\n",
    "    \"jet_pt_raw\",    \"jet_pt_corr\",    \"jet_mass\",      \"jet_area\", \n",
    "    \"jet_const_n\",   \"const_pt_mean\",  \"const_1_pt\",    \"const_2_pt\",\n",
    "    \"const_3_pt\",    \"const_4_pt\",     \"jet_y\",         \"jet_rho\"]\n",
    "feature_index_12feat = [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 18, 20]\n",
    "\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nReady!\", dt_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4130c",
   "metadata": {},
   "source": [
    "## Training & Testing\n",
    "1 Feature: pt_raw ONLY\n",
    "\n",
    "3 Features: pt_raw, jet_area, jet_rho\n",
    "\n",
    "12 Features: jet_pt_raw, jet_pt_corr, jet_mass, jet_area, jet_const_n, const_pt_mean, const_1_pt, const_2_pt, const_3_pt, const_4_pt, jet_y, jet_rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe20d7c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made directory\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 1093 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 1093 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 1.4148196687610808\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML weights .csv file closed.\n",
      "\n",
      "Testing 1 features on 18-22 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 1 features on 28-32 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 1 features on 38-42 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Testing 1 features on 48-52 GeV...\n",
      "<class 'sklearn.pipeline.Pipeline'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m     63\u001b[0m         csv_path \u001b[38;5;241m=\u001b[39m output_csv_name_2 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Test_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(min_max[\u001b[38;5;241m0\u001b[39m])) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(min_max[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 65\u001b[0m         \u001b[43mTestAndSave_LinearRegression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_pipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_coeffs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_test_select\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43msc_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_scaler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest and save complete!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m now \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mTestAndSave_LinearRegression\u001b[0;34m(feature_label, feature_index, lr_pipeline, lr_coeffs, X_test_select, y_test, sc_test, pt_test_min, pt_test_max, output_filename, use_scaler)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Tests estimator\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(lr_pipeline))\n\u001b[0;32m---> 71\u001b[0m lr_results, lr_results_delta \u001b[38;5;241m=\u001b[39m \u001b[43mTest_Estimator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test_temp\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Writes outputs to a csv file\u001b[39;00m\n\u001b[1;32m     78\u001b[0m Write_MLResults_ToCSV(\n\u001b[1;32m     79\u001b[0m     output_filename,\n\u001b[1;32m     80\u001b[0m     y_test_temp,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     feature_label\n\u001b[1;32m     85\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Research/CU Heavy Ions Group/Machine Learning/CU-Heavy-Ions-Jet-Reco-ML/Code/Macros_2022-01-02/../Scripts_Python/ML_Python_TrainTest.py:319\u001b[0m, in \u001b[0;36mTest_Estimator\u001b[0;34m(ml_pipeline, X_test, y_test)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo pipeline provided!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mml_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m results_delta \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(results)):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/pipeline.py:457\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    455\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 457\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:975\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    972\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    974\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m--> 975\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 879\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    880\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    884\u001b[0m         )\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "#                                               #\n",
    "#  TRAIN ML ON ONE BIN, WITH 1, 3, 12 FEATURES  #\n",
    "#                                               #\n",
    "#################################################\n",
    "\n",
    "# Builds outputs directories\n",
    "output_directory = file_directory + \"ML_Results/Test_4GeV_Bins/\"\n",
    "output_csv_name  = output_directory + train_base_name\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_directory)\n",
    "    print(\"made directory\")\n",
    "except:\n",
    "    print(\"directory already exists\")\n",
    "\n",
    "test_min_max_array = [  # Array of min and max for pT ranges to test on\n",
    "    [18,22], [28,32], [38,42], [48,52], \n",
    "    [58,62], [68,72], [78,82]\n",
    "    ]\n",
    "feature_bundle = [\n",
    "#     [feature_label_1feat,  feature_index_1feat], \n",
    "#     [feature_label_3feat,  feature_index_3feat],\n",
    "    [feature_label_12feat, feature_index_12feat]\n",
    "    ]\n",
    "train_bundle = [ # This may be implemented later to iterate through multiple training sets\n",
    "    [X_train, y_train, sc_train]\n",
    "    ]\n",
    "\n",
    "for feature_set in feature_bundle:\n",
    "    feature_label = feature_set[0]\n",
    "    feature_index = feature_set[1]\n",
    "    \n",
    "    output_csv_name_2 = output_csv_name + \"_F\" + str(len(feature_label)) + \"_\" + str(int(train_range[0])) + \"_\" + str(int(train_range[1]))\n",
    "    \n",
    "    # Builds training and testing arrays\n",
    "    print(\"\\nBuilding training and testing selected feature arrays...\")\n",
    "    X_train_select = Build_SelectFeatureArray(X_train, feature_index)\n",
    "    X_test_select  = Build_SelectFeatureArray(X_test, feature_index)\n",
    "\n",
    "    # Trains estimator\n",
    "    print(\"\\nTraining linear regression estimator...\")\n",
    "    lr_pipeline, lr_coeffs = Train_LinearRegression(\n",
    "        X_train_select, \n",
    "        y_train, \n",
    "        feature_label, \n",
    "        use_scaler = True)\n",
    "    print(type(lr_pipeline))\n",
    "    \n",
    "    Write_MLWeights_ToCSV(\n",
    "        output_csv_name_2 + \"_LR_Coeffs.csv\",\n",
    "        lr_coeffs, \n",
    "        feature_label\n",
    "        )\n",
    "\n",
    "    # Tests estimator and saves results\n",
    "\n",
    "    for min_max in test_min_max_array:\n",
    "        \n",
    "        output = \"\\nTesting \" + str(len(feature_index)) + \" features on \" + str(min_max[0]) + \"-\" + str(min_max[1]) + \" GeV...\"\n",
    "        print(output)\n",
    "        \n",
    "        csv_path = output_csv_name_2 + \"_Test_\" + str(int(min_max[0])) + \"_\" + str(int(min_max[1])) + \".csv\"\n",
    "        \n",
    "        TestAndSave_LinearRegression(\n",
    "            feature_label,\n",
    "            feature_index, \n",
    "            lr_pipeline, \n",
    "            lr_coeffs,\n",
    "            X_test_select,\n",
    "            y_test, \n",
    "            sc_test,\n",
    "            min_max[0],\n",
    "            min_max[1],   \n",
    "            csv_path,\n",
    "            use_scaler = True\n",
    "            )\n",
    "        \n",
    "        print(\"Test and save complete!\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nComplete!\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cac4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#                                               #\n",
    "#  TRAIN ML OVER 20 GeV BINS, USES 12 FEATURES  #\n",
    "#                                               #\n",
    "#################################################\n",
    "\n",
    "# Builds outputs directories\n",
    "output_directory = file_directory + \"ML_Results/Train_20GeV_Bins/\"\n",
    "output_csv_name  = output_directory + train_base_name\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_directory)\n",
    "except:\n",
    "    print(\"directory already exists\")\n",
    "\n",
    "test_min_max_array = [  # Array of min and max for pT ranges to test on\n",
    "    [18,22], [28,32], [38,42], [48,52], \n",
    "    [58,62], [68,72], [78,82]\n",
    "    ]\n",
    "training_bundle = [\n",
    "    [10.,30.], [20.,40.], [30.,50.], [40.,60.],\n",
    "    [50.,70.], [60.,80.], [70.,90.]\n",
    "]\n",
    "\n",
    "# ONLY runs 12 features\n",
    "for training_range in training_bundle:\n",
    "    train_min = training_range[0]\n",
    "    train_max = training_range[1]\n",
    "    \n",
    "    output_csv_name_2 = output_csv_name + \"_F\" + str(len(feature_label_12feat)) + \"_\" + str(int(train_min)) + \"_\" + str(int(train_max))\n",
    "    \n",
    "    X_train_cut = []\n",
    "    y_train_cut = []\n",
    "    sc_train_cut = []\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        if (y_train[i] > train_min) and (y_train[i] < train_max):\n",
    "            X_train_cut.append(X_train[i])\n",
    "            y_train_cut.append(y_train[i])\n",
    "            sc_train_cut.append(sc_train[i])\n",
    "    \n",
    "    X_test_cut = []\n",
    "    y_test_cut = []\n",
    "    sc_test_cut = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        if (y_test[i] > train_min) and (y_test[i] < train_max):\n",
    "            X_test_cut.append(X_test[i])\n",
    "            y_test_cut.append(y_test[i])\n",
    "            sc_test_cut.append(sc_test[i])\n",
    "    \n",
    "    # Builds training and testing arrays\n",
    "    print(\"\\nBuilding training and testing selected feature arrays...\")\n",
    "    X_train_select = Build_SelectFeatureArray(X_train_cut, feature_index_12feat)\n",
    "    X_test_select  = Build_SelectFeatureArray(X_test_cut, feature_index_12feat)\n",
    "\n",
    "    # Trains estimator\n",
    "    print(\"\\nTraining linear regression estimator...\")\n",
    "    lr_pipeline, lr_coeffs = Train_LinearRegression(\n",
    "        X_train_select, \n",
    "        y_train_cut, \n",
    "        feature_label_12feat, \n",
    "        use_scaler = True)\n",
    "    print(type(lr_pipeline))\n",
    "    \n",
    "    Write_MLWeights_ToCSV(\n",
    "        output_csv_name_2 + \"_LR_Coeffs.csv\",\n",
    "        lr_coeffs, \n",
    "        feature_label_12feat\n",
    "        )\n",
    "\n",
    "    # Tests estimator and saves results\n",
    "    output = \"\\nTesting \" + str(len(feature_index_12feat)) + \" features on \" + str(train_min) + \"-\" + str(train_max) + \" GeV...\"\n",
    "    print(output)\n",
    "\n",
    "    csv_path = output_csv_name_2 + \"_Test_\" + str(int(train_min)) + \"_\" + str(int(train_max)) + \".csv\"\n",
    "\n",
    "    TestAndSave_LinearRegression(\n",
    "        feature_label_12feat,\n",
    "        feature_index_12feat, \n",
    "        lr_pipeline, \n",
    "        lr_coeffs,\n",
    "        X_test_select,\n",
    "        y_test_cut, \n",
    "        sc_test_cut,\n",
    "        train_min,\n",
    "        train_max,   \n",
    "        csv_path,\n",
    "        use_scaler = True\n",
    "        )\n",
    "\n",
    "    print(\"Test and save complete!\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nComplete!\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#                                               #\n",
    "#  TRAIN ML OVER 30 GeV BINS, USES 12 FEATURES  #\n",
    "#                                               #\n",
    "#################################################\n",
    "\n",
    "# Builds outputs directories\n",
    "output_directory = file_directory + \"ML_Results/Train_20GeV_Bins/\"\n",
    "output_csv_name  = output_directory + train_base_name\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_directory)\n",
    "except:\n",
    "    print(\"directory already exists\")\n",
    "\n",
    "training_bundle = [\n",
    "    [10.,40.], [20.,50.], [30.,60.], [40.,70.],\n",
    "    [50.,80.], [60.,90.]\n",
    "]\n",
    "\n",
    "# ONLY runs 12 features\n",
    "for training_range in training_bundle:\n",
    "    train_min = training_range[0]\n",
    "    train_max = training_range[1]\n",
    "    \n",
    "    output_csv_name_2 = output_csv_name + \"_F\" + str(len(feature_label_12feat)) + \"_\" + str(int(train_min)) + \"_\" + str(int(train_max))\n",
    "    \n",
    "    X_train_cut = []\n",
    "    y_train_cut = []\n",
    "    sc_train_cut = []\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        if (y_train[i] > train_min) and (y_train[i] < train_max):\n",
    "            X_train_cut.append(X_train[i])\n",
    "            y_train_cut.append(y_train[i])\n",
    "            sc_train_cut.append(sc_train[i])\n",
    "    \n",
    "    X_test_cut = []\n",
    "    y_test_cut = []\n",
    "    sc_test_cut = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        if (y_test[i] > train_min) and (y_test[i] < train_max):\n",
    "            X_test_cut.append(X_test[i])\n",
    "            y_test_cut.append(y_test[i])\n",
    "            sc_test_cut.append(sc_test[i])\n",
    "    \n",
    "    # Builds training and testing arrays\n",
    "    print(\"\\nBuilding training and testing selected feature arrays...\")\n",
    "    X_train_select = Build_SelectFeatureArray(X_train_cut, feature_index_12feat)\n",
    "    X_test_select  = Build_SelectFeatureArray(X_test_cut, feature_index_12feat)\n",
    "\n",
    "    # Trains estimator\n",
    "    print(\"\\nTraining linear regression estimator...\")\n",
    "    lr_pipeline, lr_coeffs = Train_LinearRegression(\n",
    "        X_train_select, \n",
    "        y_train_cut, \n",
    "        feature_label_12feat, \n",
    "        use_scaler = True)\n",
    "    print(type(lr_pipeline))\n",
    "    \n",
    "    Write_MLWeights_ToCSV(\n",
    "        output_csv_name_2 + \"_LR_Coeffs.csv\",\n",
    "        lr_coeffs, \n",
    "        feature_label_12feat\n",
    "        )\n",
    "\n",
    "    # Tests estimator and saves results\n",
    "    output = \"\\nTesting \" + str(len(feature_index_12feat)) + \" features on \" + str(train_min) + \"-\" + str(train_max) + \" GeV...\"\n",
    "    print(output)\n",
    "\n",
    "    csv_path = output_csv_name_2 + \"_Test_\" + str(int(train_min)) + \"_\" + str(int(train_max)) + \".csv\"\n",
    "\n",
    "    TestAndSave_LinearRegression(\n",
    "        feature_label_12feat,\n",
    "        feature_index_12feat, \n",
    "        lr_pipeline, \n",
    "        lr_coeffs,\n",
    "        X_test_select,\n",
    "        y_test_cut, \n",
    "        sc_test_cut,\n",
    "        train_min,\n",
    "        train_max,   \n",
    "        csv_path,\n",
    "        use_scaler = True\n",
    "        )\n",
    "\n",
    "    print(\"Test and save complete!\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nComplete!\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fff5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
