{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a432db04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.26/06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 15:14:06.811489: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-04 15:14:06.979680: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-04 15:14:06.983258: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/qq/Documents/root_install/lib:/home/qq/fastjet-install/lib/\n",
      "2023-01-04 15:14:06.983267: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-04 15:14:07.006658: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-04 15:14:07.488872: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/qq/Documents/root_install/lib:/home/qq/fastjet-install/lib/\n",
      "2023-01-04 15:14:07.489030: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/qq/Documents/root_install/lib:/home/qq/fastjet-install/lib/\n",
      "2023-01-04 15:14:07.489079: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "from os import path\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "from statistics import mean, median\n",
    "import math\n",
    "from array import array\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras import backend as bck\n",
    "\n",
    "def r2(ytrue, ypred):\n",
    "    print(type(ytrue))\n",
    "    print(type(ypred))\n",
    "    res = bck.sum(bck.square(ytrue-ypred))\n",
    "    tot = bck.sum(bck.square(ytrue-bck.mean(ytrue)))\n",
    "    return 1-res/tot\n",
    "\n",
    "def Build_ML_Feature_Arrays_ptTrue(\n",
    "    input_file_path, input_tree_name, pt_true_min, pt_true_max) :\n",
    "    \"\"\"\n",
    "    Creates an array of all features exported from ROOT.\n",
    "    Applies a cut using pT_True values between pt_true_min and pt_true_max.\n",
    "    \"\"\"\n",
    "\n",
    "    input_file = None;\n",
    "    if (ROOT.gSystem.AccessPathName(input_file_path)) :\n",
    "        print(\"Input file path does not exist:\", input_file)\n",
    "        exit()\n",
    "    else :\n",
    "        input_file = ROOT.TFile.Open(input_file_path, \"READ\")\n",
    "        print(\"Input file accessed successfully. Output file generated.\")\n",
    "    \n",
    "    print(\"Accessing input tree...\")\n",
    "    input_tree = input_file.Get(input_tree_name)\n",
    "    print(\"Input tree accessed successfully.\")\n",
    "    \n",
    "    # Setup Arrays\n",
    "    X_values_A  = []  # Array of arrays of inputs corresponding to pT_true as PYTHIA jet pT\n",
    "    y_values_A  = []  # Array of targets for regression, pT_true is PYTHIA jet pT\n",
    "    \n",
    "    X_values_B  = []  # Array of arrays of inputs corresponding to pT_true as jet pT * PYTHIA pT / const. pT\n",
    "    y_values_B  = []  # Array of targets for regression, pT_true is jet pT * PYTHIA pT / const. pT\n",
    "\n",
    "    # Predictors\n",
    "    jet_pt_raw       = None  # Raw/uncorrected jet pt\n",
    "    jet_pt_corr      = None  # Corrected jet pt\n",
    "    jet_mass         = None\n",
    "    jet_area         = None\n",
    "    jet_area_err     = None\n",
    "    jet_const_n      = None\n",
    "    const_pt_mean    = None  # Mean pt of jet constituents\n",
    "    const_pt_median  = None  # Mean pt of jet constituents\n",
    "    const_1_pt       = None  # pt of jet constituent particle 1\n",
    "    const_2_pt       = None  # pt of jet constituent particle 2\n",
    "    const_3_pt       = None  # pt of jet constituent particle 3\n",
    "    const_4_pt       = None  # pt of jet constituent particle 4\n",
    "    const_5_pt       = None  # pt of jet constituent particle 5\n",
    "    const_6_pt       = None  # pt of jet constituent particle 6\n",
    "    const_7_pt       = None  # pt of jet constituent particle 7\n",
    "    const_8_pt       = None  # pt of jet constituent particle 8\n",
    "    const_9_pt       = None  # pt of jet constituent particle 9\n",
    "    const_10_pt      = None  # pt of jet constituent particle 10\n",
    "    jet_y            = None\n",
    "    jet_phi          = None\n",
    "    jet_rho          = None\n",
    "\n",
    "    # Targets\n",
    "    jet_pt_true_A    = None  # True jet pt (determined from PYTHIA jets)\n",
    "    jet_pt_true_B    = None\n",
    "\n",
    "    # Helper Variables\n",
    "    event_counter    = 0\n",
    "    event_n_total    = 20000\n",
    "    jet_n            = None  # Number of jets in an event\n",
    "    jet_n_counter_A  = 0\n",
    "    jet_n_counter_B  = 0\n",
    "    jet_const_pt_arr = []    # Array of jet constituents and their values\n",
    "    sc_correction_arr_A = []\n",
    "    sc_correction_arr_B = []\n",
    "    \n",
    "    print(\"Preparing to collect data from tree...\")\n",
    "\n",
    "    # Collecting from TTree\n",
    "    for event in input_tree :  \n",
    "        jet_n = event.jet_n\n",
    "\n",
    "        for jet in range(0, 2) :\n",
    "            jet_pt_raw      = input_tree.jet_pt_raw[jet]\n",
    "            jet_pt_corr     = input_tree.jet_pt_corr[jet]\n",
    "            jet_mass        = input_tree.jet_mass[jet]\n",
    "            jet_area        = input_tree.jet_area[jet]\n",
    "            jet_const_n     = input_tree.jet_const_n[jet]\n",
    "            const_pt_mean   = input_tree.const_pt_mean[jet]\n",
    "            const_pt_median = input_tree.const_pt_median[jet]\n",
    "            const_1_pt      = input_tree.const_1_pt[jet]\n",
    "            const_2_pt      = input_tree.const_2_pt[jet]\n",
    "            const_3_pt      = input_tree.const_3_pt[jet]\n",
    "            const_4_pt      = input_tree.const_4_pt[jet]\n",
    "            const_5_pt      = input_tree.const_5_pt[jet]\n",
    "            const_6_pt      = input_tree.const_6_pt[jet]\n",
    "            const_7_pt      = input_tree.const_7_pt[jet]\n",
    "            const_8_pt      = input_tree.const_8_pt[jet]\n",
    "            const_9_pt      = input_tree.const_9_pt[jet]\n",
    "            const_10_pt     = input_tree.const_10_pt[jet]\n",
    "            jet_y           = input_tree.jet_y[jet]\n",
    "            jet_phi         = input_tree.jet_phi[jet]\n",
    "            jet_rho         = input_tree.jet_rho[jet]\n",
    "            \n",
    "            jet_pt_true_A   = input_tree.jet_pt_true_pythia[jet]\n",
    "            jet_pt_true_B   = input_tree.jet_pt_true_paper[jet]\n",
    "            \n",
    "            temp_jet_arr = [\n",
    "                    jet_pt_corr,      jet_pt_raw,       jet_area, jet_mass, \n",
    "                        jet_const_n,     const_pt_mean,   const_pt_median, jet_rho,\n",
    "                    const_1_pt,      const_2_pt,      const_3_pt,      const_4_pt,\n",
    "                    const_5_pt,      const_6_pt,      const_7_pt,      const_8_pt,\n",
    "                    const_9_pt,      const_10_pt,     jet_y,           jet_phi]\n",
    "            \n",
    "            if (jet_pt_true_A != 0.0) and (jet_pt_true_A > pt_true_min) and (jet_pt_true_A < pt_true_max) :\n",
    "                X_values_A.append(temp_jet_arr)\n",
    "\n",
    "                y_values_A.append(jet_pt_true_A)\n",
    "                \n",
    "                sc_correction_arr_A.append(jet_pt_corr)\n",
    "                \n",
    "                jet_n_counter_A   = jet_n_counter_A + 1\n",
    "                \n",
    "                if event_counter % 1000 == 0 : print(f\"Event: {event_counter:3.0f} | Jet: {jet:2.0f} | pTraw: {jet_pt_raw:3.3f} | pTcorr: {jet_pt_corr: 3.3f} | pTtrue_A: {jet_pt_true_A: 5.3f}\")\n",
    "            \n",
    "            if (jet_pt_true_B != 0.0) and (jet_pt_true_B > pt_true_min) and (jet_pt_true_B < pt_true_max) :\n",
    "                X_values_B.append(temp_jet_arr)\n",
    "                \n",
    "                y_values_B.append(jet_pt_true_B)\n",
    "\n",
    "                sc_correction_arr_B.append(jet_pt_corr)\n",
    "                \n",
    "                jet_n_counter_B   = jet_n_counter_B + 1\n",
    "\n",
    "                if event_counter % 1000 == 0 : print(f\"Event: {event_counter:3.0f} | Jet: {jet:2.0f} | pTraw: {jet_pt_raw:3.3f} | pTcorr: {jet_pt_corr: 3.3f} | pTtrue_B: {jet_pt_true_B: 5.3f}\")\n",
    "            \n",
    "        event_counter += 1\n",
    "\n",
    "    print(f\"All data transferred to array. Testing with {jet_n_counter_A} A-jets and {jet_n_counter_B} B-jets.\\n\")\n",
    "    print(f\"Training set A: {len(X_values_A)} / {len(y_values_A)} / {len(sc_correction_arr_A)}\")\n",
    "    print(f\"Training set B: {len(X_values_B)} / {len(y_values_B)} / {len(sc_correction_arr_B)}\")\n",
    "\n",
    "    input_file.Close()\n",
    "    print(\"Input file closed.\")\n",
    "    \n",
    "    return X_values_A, y_values_A, sc_correction_arr_A, X_values_B, y_values_B, sc_correction_arr_B\n",
    "\n",
    "    \n",
    "\n",
    "def Build_ML_Feature_Arrays_ptCorr(\n",
    "    input_file_path, input_tree_name, pt_corr_min, pt_corr_max) :\n",
    "    \"\"\"\n",
    "    WARNING: CODE MAY BE OUTDATED\n",
    "    Creates an array of all features exported from ROOT.\n",
    "    Applies a cut using pT_Corrected values between pt_corr_min and pt_corr_max.\n",
    "    This was used once for an alternative selection method and may no longer work.\n",
    "    \"\"\"\n",
    "\n",
    "    input_file = None;\n",
    "    if (ROOT.gSystem.AccessPathName(input_file_path)) :\n",
    "        print(\"Input file path does not exist:\", input_file)\n",
    "        exit()\n",
    "    else :\n",
    "        input_file = ROOT.TFile.Open(input_file_path, \"READ\")\n",
    "        print(\"Input file accessed successfully. Output file generated.\")\n",
    "    \n",
    "    print(\"Accessing input tree...\")\n",
    "    input_tree = input_file.Get(input_tree_name)\n",
    "    print(\"Input tree accessed successfully.\")\n",
    "\n",
    "    # Setup Arrays\n",
    "    X_values_A  = []  # Array of arrays of inputs corresponding to pT_true as PYTHIA jet pT\n",
    "    y_values_A  = []  # Array of targets for regression, pT_true is PYTHIA jet pT\n",
    "    \n",
    "    X_values_B  = []  # Array of arrays of inputs corresponding to pT_true as jet pT * PYTHIA pT / const. pT\n",
    "    y_values_B  = []  # Array of targets for regression, pT_true is jet pT * PYTHIA pT / const. pT\n",
    "\n",
    "    # Predictors\n",
    "    jet_pt_raw       = None  # Raw/uncorrected jet pt\n",
    "    jet_pt_corr      = None  # Corrected jet pt\n",
    "    jet_mass         = None\n",
    "    jet_area         = None\n",
    "    jet_area_err     = None\n",
    "    jet_const_n      = None\n",
    "    const_pt_mean    = None  # Mean pt of jet constituents\n",
    "    const_pt_median  = None  # Mean pt of jet constituents\n",
    "    const_1_pt       = None  # pt of jet constituent particle 1\n",
    "    const_2_pt       = None  # pt of jet constituent particle 2\n",
    "    const_3_pt       = None  # pt of jet constituent particle 3\n",
    "    const_4_pt       = None  # pt of jet constituent particle 4\n",
    "    const_5_pt       = None  # pt of jet constituent particle 5\n",
    "    const_6_pt       = None  # pt of jet constituent particle 6\n",
    "    const_7_pt       = None  # pt of jet constituent particle 7\n",
    "    const_8_pt       = None  # pt of jet constituent particle 8\n",
    "    const_9_pt       = None  # pt of jet constituent particle 9\n",
    "    const_10_pt      = None  # pt of jet constituent particle 10\n",
    "    jet_y            = None\n",
    "    jet_phi          = None\n",
    "    jet_rho          = None\n",
    "    \n",
    "\n",
    "    # Targets\n",
    "    jet_pt_true_A    = None  # True jet pt (determined from PYTHIA jets)\n",
    "    jet_pt_true_B    = None\n",
    "\n",
    "    # Helper Variables\n",
    "    event_n          = 0\n",
    "    event_n_total    = 20000\n",
    "    jet_n            = None  # Number of jets in an event\n",
    "    jet_n_counter_A  = 0\n",
    "    jet_n_counter_B  = 0\n",
    "    jet_const_pt_arr = []    # Array of jet constituents and their values\n",
    "    sc_correction_arr_A = []\n",
    "    sc_correction_arr_B = []\n",
    "\n",
    "    print(\"Preparing to collect data from tree...\")\n",
    "    \n",
    "    # Collecting from TTree\n",
    "    for event in input_tree :  \n",
    "        jet_n = event.jet_n\n",
    "        \n",
    "        for jet in range(0, 2) :\n",
    "            jet_pt_raw      = input_tree.jet_pt_raw[jet]\n",
    "            jet_pt_corr     = input_tree.jet_pt_corr[jet]\n",
    "            jet_mass        = input_tree.jet_mass[jet]\n",
    "            jet_area        = input_tree.jet_area[jet]\n",
    "            jet_const_n     = input_tree.jet_const_n[jet]\n",
    "            const_pt_mean   = input_tree.const_pt_mean[jet]\n",
    "            const_pt_median = input_tree.const_pt_median[jet]\n",
    "            const_1_pt      = input_tree.const_1_pt[jet]\n",
    "            const_2_pt      = input_tree.const_2_pt[jet]\n",
    "            const_3_pt      = input_tree.const_3_pt[jet]\n",
    "            const_4_pt      = input_tree.const_4_pt[jet]\n",
    "            const_5_pt      = input_tree.const_5_pt[jet]\n",
    "            const_6_pt      = input_tree.const_6_pt[jet]\n",
    "            const_7_pt      = input_tree.const_7_pt[jet]\n",
    "            const_8_pt      = input_tree.const_8_pt[jet]\n",
    "            const_9_pt      = input_tree.const_9_pt[jet]\n",
    "            const_10_pt     = input_tree.const_10_pt[jet]\n",
    "            jet_y           = input_tree.jet_y[jet]\n",
    "            jet_phi         = input_tree.jet_phi[jet]\n",
    "            jet_rho         = input_tree.jet_rho[jet]\n",
    "            \n",
    "            jet_pt_true_A   = input_tree.jet_pt_true_pythia[jet]\n",
    "            jet_pt_true_B   = input_tree.jet_pt_true_paper[jet]\n",
    "            \n",
    "            temp_jet_arr = [\n",
    "                    jet_pt_raw,      jet_pt_corr,     const_pt_mean,        jet_area, \n",
    "                        jet_const_n,     jet_mass,   const_pt_median, jet_rho,\n",
    "                    const_1_pt,      const_2_pt,      const_3_pt,      const_4_pt,\n",
    "                    const_5_pt,      const_6_pt,      const_7_pt,      const_8_pt,\n",
    "                    const_9_pt,      const_10_pt,     jet_y,           jet_phi,]\n",
    "            \n",
    "            if (jet_pt_true_A != 0.0) and (jet_pt_corr > pt_corr_min) and (jet_pt_corr < pt_corr_max) :\n",
    "                \n",
    "                X_values_A.append(temp_jet_arr)\n",
    "\n",
    "                y_values_A.append(jet_pt_true_A)\n",
    "                \n",
    "                sc_correction_arr_A.append(jet_pt_corr)\n",
    "                \n",
    "                jet_n_counter_A   = jet_n_counter_A + 1\n",
    "                \n",
    "                if jet_n_counter_A % 10 == 0 :\n",
    "                    print(f\"Event: {event_n:3.0f} | Jet: {jet:2.0f} | pTraw: {jet_pt_raw:3.3f} | pTcorr: {jet_pt_corr: 3.3f} | pTtrue_A: {jet_pt_true_A: 5.3f}\")\n",
    "            \n",
    "            if (jet_pt_true_B != 0.0) and (jet_pt_corr > pt_corr_min) and (jet_pt_corr < pt_corr_max) :\n",
    "                X_values_B.append(temp_jet_arr)\n",
    "                \n",
    "                y_values_B.append(jet_pt_true_B)\n",
    "\n",
    "                sc_correction_arr_B.append(jet_pt_corr)\n",
    "                \n",
    "                jet_n_counter_B   = jet_n_counter_B + 1\n",
    "\n",
    "                if jet_n_counter_B % 10 == 0 :\n",
    "                    print(f\"Event: {event_n:3.0f} | Jet: {jet:2.0f} | pTraw: {jet_pt_raw:3.3f} | pTcorr: {jet_pt_corr: 3.3f} | pTtrue_B: {jet_pt_true_A: 5.3f}\")\n",
    "\n",
    "        event_n = event_n + 1\n",
    "\n",
    "    print(f\"All data transferred to array. Testing with {jet_n_counter_A} A-jets and {jet_n_counter_B} B-jets.\\n\")\n",
    "    print(f\"Training set A: {len(X_values_A)} / {len(y_values_A)} / {len(sc_correction_arr_A)}\")\n",
    "    print(f\"Training set B: {len(X_values_B)} / {len(y_values_B)} / {len(sc_correction_arr_B)}\")\n",
    "\n",
    "    input_file.Close()\n",
    "    print(\"Input file closed.\")\n",
    "    \n",
    "    return X_values_A, y_values_A, sc_correction_arr_A, X_values_B, y_values_B, sc_correction_arr_B\n",
    "\n",
    "\n",
    "def buildfeaturescsv(filename):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            temp = []\n",
    "            line = line.strip().split(',')\n",
    "            for i in range(1,len(line)):\n",
    "                temp.append(float(line[i]))\n",
    "            y.append(float(line[0]))\n",
    "            x.append(temp)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d49fe52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready! 2023/01/04 15:14:11\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = [], []\n",
    "powers = []\n",
    "train = []\n",
    "test = []\n",
    "trainstring = \"\"\n",
    "teststring = \"\"\n",
    "with open(\"powers.txt\") as file:\n",
    "    for line in file:\n",
    "        powers.append(int(line.strip()))\n",
    "\n",
    "with open(\"ranges.txt\") as file:\n",
    "    line = file.readline()\n",
    "    line = line.strip().split()\n",
    "    for bound in line:\n",
    "        train.append(int(bound))\n",
    "    line = file.readline()\n",
    "    line = line.strip().split()\n",
    "    for bound in line:\n",
    "        test.append(int(bound))\n",
    "\n",
    "trainstring = str(train[0]) + \"_\" + str(train[1])\n",
    "teststring = str(test[0]) + \"_\" + str(test[1])\n",
    "            \n",
    "train_tree_name    = \"Tree_Tree\"\n",
    "train_file_paths = []\n",
    "for power in powers:\n",
    "    train_directory    = \"./prepped/\"\n",
    "    train_file_name    = \"ML_Prep_\" + trainstring + \"_Train\" + str(power) +\".csv\"\n",
    "    train_file_path    = train_directory + train_file_name\n",
    "    train_file_paths.append(train_file_path)\n",
    "\n",
    "for i in range(len(powers)):\n",
    "    x, y = buildfeaturescsv(train_file_paths[i])\n",
    "    X_train.append(x)\n",
    "    y_train.append(y)\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "print(\"Ready!\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a0cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./compiled/Data\"\n",
    "output_fil = \"results_\" + trainstring\n",
    "output_ext = \".root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4122080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts,bins = np.histogram(newY, bins=9)\n",
    "#plt.hist(bins[:-1], bins, weights=counts, range=(10,90))\n",
    "\n",
    "def test(X_test, y_test, indices, model, i, l, k, q):\n",
    "    y_pred = model.predict(X_test)\n",
    "    xmin = -49.5\n",
    "    xmax = 50.5\n",
    "    bins = 100\n",
    "    outf = ROOT.TFile.Open(output_directory + output_fil + \"train_ptbias\" + str(l) + \"test_ptbias\" + str(8) + model.__class__.__name__ + str(len(indices)) + \"Features_set\" + str(ptrange[k][0])+ \"_\" + str(ptrange[k][1])+ output_ext, \"RECREATE\")\n",
    "    outt = ROOT.TTree(test_tree_names[0] + model.__class__.__name__, \"tree\")\n",
    "    csvfile = output_directory + output_fil + \"_train_ptbias\" + str(l) + \"_test_ptbias\" + str(8) + \"_\" + model.__class__.__name__ + \"_\" + str(len(indices)) + \"Features_set\" + str(ptrange[k][0])+ \"_\" + str(ptrange[k][1]) + \".csv\"\n",
    "    f = open(csvfile, \"w\")\n",
    "    deltahist = ROOT.TH1D(\"hist\", \"Jet p_{T} Delta \" + str(len(indices)) + \" Feature(s) Test \" + test_tree_names[0][5:-5] + \" GeV (Falling) Test 10_90 GeV (Falling) Train\", bins, xmin, xmax)\n",
    "    deltahist.GetXaxis().SetTitle(\"p_{T true} - p_{T predicted}\")\n",
    "    deltahist.GetYaxis().SetTitle(\"Counts\")\n",
    "    deltahist.GetXaxis().SetRangeUser(-50, 50)\n",
    "    deltahist.GetYaxis().SetRangeUser(0,750)\n",
    "    deltahist.SetMarkerStyle(39)\n",
    "    deltahist.SetMarkerColor(2)\n",
    "    for j in range(len(y_test)):\n",
    "        if y_test[j] < ptrange[k][0] or y_test[j] > ptrange[k][1]:\n",
    "            continue\n",
    "        deltahist.Fill((y_pred[j] - y_test[j]))\n",
    "        f.write(str((y_pred[j] - y_test[j])) + \"\\n\")\n",
    "    deltahist.SetDirectory(0)\n",
    "    outf.cd()\n",
    "    deltahist.Write()\n",
    "    outf.Write()\n",
    "    outf.Close()\n",
    "    f.close()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a285469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train.append(newY)\n",
    "#X_train.append(newX)\n",
    "\n",
    "def fill_schist(corvals, truevals, indices, i, l, k):\n",
    "    xmin = -49.5\n",
    "    xmax = 50.5\n",
    "    bins = 100 #NEED TO FIX: test ptbias needs to be selected from inputs, not hardcoded\n",
    "    outf = ROOT.TFile.Open(output_directory + output_fil + \"train_ptbias\" + str(l) + \"test_ptbias\" + str(8) +\"corrected\" + str(len(indices)) + \"Features_set\" + str(ptrange[k][0])+ \"_\" + str(ptrange[k][1]) + output_ext, \"RECREATE\")\n",
    "    outt = ROOT.TTree(test_tree_names[0][:-5] + \" corrected\", \"tree\")\n",
    "    deltahist = ROOT.TH1D(\"hist\", \"Jet p_{T} Delta \" + str(len(indices)) + \" Feature(s) Test \" + test_tree_names[0][5:-5] + \" GeV (Falling) Test 10_90 GeV (Falling) Test\", bins, xmin, xmax)\n",
    "    deltahist.GetXaxis().SetTitle(\"p_{T true} - p_{T predicted}\")\n",
    "    deltahist.GetYaxis().SetTitle(\"Counts\")\n",
    "    deltahist.GetXaxis().SetRangeUser(-50, 50)\n",
    "    deltahist.GetYaxis().SetRangeUser(0,750)\n",
    "    deltahist.SetMarkerStyle(39)\n",
    "    deltahist.SetMarkerColor(2)\n",
    "    csvfile = output_directory + output_fil + \"_train_ptbias\" + str(l) + \"_test_ptbias\" + str(8) +\"_corrected_\" + str(len(indices)) + \"Features_set\" + str(ptrange[k][0])+ \"_\" + str(ptrange[k][1]) + \".csv\"\n",
    "    f = open(csvfile, \"w\")\n",
    "    for j in range(len(corvals)):\n",
    "        if truevals[j] < ptrange[k][0] or truevals[j] > ptrange[k][1]:\n",
    "            continue\n",
    "        deltahist.Fill((corvals[j][0] - truevals[j]))\n",
    "        f.write(str((corvals[j][0]-truevals[j])) + \"\\n\")\n",
    "    deltahist.SetDirectory(0)\n",
    "    outf.cd()\n",
    "    deltahist.Write()\n",
    "    outf.Write()\n",
    "    outf.Close()\n",
    "    f.close()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50dd10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, indices, X_test, y_test, k, p, l, q):\n",
    "    newX_train = []\n",
    "    for i in range(len(X_train[q])):\n",
    "        ph = []\n",
    "        for j in range(len(X_train[q][0])):\n",
    "            if j in indices:\n",
    "                ph.append(X_train[q][i][j])\n",
    "        newX_train.append(ph)\n",
    "    model.fit(newX_train, y_train[q])\n",
    "    print(model.coef_)\n",
    "    print(model.intercept_)\n",
    "#     elif(q%5 == 1):\n",
    "#         print(model.feature_importances_)\n",
    "    newX_test = []\n",
    "    for i in range(len(X_test)):\n",
    "        ph = []\n",
    "        for j in range(len(X_test[i])):\n",
    "            if j in indices:\n",
    "                ph.append(X_test[i][j])\n",
    "        newX_test.append(ph)\n",
    "    test(newX_test, y_test, indices, model, k, p, l, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed14a05e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./ML_Prep_40_60_Test8.csv']\n",
      "[-1.20072478e+00 -2.11853742e-01  5.22788482e-01  2.56281784e-01\n",
      "  1.58795537e+00 -4.29367039e-01  5.53273915e-02  3.12696586e+00\n",
      " -1.16605266e+00  5.32153677e-01 -2.36872139e-03 -8.90066338e-01]\n",
      "[87.7523, 136.402, 0.444311, 26.9701, 86.0, 1.17241, 0.59534, 109.493, 0.0423735, 0.17997, 0.102262, 0.14376]\n"
     ]
    }
   ],
   "source": [
    "test_directory     = \"./\"\n",
    "test_file_names    = []\n",
    "group = 2\n",
    "ptrange = [[10,12],[18,22],[28,32],[38,42],[48,52],[58,62],[68,72],[78,82],[88,90],[10,20],[20,30],[30,40],[40,50],[50,60],[60,70],[70,80],[80,90],[10,90]]\n",
    "#for power in powers:\n",
    "test_file_names.append(\"ML_Prep_\" + \"40_60\" + \"_Test\" + str(8) + \".csv\")# teststring + \"_Test\" + str(8) + \".csv\")\n",
    "# test_file_names    = [\"ML_Prep_40_60_Test.root\"]\n",
    "test_tree_names    = [\"Tree_\" + teststring + \"_Test\"]\n",
    "# test_tree_names    = [\"Tree_40_60_Test\"]\n",
    "test_file_paths    = [test_directory + test_file_names[i] for i in range(len(test_file_names))]\n",
    "print(test_file_paths)\n",
    "output_directory   = \"./results/\"\n",
    "output_file_name   = \"ML_Results_10_90.root\"\n",
    "output_file_path   = output_directory + output_file_name\n",
    "X_test, y_test = [], []\n",
    "for i in range(len(test_file_names)):\n",
    "    X, y = buildfeaturescsv(test_file_names[i])\n",
    "    X_test.append(X)\n",
    "    y_test.append(y)\n",
    "\n",
    "    \n",
    "indices = [[0,1,2,3,4,5,6,7,8,9,10,11]]\n",
    "indices.append([1,2,7])\n",
    "indices.append([1])\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor()\n",
    "nn = MLPRegressor()\n",
    "el = ElasticNet()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler = scaler.fit(X_train[0])\n",
    "X_train[0] = scaler.transform(X_train[0])\n",
    "X_test_scaled = scaler.transform(X_test[0])\n",
    "print(X_train[0][0])\n",
    "print(X_test[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e30615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87.7523, 136.402, 0.444311, 26.9701, 86.0, 1.17241, 0.59534, 109.493, 0.0423735, 0.17997, 0.102262, 0.14376]\n",
      "84.9504\n",
      "[-1.20072478e+00 -2.11853742e-01  5.22788482e-01  2.56281784e-01\n",
      "  1.58795537e+00 -4.29367039e-01  5.53273915e-02  3.12696586e+00\n",
      " -1.16605266e+00  5.32153677e-01 -2.36872139e-03 -8.90066338e-01]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0][0])\n",
    "print(y_test[0][0])\n",
    "print(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb6ddfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 0 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 1 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 2 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 3 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 4 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 5 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 6 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 7 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 8 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 9 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 10 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 11 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 12 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 13 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 14 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 15 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 16 done.\n",
      "[ 2.24519515e+00  3.30138848e+01  3.89954039e-01 -1.23973268e+01\n",
      " -5.82320015e+00  2.08422724e-01 -7.01463052e-01 -2.37322568e-01\n",
      " -1.52188578e-02 -1.15299853e-02  5.85221416e-03 -1.26614737e-02]\n",
      "36.56230715904533\n",
      "Train set 0, 12 features, pt range 17 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 0 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 1 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 2 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 3 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 4 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 5 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 6 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 7 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 8 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 9 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 10 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 11 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 12 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 13 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 14 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 15 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 16 done.\n",
      "[23.55939161 -6.67208011 -4.23082491]\n",
      "36.56230715926123\n",
      "Train set 0, 3 features, pt range 17 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 0 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 1 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 2 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 3 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 4 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 5 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 6 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 7 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 8 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 9 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 10 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 11 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 12 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 13 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 14 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 15 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 16 done.\n",
      "[20.26840135]\n",
      "36.56230715905737\n",
      "Train set 0, 1 features, pt range 17 done.\n"
     ]
    }
   ],
   "source": [
    "# nn = [keras.Sequential(),keras.Sequential(),keras.Sequential()]\n",
    "# nn[0].add(layers.Dense(16, input_shape=(12,)))#, activation='tanh'))\n",
    "# nn[0].add(layers.Dense(8))#, activation='tanh'))\n",
    "# nn[0].add(layers.Dense(10))\n",
    "# nn[0].add(layers.Dense(5))\n",
    "# nn[0].add(layers.Dense(1, activation='relu'))\n",
    "# nn[0].compile(optimizer='sgd', loss='mse', metrics=[r2])\n",
    "# nn[1].add(layers.Dense(3, input_shape=(3,), activation='tanh'))\n",
    "# nn[1].add(layers.Dense(1, activation='relu'))\n",
    "# nn[1].compile(optimizer='sgd', loss='mse', metrics=[r2])\n",
    "# nn[2].add(layers.Dense(1, input_shape=(1,), activation='tanh'))\n",
    "# nn[2].compile(optimizer='sgd', loss='mse', metrics=[r2])\n",
    "for j in range(len(X_train)):\n",
    "    for i in range(len(indices)):\n",
    "        for k in range(len(ptrange)):\n",
    "            #evaluate_model(nn[i], indices[i], X_test[k], y_test[k], i, powers[j], k)\n",
    "            evaluate_model(lr, indices[i], X_test_scaled, y_test[0],i, powers[j], k, j)\n",
    "#             q += 1\n",
    "#             evaluate_model(rf, indices[i], X_test[k], y_test[k],i, powers[j],k)\n",
    "#             q += 1\n",
    "#             evaluate_model(nn, indices[i], X_test[k], y_test[k],i, powers[j],k)\n",
    "#             q += 1\n",
    "            fill_schist(X_test[0], y_test[0], indices[i], i, powers[j], k)\n",
    "#             q += 1\n",
    "#             evaluate_model(el ,indices[i], X_test[k], y_test[k], i, powers[j],k)\n",
    "#             q += 1\n",
    "            print(\"Train set \" + str(j) + \", \" + str(len(indices[i])) + \" features, pt range \" + str(k) + \" done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6508e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
