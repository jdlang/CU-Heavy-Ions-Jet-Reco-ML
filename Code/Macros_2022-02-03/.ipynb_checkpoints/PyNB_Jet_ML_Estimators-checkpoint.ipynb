{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26eb87a",
   "metadata": {},
   "source": [
    "## Core Functions\n",
    "These handle importing necessary libraries, preparation of the feature arrays for Machine Learning, and execution of Machine Learning training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f008279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ML_Results/' already exists or not made\n",
      "'CSV_Backup/' already exists or not made\n",
      "\n",
      "Ready! 2023/02/16 13:14:15\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from Scripts_Python.ML_Python_Build_FeatureArrays_FromROOT import Build_FeatureArrays_FromROOT\n",
    "from Scripts_Python.ML_Python_TrainTest import (\n",
    "    Build_FeatureArrays_FromCSV,\n",
    "    Write_MLResults_ToCSV,\n",
    "    Write_MLCoefficients_ToCSV,\n",
    "    Train_All_Estimators,\n",
    "    Train_LinearRegression,\n",
    "    Train_RandomForestRegression,\n",
    "    Train_MLPRegression,\n",
    "    Test_Estimator,\n",
    "    Test_All_Estimators,\n",
    "    Full_TrainTest)\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "#                                         #\n",
    "#     DATA PREPARATION - CHANGE BELOW     #\n",
    "#                                         #\n",
    "###########################################\n",
    "\n",
    "# File Directories\n",
    "file_directory   = \"../../Files/Test/\"\n",
    "output_directory = file_directory\n",
    "csv_directory    = file_directory + \"CSV_Backup/\"\n",
    "\n",
    "# Training Data Sources\n",
    "train_file_prep_arr = [  \n",
    "    # String tuple with: \n",
    "    # (0:\"File_Name.root\",   1:\"Tree_Name\",\n",
    "    #  2:\"Base_Name\",   3:\"Bias\",   4:(pt_min, pt_max))\n",
    "    (\"Full_Train_B8_10_90_N500000_ML_Prep.root\", \"ML_Train_B8_10_90_N500000_Flat\",\n",
    "     \"Train_B8_Flat_10_90\", \"B8_Flat\", (10., 90.)),\n",
    "#     (\"Full_Train_B8_10_90_N500000_ML_Prep.root\", \"ML_Train_B8_10_90_N500000\",\n",
    "#      \"Train_B8_10_90\",      \"B8\",   (10., 90.)),\n",
    "#     (\"Full_Train_B4_10_90_N500000_ML_Prep.root\", \"ML_Train_B4_10_90_N500000\",\n",
    "#      \"Train_B4_10_90\",      \"B4\",   (10., 90.)),\n",
    "#     (\"Full_Train_B0_10_90_N500000_ML_Prep.root\", \"ML_Train_B0_10_90_N500000\",\n",
    "#      \"Train_B8_10_90\",      \"B0\",   (10., 90.))\n",
    "]\n",
    "\n",
    "# Testing Data Sources\n",
    "test_file_prep_arr = [\n",
    "    # String tuple with: \n",
    "    # (0:\"File_Name.root\",   1:\"Tree_Name\",\n",
    "    #  2:\"Base_Name\",   3:\"Bias\",   4:(pt_min, pt_max))\n",
    "    (\"Full_Test_B8_10_90_N500000_ML_Prep.root\", \"ML_Test_B8_10_90_N500000_Flat\", \n",
    "     \"Test_Flat_10_90\", \"B8_Flat\", (10., 90.))\n",
    "]\n",
    "\n",
    "# Testing pT Bins\n",
    "test_bin_array = [\n",
    "    # Tuple with:\n",
    "    # (0:\"Test Label / Folder Name\", \n",
    "    #  1:(Training bins: (min,max), (min,max),...), 3:Optional testing bin (min,max))\n",
    "#     (\"Test_4GeV_Bins\", \n",
    "#      ((18,22), (28,32), (38,42), (48,52), (58,62), (68,72), (78,82))),\n",
    "#     (\"Test_Centered_Wide_Bins\", \n",
    "#      ((40,60), (30,70), (20,80), (10,90)))\n",
    "    (\"Train_Centered_Test_40_60\", \n",
    "     ((40,60), (30,70), (20,80), (10,90)), (40,60)) # <- Includes a 3rd index item\n",
    "]\n",
    "\n",
    "# Training and Testing pT Bins\n",
    "traintest_bin_array = [ \n",
    "    # Tuple with:\n",
    "    # (0:\"Test Label / Folder Name\", \n",
    "    #  1:(Training bins: (min,max), (min,max),...), 3:Optional testing bin (min,max))\n",
    "#     (\"Train_20GeV_Bins\", \n",
    "#      ((10,30), (20,40), (30,50), (40,60), (50,70), (60,80), (70,90))),\n",
    "#     (\"Train_30GeV_Bins\", \n",
    "#      ((10,40), (20,50), (30,60), (40,70), (50,80), (60,90))),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "########## ANYTHING BELOW THIS SHOULDN'T NEED TO CHANGE ##########\n",
    "\n",
    "\n",
    "\n",
    "# Builds output directories\n",
    "try:\n",
    "    os.mkdir(output_directory)\n",
    "    print(\"made output directory\")\n",
    "except:\n",
    "    print(\"Output directory already exists or not made\")\n",
    "    \n",
    "try:\n",
    "    os.mkdir(csv_directory)\n",
    "    print(\"made 'CSV_Backup' directory\")\n",
    "except:\n",
    "    print(\"'CSV_Backup/' already exists or not made\")\n",
    "\n",
    "# Builds feature and target arrays from root file, or skips them if csv already exists\n",
    "\n",
    "# Training data\n",
    "train_file_bundle = []\n",
    "for train_file_info in train_file_prep_arr:\n",
    "    train_file_path  = file_directory + train_file_info[0]\n",
    "    train_csv_path   = csv_directory + \"ML_CSV_\" + train_file_info[2] + \".csv\"\n",
    "    train_file_bundle.append((train_csv_path, train_file_info[2], train_file_info[3]))\n",
    "    if not os.path.exists(train_csv_path):\n",
    "        X_train, y_train, sc_train = Build_FeatureArrays_FromROOT(\n",
    "            train_file_path, train_file_info[1], train_csv_path, train_file_info[4][0], train_file_info[4][1])\n",
    "        \n",
    "# Testing data\n",
    "test_file_bundle = []\n",
    "for test_file_info in test_file_prep_arr:\n",
    "    test_file_path   = file_directory + test_file_info[0]\n",
    "    test_csv_path    = csv_directory + \"ML_CSV_\" + test_file_info[2] + \".csv\"\n",
    "    test_file_bundle.append((test_csv_path, test_file_info[2], test_file_info[3]))\n",
    "    if not os.path.exists(test_csv_path):\n",
    "        X_test, y_test, sc_test = Build_FeatureArrays_FromROOT(\n",
    "            test_file_path,  test_file_info[1],  test_csv_path,  test_file_info[4][0],  test_file_info[4][1])\n",
    "\n",
    "# Set Features to train with\n",
    "# X_values[\n",
    "#    0  jet_pt_raw,      1  jet_pt_corr,     2  jet_mass,        3  jet_area, \n",
    "#    4  jet_area_err,    5  jet_const_n,     6  const_pt_mean,   7  const_pt_median, \n",
    "#    8  const_1_pt,      9  const_2_pt,      10 const_3_pt,      11 const_4_pt,\n",
    "#    12 const_5_pt,      13 const_6_pt,      14 const_7_pt,      15 const_8_pt,\n",
    "#    16 const_9_pt,      17 const_10_pt,     18 jet_y,           19 jet_phi,\n",
    "#    20 jet_rho]\n",
    "\n",
    "# Training with 1 feature\n",
    "feature_label_1feat = [\n",
    "    \"jet_pt_raw\"]\n",
    "feature_index_1feat = [0]\n",
    "\n",
    "# Training with 3 features\n",
    "feature_label_3feat = [\n",
    "    \"jet_pt_raw\", \"jet_area\", \"jet_rho\"]\n",
    "feature_index_3feat = [0, 3, 20]\n",
    "\n",
    "# Training with 11 features (removes jet_pt_corr)\n",
    "feature_label_11feat = [\n",
    "    \"jet_pt_raw\",                      \"jet_mass\",      \"jet_area\", \n",
    "    \"jet_const_n\",   \"const_pt_mean\",  \"const_1_pt\",    \"const_2_pt\",\n",
    "    \"const_3_pt\",    \"const_4_pt\",     \"jet_y\",         \"jet_rho\"]\n",
    "feature_index_11feat = [0,    2, 3, 5, 6, 8, 9, 10, 11, 18, 20]\n",
    "\n",
    "# Training with 12 features\n",
    "feature_label_12feat = [\n",
    "    \"jet_pt_raw\",    \"jet_pt_corr\",    \"jet_mass\",      \"jet_area\", \n",
    "    \"jet_const_n\",   \"const_pt_mean\",  \"const_1_pt\",    \"const_2_pt\",\n",
    "    \"const_3_pt\",    \"const_4_pt\",     \"jet_y\",         \"jet_rho\"]\n",
    "feature_index_12feat = [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 18, 20]\n",
    "\n",
    "# CONSIDERATIONS:\n",
    "# get rid of jet_pt_corr - why not try to correct without it?\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"\\nReady!\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206d3507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../../Files/Test/\n",
      "Preparing to collect data from csv backup file...\n",
      "Jet: 10000 | pTraw: 67.802 | pTcorr:  9.889 | pTtrue:  22.714\n",
      "Jet: 20000 | pTraw: 113.494 | pTcorr:  68.569 | pTtrue:  73.197\n",
      "Jet: 30000 | pTraw: 128.162 | pTcorr:  83.969 | pTtrue:  78.818\n",
      "Jet: 40000 | pTraw: 53.972 | pTcorr:  6.135 | pTtrue:  13.920\n",
      "Jet: 50000 | pTraw: 74.984 | pTcorr:  17.824 | pTtrue:  23.420\n",
      "Jet: 60000 | pTraw: 133.699 | pTcorr:  77.283 | pTtrue:  89.206\n",
      "Jet: 70000 | pTraw: 135.533 | pTcorr:  82.953 | pTtrue:  89.507\n",
      "Jet: 80000 | pTraw: 116.430 | pTcorr:  68.602 | pTtrue:  71.660\n",
      "Jet: 90000 | pTraw: 106.142 | pTcorr:  55.696 | pTtrue:  58.960\n",
      "Jet: 100000 | pTraw: 90.687 | pTcorr:  25.634 | pTtrue:  24.841\n",
      "Jet: 110000 | pTraw: 106.689 | pTcorr:  60.016 | pTtrue:  40.791\n",
      "Jet: 120000 | pTraw: 76.343 | pTcorr:  25.970 | pTtrue:  31.077\n",
      "Jet: 130000 | pTraw: 84.739 | pTcorr:  33.524 | pTtrue:  30.955\n",
      "Jet: 140000 | pTraw: 77.394 | pTcorr:  32.290 | pTtrue:  28.719\n",
      "Jet: 150000 | pTraw: 98.469 | pTcorr:  43.165 | pTtrue:  35.446\n",
      "Jet: 160000 | pTraw: 82.528 | pTcorr:  26.143 | pTtrue:  33.867\n",
      "Jet: 170000 | pTraw: 90.957 | pTcorr:  28.176 | pTtrue:  34.423\n",
      "Jet: 180000 | pTraw: 75.809 | pTcorr:  11.515 | pTtrue:  18.818\n",
      "Jet: 190000 | pTraw: 109.108 | pTcorr:  56.226 | pTtrue:  69.928\n",
      "Jet: 200000 | pTraw: 133.437 | pTcorr:  72.708 | pTtrue:  84.851\n",
      "Jet: 210000 | pTraw: 74.622 | pTcorr:  27.733 | pTtrue:  16.392\n",
      "Jet: 220000 | pTraw: 111.318 | pTcorr:  54.006 | pTtrue:  61.517\n",
      "Jet: 230000 | pTraw: 78.922 | pTcorr:  24.879 | pTtrue:  23.053\n",
      "Jet: 240000 | pTraw: 125.912 | pTcorr:  71.593 | pTtrue:  61.019\n",
      "Jet: 250000 | pTraw: 82.245 | pTcorr:  23.465 | pTtrue:  30.478\n",
      "Jet: 260000 | pTraw: 92.894 | pTcorr:  41.390 | pTtrue:  43.041\n",
      "Jet: 270000 | pTraw: 80.122 | pTcorr:  27.663 | pTtrue:  35.579\n",
      "Jet: 280000 | pTraw: 87.708 | pTcorr:  22.331 | pTtrue:  26.702\n",
      "Jet: 290000 | pTraw: 71.193 | pTcorr:  30.477 | pTtrue:  34.385\n",
      "Jet: 300000 | pTraw: 65.519 | pTcorr:  14.275 | pTtrue:  22.978\n",
      "Jet: 310000 | pTraw: 78.681 | pTcorr:  31.837 | pTtrue:  23.189\n",
      "Jet: 320000 | pTraw: 113.637 | pTcorr:  53.197 | pTtrue:  66.285\n",
      "Jet: 330000 | pTraw: 188.763 | pTcorr:  129.272 | pTtrue:  75.675\n",
      "Jet: 340000 | pTraw: 127.599 | pTcorr:  70.366 | pTtrue:  61.936\n",
      "Backup .csv file closed.\n",
      "All data transferred to array. Testing with 349150 jets.\n",
      "\n",
      "Data set lengths: 349150 / 349150 / 349150\n",
      "Made: ../../Files/Test/Train_B8_Flat/\n",
      "Preparing to collect data from csv backup file...\n",
      "Jet: 10000 | pTraw: 107.742 | pTcorr:  50.822 | pTtrue:  45.286\n",
      "Jet: 20000 | pTraw: 122.660 | pTcorr:  72.529 | pTtrue:  67.071\n",
      "Jet: 30000 | pTraw: 96.010 | pTcorr:  50.174 | pTtrue:  55.664\n",
      "Jet: 40000 | pTraw: 91.125 | pTcorr:  44.373 | pTtrue:  46.685\n",
      "Jet: 50000 | pTraw: 86.715 | pTcorr:  18.833 | pTtrue:  41.730\n",
      "Jet: 60000 | pTraw: 144.433 | pTcorr:  88.443 | pTtrue:  83.773\n",
      "Jet: 70000 | pTraw: 108.127 | pTcorr:  46.880 | pTtrue:  39.898\n",
      "Jet: 80000 | pTraw: 121.729 | pTcorr:  48.660 | pTtrue:  48.081\n",
      "Jet: 90000 | pTraw: 74.983 | pTcorr:  5.626 | pTtrue:  19.261\n",
      "Jet: 100000 | pTraw: 82.241 | pTcorr:  26.027 | pTtrue:  25.855\n",
      "Jet: 110000 | pTraw: 90.286 | pTcorr:  41.616 | pTtrue:  39.725\n",
      "Jet: 120000 | pTraw: 86.430 | pTcorr:  26.711 | pTtrue:  20.453\n",
      "Jet: 130000 | pTraw: 101.810 | pTcorr:  51.686 | pTtrue:  53.662\n",
      "Jet: 140000 | pTraw: 77.618 | pTcorr:  18.793 | pTtrue:  11.427\n",
      "Jet: 150000 | pTraw: 103.331 | pTcorr:  60.636 | pTtrue:  64.947\n",
      "Jet: 160000 | pTraw: 78.679 | pTcorr:  10.813 | pTtrue:  22.533\n",
      "Jet: 170000 | pTraw: 161.976 | pTcorr:  97.371 | pTtrue:  83.485\n",
      "Jet: 180000 | pTraw: 136.107 | pTcorr:  83.283 | pTtrue:  80.122\n",
      "Jet: 190000 | pTraw: 133.738 | pTcorr:  78.417 | pTtrue:  88.906\n",
      "Jet: 200000 | pTraw: 132.209 | pTcorr:  71.976 | pTtrue:  48.525\n",
      "Jet: 210000 | pTraw: 139.977 | pTcorr:  92.165 | pTtrue:  88.935\n",
      "Jet: 220000 | pTraw: 93.447 | pTcorr:  27.021 | pTtrue:  37.411\n",
      "Jet: 230000 | pTraw: 84.283 | pTcorr:  16.625 | pTtrue:  20.892\n",
      "Jet: 240000 | pTraw: 83.793 | pTcorr:  28.231 | pTtrue:  31.189\n",
      "Jet: 250000 | pTraw: 117.749 | pTcorr:  71.726 | pTtrue:  77.783\n",
      "Jet: 260000 | pTraw: 120.946 | pTcorr:  63.078 | pTtrue:  70.887\n",
      "Jet: 270000 | pTraw: 94.825 | pTcorr:  33.920 | pTtrue:  35.052\n",
      "Jet: 280000 | pTraw: 117.375 | pTcorr:  54.033 | pTtrue:  35.625\n",
      "Jet: 290000 | pTraw: 148.642 | pTcorr:  93.947 | pTtrue:  82.160\n",
      "Jet: 300000 | pTraw: 90.225 | pTcorr:  39.652 | pTtrue:  42.481\n",
      "Jet: 310000 | pTraw: 85.886 | pTcorr:  31.571 | pTtrue:  25.779\n",
      "Jet: 320000 | pTraw: 101.264 | pTcorr:  54.473 | pTtrue:  65.375\n",
      "Jet: 330000 | pTraw: 67.308 | pTcorr:  12.063 | pTtrue:  16.893\n",
      "Jet: 340000 | pTraw: 124.594 | pTcorr:  76.424 | pTtrue:  72.481\n",
      "Backup .csv file closed.\n",
      "All data transferred to array. Testing with 346083 jets.\n",
      "\n",
      "Data set lengths: 346083 / 346083 / 346083\n",
      "Directory already exists: ../../Files/Test/Train_B8_Flat/\n",
      "Directory already exists: ../../Files/Test/Train_B8_Flat/\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 349150 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 346083 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "50.0133871664626\n",
      "[20.1374815]\n",
      "[20.1374815  50.01338717]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 20.1374815030091\n",
      "lr_intercept 50.0133871664626\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training random forest regression estimator...\n",
      "\n",
      "----- Fitting Random Forest Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Random Tree Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor())])\n",
      "Feature Importance:\n",
      "jet_pt_raw 1.0\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training multilayer perceptron (neural net) regression estimator...\n",
      "\n",
      "----- Fitting Neural Network Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Multilayer Perceptron Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpregressor', MLPRegressor(max_iter=100))])\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "made directory\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 87252 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "49.997940298386574\n",
      "[2.35465589]\n",
      "[ 2.35465589 49.9979403 ]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 2.3546558873630556\n",
      "lr_intercept 49.997940298386574\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 1 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 174610 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "50.0035052174808\n",
      "[7.67055732]\n",
      "[ 7.67055732 50.00350522]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 7.670557320639645\n",
      "lr_intercept 50.0035052174808\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 1 features on 40_60 GeV...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 262176 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "49.984597313975904\n",
      "[13.89696238]\n",
      "[13.89696238 49.98459731]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 13.89696238448797\n",
      "lr_intercept 49.984597313975904\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 1 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 349150 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "50.0133871664626\n",
      "[20.1374815]\n",
      "[20.1374815  50.01338717]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 20.1374815030091\n",
      "lr_intercept 50.0133871664626\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 1 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "Directory already exists: ../../Files/Test/Train_B8_Flat/\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 349150 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 346083 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "50.01338716646259\n",
      "[22.12981995 -4.03780246 -4.36348806]\n",
      "[22.12981995 -4.03780246 -4.36348806 50.01338717]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 22.129819951745798\n",
      "jet_area -4.037802460644471\n",
      "jet_rho -4.363488063171067\n",
      "lr_intercept 50.01338716646259\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training random forest regression estimator...\n",
      "\n",
      "----- Fitting Random Forest Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Random Tree Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor())])\n",
      "Feature Importance:\n",
      "jet_pt_raw 0.8722528930827522\n",
      "jet_area 0.034772460115095556\n",
      "jet_rho 0.09297464680215217\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training multilayer perceptron (neural net) regression estimator...\n",
      "\n",
      "----- Fitting Neural Network Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multilayer Perceptron Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpregressor', MLPRegressor(max_iter=100))])\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "made directory\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 87252 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "49.997940298386574\n",
      "[ 3.1078148  -0.94388597 -1.14457185]\n",
      "[ 3.1078148  -0.94388597 -1.14457185 49.9979403 ]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 3.1078148021337153\n",
      "jet_area -0.9438859734610536\n",
      "jet_rho -1.1445718517083319\n",
      "lr_intercept 49.997940298386574\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 3 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 174610 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "50.0035052174808\n",
      "[ 9.20589794 -2.31641601 -2.82656908]\n",
      "[ 9.20589794 -2.31641601 -2.82656908 50.00350522]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 9.205897938266084\n",
      "jet_area -2.3164160052683886\n",
      "jet_rho -2.8265690834793107\n",
      "lr_intercept 50.0035052174808\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 3 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 262176 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "49.984597313975904\n",
      "[15.65194977 -3.20677727 -3.85429058]\n",
      "[15.65194977 -3.20677727 -3.85429058 49.98459731]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 15.651949773603183\n",
      "jet_area -3.2067772739838896\n",
      "jet_rho -3.8542905759715467\n",
      "lr_intercept 49.984597313975904\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 3 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 349150 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "50.01338716646259\n",
      "[22.12981995 -4.03780246 -4.36348806]\n",
      "[22.12981995 -4.03780246 -4.36348806 50.01338717]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 22.129819951745798\n",
      "jet_area -4.037802460644471\n",
      "jet_rho -4.363488063171067\n",
      "lr_intercept 50.01338716646259\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 3 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "Directory already exists: ../../Files/Test/Train_B8_Flat/\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 349150 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 346083 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "50.0133871664626\n",
      "[ 9.19984500e+00  6.61579804e+00 -2.36282788e+00  1.28546307e-01\n",
      " -1.73229715e+00  1.19412788e+00  3.55996349e+00  1.92766977e+00\n",
      "  1.34029624e+00  3.55033776e+00 -7.34990248e-03  2.42369699e-01]\n",
      "[ 9.19984500e+00  6.61579804e+00 -2.36282788e+00  1.28546307e-01\n",
      " -1.73229715e+00  1.19412788e+00  3.55996349e+00  1.92766977e+00\n",
      "  1.34029624e+00  3.55033776e+00 -7.34990248e-03  2.42369699e-01\n",
      "  5.00133872e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 9.199845003814568\n",
      "jet_pt_corr 6.61579804121687\n",
      "jet_mass -2.3628278758082937\n",
      "jet_area 0.1285463070039313\n",
      "jet_const_n -1.7322971508305662\n",
      "const_pt_mean 1.194127879339815\n",
      "const_1_pt 3.559963494491547\n",
      "const_2_pt 1.9276697671405636\n",
      "const_3_pt 1.3402962399879037\n",
      "const_4_pt 3.5503377643838974\n",
      "jet_y -0.0073499024802209795\n",
      "jet_rho 0.2423696991934208\n",
      "lr_intercept 50.0133871664626\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training random forest regression estimator...\n",
      "\n",
      "----- Fitting Random Forest Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Random Tree Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor())])\n",
      "Feature Importance:\n",
      "jet_pt_raw 0.021562107426864575\n",
      "jet_pt_corr 0.8295329495687167\n",
      "jet_mass 0.008585286497078456\n",
      "jet_area 0.004107745531503387\n",
      "jet_const_n 0.0028999716186546443\n",
      "const_pt_mean 0.04833218419536416\n",
      "const_1_pt 0.016511825730694603\n",
      "const_2_pt 0.021278467618541224\n",
      "const_3_pt 0.013425415294933324\n",
      "const_4_pt 0.015839786825368917\n",
      "jet_y 0.012207202668314291\n",
      "jet_rho 0.005717057023965581\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training multilayer perceptron (neural net) regression estimator...\n",
      "\n",
      "----- Fitting Neural Network Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multilayer Perceptron Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpregressor', MLPRegressor(max_iter=100))])\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "made directory\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 87252 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "49.997940298386574\n",
      "[ 0.38032502  1.89781431 -1.39416531  0.44952562  0.70378393  0.70389997\n",
      "  1.21646651  0.62783988  0.42449509  1.11595741  0.02243733  0.4472568 ]\n",
      "[ 3.80325021e-01  1.89781431e+00 -1.39416531e+00  4.49525616e-01\n",
      "  7.03783933e-01  7.03899970e-01  1.21646651e+00  6.27839883e-01\n",
      "  4.24495093e-01  1.11595741e+00  2.24373289e-02  4.47256801e-01\n",
      "  4.99979403e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 0.380325020780088\n",
      "jet_pt_corr 1.89781430947962\n",
      "jet_mass -1.394165314891483\n",
      "jet_area 0.44952561584346373\n",
      "jet_const_n 0.7037839334752195\n",
      "const_pt_mean 0.7038999696413594\n",
      "const_1_pt 1.2164665083717592\n",
      "const_2_pt 0.6278398830619529\n",
      "const_3_pt 0.42449509307137784\n",
      "const_4_pt 1.115957410478511\n",
      "jet_y 0.02243732888056064\n",
      "jet_rho 0.44725680063538015\n",
      "lr_intercept 49.997940298386574\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 12 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 174610 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "50.0035052174808\n",
      "[ 3.26374139  3.3255163  -2.72494578  0.31924246  0.5557539   1.06997225\n",
      "  2.54918008  1.30978067  0.91643371  2.41316287 -0.00399068  0.27192511]\n",
      "[ 3.26374139e+00  3.32551630e+00 -2.72494578e+00  3.19242458e-01\n",
      "  5.55753899e-01  1.06997225e+00  2.54918008e+00  1.30978067e+00\n",
      "  9.16433710e-01  2.41316287e+00 -3.99067518e-03  2.71925108e-01\n",
      "  5.00035052e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 3.2637413931669705\n",
      "jet_pt_corr 3.325516304647788\n",
      "jet_mass -2.7249457828550807\n",
      "jet_area 0.3192424578373902\n",
      "jet_const_n 0.5557538989344218\n",
      "const_pt_mean 1.0699722514970298\n",
      "const_1_pt 2.5491800807842986\n",
      "const_2_pt 1.3097806654515858\n",
      "const_3_pt 0.916433709852373\n",
      "const_4_pt 2.4131628724864744\n",
      "jet_y -0.00399067518315591\n",
      "jet_rho 0.27192510817955284\n",
      "lr_intercept 50.0035052174808\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 12 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 262176 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "49.984597313975904\n",
      "[ 4.95917679e+00  5.97250955e+00 -2.73967596e+00  5.12091407e-01\n",
      " -5.18856857e-01  1.21578727e+00  3.20811675e+00  1.68385290e+00\n",
      "  1.20726087e+00  3.12479016e+00 -1.07853885e-04  5.76647899e-01]\n",
      "[ 4.95917679e+00  5.97250955e+00 -2.73967596e+00  5.12091407e-01\n",
      " -5.18856857e-01  1.21578727e+00  3.20811675e+00  1.68385290e+00\n",
      "  1.20726087e+00  3.12479016e+00 -1.07853885e-04  5.76647899e-01\n",
      "  4.99845973e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 4.9591767934695365\n",
      "jet_pt_corr 5.972509547132207\n",
      "jet_mass -2.739675955567881\n",
      "jet_area 0.5120914069983339\n",
      "jet_const_n -0.5188568570087623\n",
      "const_pt_mean 1.2157872715331781\n",
      "const_1_pt 3.2081167481424986\n",
      "const_2_pt 1.6838529044998243\n",
      "const_3_pt 1.2072608711115935\n",
      "const_4_pt 3.12479015584257\n",
      "jet_y -0.00010785388519790076\n",
      "jet_rho 0.5766478985353678\n",
      "lr_intercept 49.984597313975904\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 12 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 349150 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "50.0133871664626\n",
      "[ 9.19984500e+00  6.61579804e+00 -2.36282788e+00  1.28546307e-01\n",
      " -1.73229715e+00  1.19412788e+00  3.55996349e+00  1.92766977e+00\n",
      "  1.34029624e+00  3.55033776e+00 -7.34990248e-03  2.42369699e-01]\n",
      "[ 9.19984500e+00  6.61579804e+00 -2.36282788e+00  1.28546307e-01\n",
      " -1.73229715e+00  1.19412788e+00  3.55996349e+00  1.92766977e+00\n",
      "  1.34029624e+00  3.55033776e+00 -7.34990248e-03  2.42369699e-01\n",
      "  5.00133872e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 9.199845003814568\n",
      "jet_pt_corr 6.61579804121687\n",
      "jet_mass -2.3628278758082937\n",
      "jet_area 0.1285463070039313\n",
      "jet_const_n -1.7322971508305662\n",
      "const_pt_mean 1.194127879339815\n",
      "const_1_pt 3.559963494491547\n",
      "const_2_pt 1.9276697671405636\n",
      "const_3_pt 1.3402962399879037\n",
      "const_4_pt 3.5503377643838974\n",
      "jet_y -0.0073499024802209795\n",
      "jet_rho 0.2423696991934208\n",
      "lr_intercept 50.0133871664626\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 12 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "Directory already exists: ../../Files/Test/Train_B8_Flat/\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 349150 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 346083 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "50.0133871664626\n",
      "[ 1.62876823e+01 -2.35433972e+00 -1.42788007e+00 -1.80123376e+00\n",
      "  1.13338105e+00  3.56066190e+00  1.92798136e+00  1.34072475e+00\n",
      "  3.55253105e+00 -7.42360636e-03 -1.35025377e+00]\n",
      "[ 1.62876823e+01 -2.35433972e+00 -1.42788007e+00 -1.80123376e+00\n",
      "  1.13338105e+00  3.56066190e+00  1.92798136e+00  1.34072475e+00\n",
      "  3.55253105e+00 -7.42360636e-03 -1.35025377e+00  5.00133872e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 16.287682339749146\n",
      "jet_mass -2.354339718717529\n",
      "jet_area -1.427880074513518\n",
      "jet_const_n -1.8012337634362274\n",
      "const_pt_mean 1.1333810472882895\n",
      "const_1_pt 3.5606618969243273\n",
      "const_2_pt 1.9279813618291142\n",
      "const_3_pt 1.3407247511493483\n",
      "const_4_pt 3.5525310485114034\n",
      "jet_y -0.007423606364382693\n",
      "jet_rho -1.350253773488054\n",
      "lr_intercept 50.0133871664626\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training random forest regression estimator...\n",
      "\n",
      "----- Fitting Random Forest Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Random Tree Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor())])\n",
      "Feature Importance:\n",
      "jet_pt_raw 0.7385103659458802\n",
      "jet_mass 0.009208606653017362\n",
      "jet_area 0.0052326553146819195\n",
      "jet_const_n 0.002985323180822941\n",
      "const_pt_mean 0.15249482714453866\n",
      "const_1_pt 0.014974554086067373\n",
      "const_2_pt 0.024428149876042398\n",
      "const_3_pt 0.014903640656823766\n",
      "const_4_pt 0.015126556544529234\n",
      "jet_y 0.01454920521193102\n",
      "jet_rho 0.007586115385665087\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training multilayer perceptron (neural net) regression estimator...\n",
      "\n",
      "----- Fitting Neural Network Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multilayer Perceptron Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpregressor', MLPRegressor(max_iter=100))])\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "made directory\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 87252 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "49.997940298386574\n",
      "[ 2.62969207 -1.39064765 -0.38669086  0.61819412  0.64546025  1.21601726\n",
      "  0.62749355  0.42494801  1.11521288  0.02226766 -0.48662591]\n",
      "[ 2.62969207e+00 -1.39064765e+00 -3.86690864e-01  6.18194121e-01\n",
      "  6.45460249e-01  1.21601726e+00  6.27493552e-01  4.24948015e-01\n",
      "  1.11521288e+00  2.22676648e-02 -4.86625910e-01  4.99979403e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 2.6296920703058526\n",
      "jet_mass -1.3906476490729145\n",
      "jet_area -0.38669086367375216\n",
      "jet_const_n 0.6181941206627192\n",
      "const_pt_mean 0.6454602488418149\n",
      "const_1_pt 1.2160172577751223\n",
      "const_2_pt 0.6274935520134585\n",
      "const_3_pt 0.42494801468831517\n",
      "const_4_pt 1.1152128840403563\n",
      "jet_y 0.022267664836905704\n",
      "jet_rho -0.4866259096845861\n",
      "lr_intercept 49.997940298386574\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 11 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 174610 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "50.0035052174808\n",
      "[ 7.00226082e+00 -2.72122796e+00 -8.23099334e-01  4.52542532e-01\n",
      "  9.86990510e-01  2.55009320e+00  1.31005149e+00  9.17099057e-01\n",
      "  2.41306917e+00 -3.92235829e-03 -1.00509036e+00]\n",
      "[ 7.00226082e+00 -2.72122796e+00 -8.23099334e-01  4.52542532e-01\n",
      "  9.86990510e-01  2.55009320e+00  1.31005149e+00  9.17099057e-01\n",
      "  2.41306917e+00 -3.92235829e-03 -1.00509036e+00  5.00035052e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 7.002260821850746\n",
      "jet_mass -2.7212279588654766\n",
      "jet_area -0.8230993339941948\n",
      "jet_const_n 0.4525425324475923\n",
      "const_pt_mean 0.9869905100596634\n",
      "const_1_pt 2.550093201393549\n",
      "const_2_pt 1.3100514907219523\n",
      "const_3_pt 0.9170990570439282\n",
      "const_4_pt 2.413069166108084\n",
      "jet_y -0.0039223582859447235\n",
      "jet_rho -1.0050903570887477\n",
      "lr_intercept 50.0035052174808\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 11 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 262176 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "49.984597313975904\n",
      "[ 1.14308728e+01 -2.73494129e+00 -1.10699214e+00 -6.24187881e-01\n",
      "  1.11900412e+00  3.20974540e+00  1.68441933e+00  1.20845381e+00\n",
      "  3.12602528e+00 -3.92765983e-05 -1.21609742e+00]\n",
      "[ 1.14308728e+01 -2.73494129e+00 -1.10699214e+00 -6.24187881e-01\n",
      "  1.11900412e+00  3.20974540e+00  1.68441933e+00  1.20845381e+00\n",
      "  3.12602528e+00 -3.92765983e-05 -1.21609742e+00  4.99845973e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 11.430872765241531\n",
      "jet_mass -2.734941285133633\n",
      "jet_area -1.1069921395523707\n",
      "jet_const_n -0.6241878808485234\n",
      "const_pt_mean 1.1190041170626517\n",
      "const_1_pt 3.209745398547523\n",
      "const_2_pt 1.6844193287756977\n",
      "const_3_pt 1.2084538093715111\n",
      "const_4_pt 3.1260252821345005\n",
      "jet_y -3.927659825469392e-05\n",
      "jet_rho -1.2160974217800415\n",
      "lr_intercept 49.984597313975904\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 11 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 349150 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "50.0133871664626\n",
      "[ 1.62876823e+01 -2.35433972e+00 -1.42788007e+00 -1.80123376e+00\n",
      "  1.13338105e+00  3.56066190e+00  1.92798136e+00  1.34072475e+00\n",
      "  3.55253105e+00 -7.42360636e-03 -1.35025377e+00]\n",
      "[ 1.62876823e+01 -2.35433972e+00 -1.42788007e+00 -1.80123376e+00\n",
      "  1.13338105e+00  3.56066190e+00  1.92798136e+00  1.34072475e+00\n",
      "  3.55253105e+00 -7.42360636e-03 -1.35025377e+00  5.00133872e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 16.287682339749146\n",
      "jet_mass -2.354339718717529\n",
      "jet_area -1.427880074513518\n",
      "jet_const_n -1.8012337634362274\n",
      "const_pt_mean 1.1333810472882895\n",
      "const_1_pt 3.5606618969243273\n",
      "const_2_pt 1.9279813618291142\n",
      "const_3_pt 1.3407247511493483\n",
      "const_4_pt 3.5525310485114034\n",
      "jet_y -0.007423606364382693\n",
      "jet_rho -1.350253773488054\n",
      "lr_intercept 50.0133871664626\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 11 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "Preparing to collect data from csv backup file...\n",
      "Jet: 10000 | pTraw: 95.149 | pTcorr:  22.304 | pTtrue:  41.646\n",
      "Jet: 20000 | pTraw: 86.747 | pTcorr:  28.942 | pTtrue:  15.469\n",
      "Jet: 30000 | pTraw: 128.124 | pTcorr:  60.392 | pTtrue:  57.089\n",
      "Jet: 40000 | pTraw: 93.523 | pTcorr:  33.070 | pTtrue:  28.235\n",
      "Jet: 50000 | pTraw: 134.002 | pTcorr:  87.521 | pTtrue:  84.685\n",
      "Jet: 60000 | pTraw: 129.783 | pTcorr:  63.585 | pTtrue:  58.441\n",
      "Jet: 70000 | pTraw: 79.470 | pTcorr:  13.674 | pTtrue:  11.374\n",
      "Jet: 80000 | pTraw: 68.896 | pTcorr:  25.631 | pTtrue:  23.872\n",
      "Jet: 90000 | pTraw: 78.807 | pTcorr:  27.536 | pTtrue:  22.811\n",
      "Jet: 100000 | pTraw: 133.453 | pTcorr:  89.215 | pTtrue:  86.021\n",
      "Jet: 110000 | pTraw: 58.580 | pTcorr:  15.766 | pTtrue:  12.802\n",
      "Jet: 120000 | pTraw: 54.089 | pTcorr:  7.176 | pTtrue:  12.348\n",
      "Jet: 130000 | pTraw: 53.492 | pTcorr:  0.000 | pTtrue:  13.826\n",
      "Jet: 140000 | pTraw: 70.569 | pTcorr:  12.581 | pTtrue:  18.386\n",
      "Jet: 150000 | pTraw: 71.714 | pTcorr:  17.625 | pTtrue:  12.133\n",
      "Jet: 160000 | pTraw: 98.062 | pTcorr:  40.260 | pTtrue:  18.098\n",
      "Jet: 170000 | pTraw: 74.511 | pTcorr:  26.149 | pTtrue:  13.983\n",
      "Jet: 180000 | pTraw: 62.702 | pTcorr:  4.254 | pTtrue:  27.093\n",
      "Jet: 190000 | pTraw: 129.322 | pTcorr:  49.770 | pTtrue:  46.483\n",
      "Jet: 200000 | pTraw: 77.001 | pTcorr:  20.824 | pTtrue:  35.740\n",
      "Jet: 210000 | pTraw: 86.200 | pTcorr:  21.498 | pTtrue:  27.374\n",
      "Jet: 220000 | pTraw: 65.134 | pTcorr:  10.756 | pTtrue:  10.680\n",
      "Jet: 230000 | pTraw: 54.039 | pTcorr:  9.732 | pTtrue:  10.871\n",
      "Jet: 240000 | pTraw: 61.247 | pTcorr:  15.893 | pTtrue:  11.605\n",
      "Jet: 250000 | pTraw: 77.655 | pTcorr:  18.365 | pTtrue:  12.782\n",
      "Jet: 260000 | pTraw: 67.721 | pTcorr:  30.929 | pTtrue:  37.279\n",
      "Jet: 270000 | pTraw: 129.969 | pTcorr:  74.390 | pTtrue:  75.986\n",
      "Jet: 280000 | pTraw: 68.570 | pTcorr:  16.008 | pTtrue:  24.095\n",
      "Jet: 290000 | pTraw: 63.085 | pTcorr:  5.715 | pTtrue:  21.065\n",
      "Jet: 300000 | pTraw: 57.935 | pTcorr:  2.219 | pTtrue:  14.621\n",
      "Jet: 310000 | pTraw: 93.514 | pTcorr:  27.073 | pTtrue:  35.587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jet: 320000 | pTraw: 99.787 | pTcorr:  41.591 | pTtrue:  39.929\n",
      "Jet: 330000 | pTraw: 71.682 | pTcorr:  14.959 | pTtrue:  14.693\n",
      "Jet: 340000 | pTraw: 100.084 | pTcorr:  39.902 | pTtrue:  48.623\n",
      "Jet: 350000 | pTraw: 72.465 | pTcorr:  13.904 | pTtrue:  26.976\n",
      "Jet: 360000 | pTraw: 131.157 | pTcorr:  83.618 | pTtrue:  62.055\n",
      "Jet: 370000 | pTraw: 104.449 | pTcorr:  49.863 | pTtrue:  56.937\n",
      "Jet: 380000 | pTraw: 84.693 | pTcorr:  38.324 | pTtrue:  29.811\n",
      "Jet: 390000 | pTraw: 98.544 | pTcorr:  47.749 | pTtrue:  33.386\n",
      "Jet: 400000 | pTraw: 10.760 | pTcorr:  3.191 | pTtrue:  16.660\n",
      "Jet: 410000 | pTraw: 83.914 | pTcorr:  23.916 | pTtrue:  28.244\n",
      "Jet: 420000 | pTraw: 49.416 | pTcorr:  5.587 | pTtrue:  23.649\n",
      "Jet: 430000 | pTraw: 93.354 | pTcorr:  39.321 | pTtrue:  29.593\n",
      "Jet: 440000 | pTraw: 88.619 | pTcorr:  35.148 | pTtrue:  31.754\n",
      "Jet: 450000 | pTraw: 94.736 | pTcorr:  39.934 | pTtrue:  27.414\n",
      "Jet: 460000 | pTraw: 42.444 | pTcorr: -0.234 | pTtrue:  11.945\n",
      "Jet: 470000 | pTraw: 84.913 | pTcorr:  28.783 | pTtrue:  30.689\n",
      "Jet: 480000 | pTraw: 78.653 | pTcorr:  24.017 | pTtrue:  12.825\n",
      "Jet: 490000 | pTraw: 73.182 | pTcorr:  23.618 | pTtrue:  26.924\n",
      "Jet: 500000 | pTraw: 77.191 | pTcorr:  29.412 | pTtrue:  27.908\n",
      "Jet: 510000 | pTraw: 83.870 | pTcorr:  11.721 | pTtrue:  16.262\n",
      "Jet: 520000 | pTraw: 89.825 | pTcorr:  37.466 | pTtrue:  46.588\n",
      "Jet: 530000 | pTraw: 86.338 | pTcorr:  35.579 | pTtrue:  33.728\n",
      "Jet: 540000 | pTraw: 59.579 | pTcorr:  11.763 | pTtrue:  12.556\n",
      "Jet: 550000 | pTraw: 91.028 | pTcorr:  35.437 | pTtrue:  28.557\n",
      "Jet: 560000 | pTraw: 77.376 | pTcorr:  17.037 | pTtrue:  18.211\n",
      "Jet: 570000 | pTraw: 81.408 | pTcorr:  27.676 | pTtrue:  30.619\n",
      "Jet: 580000 | pTraw: 91.928 | pTcorr:  26.854 | pTtrue:  30.542\n",
      "Jet: 590000 | pTraw: 89.941 | pTcorr:  36.308 | pTtrue:  28.508\n",
      "Jet: 600000 | pTraw: 91.411 | pTcorr:  40.300 | pTtrue:  31.230\n",
      "Jet: 610000 | pTraw: 91.397 | pTcorr:  32.081 | pTtrue:  33.874\n",
      "Jet: 620000 | pTraw: 134.951 | pTcorr:  82.907 | pTtrue:  78.053\n",
      "Jet: 630000 | pTraw: 91.909 | pTcorr:  27.509 | pTtrue:  24.665\n",
      "Jet: 640000 | pTraw: 54.089 | pTcorr:  12.043 | pTtrue:  15.811\n",
      "Jet: 650000 | pTraw: 101.361 | pTcorr:  43.325 | pTtrue:  36.617\n",
      "Jet: 660000 | pTraw: 102.780 | pTcorr:  41.695 | pTtrue:  47.945\n",
      "Backup .csv file closed.\n",
      "All data transferred to array. Testing with 662222 jets.\n",
      "\n",
      "Data set lengths: 662222 / 662222 / 662222\n",
      "Made: ../../Files/Test/Train_B8/\n",
      "Preparing to collect data from csv backup file...\n",
      "Jet: 10000 | pTraw: 107.742 | pTcorr:  50.822 | pTtrue:  45.286\n",
      "Jet: 20000 | pTraw: 122.660 | pTcorr:  72.529 | pTtrue:  67.071\n",
      "Jet: 30000 | pTraw: 96.010 | pTcorr:  50.174 | pTtrue:  55.664\n",
      "Jet: 40000 | pTraw: 91.125 | pTcorr:  44.373 | pTtrue:  46.685\n",
      "Jet: 50000 | pTraw: 86.715 | pTcorr:  18.833 | pTtrue:  41.730\n",
      "Jet: 60000 | pTraw: 144.433 | pTcorr:  88.443 | pTtrue:  83.773\n",
      "Jet: 70000 | pTraw: 108.127 | pTcorr:  46.880 | pTtrue:  39.898\n",
      "Jet: 80000 | pTraw: 121.729 | pTcorr:  48.660 | pTtrue:  48.081\n",
      "Jet: 90000 | pTraw: 74.983 | pTcorr:  5.626 | pTtrue:  19.261\n",
      "Jet: 100000 | pTraw: 82.241 | pTcorr:  26.027 | pTtrue:  25.855\n",
      "Jet: 110000 | pTraw: 90.286 | pTcorr:  41.616 | pTtrue:  39.725\n",
      "Jet: 120000 | pTraw: 86.430 | pTcorr:  26.711 | pTtrue:  20.453\n",
      "Jet: 130000 | pTraw: 101.810 | pTcorr:  51.686 | pTtrue:  53.662\n",
      "Jet: 140000 | pTraw: 77.618 | pTcorr:  18.793 | pTtrue:  11.427\n",
      "Jet: 150000 | pTraw: 103.331 | pTcorr:  60.636 | pTtrue:  64.947\n",
      "Jet: 160000 | pTraw: 78.679 | pTcorr:  10.813 | pTtrue:  22.533\n",
      "Jet: 170000 | pTraw: 161.976 | pTcorr:  97.371 | pTtrue:  83.485\n",
      "Jet: 180000 | pTraw: 136.107 | pTcorr:  83.283 | pTtrue:  80.122\n",
      "Jet: 190000 | pTraw: 133.738 | pTcorr:  78.417 | pTtrue:  88.906\n",
      "Jet: 200000 | pTraw: 132.209 | pTcorr:  71.976 | pTtrue:  48.525\n",
      "Jet: 210000 | pTraw: 139.977 | pTcorr:  92.165 | pTtrue:  88.935\n",
      "Jet: 220000 | pTraw: 93.447 | pTcorr:  27.021 | pTtrue:  37.411\n",
      "Jet: 230000 | pTraw: 84.283 | pTcorr:  16.625 | pTtrue:  20.892\n",
      "Jet: 240000 | pTraw: 83.793 | pTcorr:  28.231 | pTtrue:  31.189\n",
      "Jet: 250000 | pTraw: 117.749 | pTcorr:  71.726 | pTtrue:  77.783\n",
      "Jet: 260000 | pTraw: 120.946 | pTcorr:  63.078 | pTtrue:  70.887\n",
      "Jet: 270000 | pTraw: 94.825 | pTcorr:  33.920 | pTtrue:  35.052\n",
      "Jet: 280000 | pTraw: 117.375 | pTcorr:  54.033 | pTtrue:  35.625\n",
      "Jet: 290000 | pTraw: 148.642 | pTcorr:  93.947 | pTtrue:  82.160\n",
      "Jet: 300000 | pTraw: 90.225 | pTcorr:  39.652 | pTtrue:  42.481\n",
      "Jet: 310000 | pTraw: 85.886 | pTcorr:  31.571 | pTtrue:  25.779\n",
      "Jet: 320000 | pTraw: 101.264 | pTcorr:  54.473 | pTtrue:  65.375\n",
      "Jet: 330000 | pTraw: 67.308 | pTcorr:  12.063 | pTtrue:  16.893\n",
      "Jet: 340000 | pTraw: 124.594 | pTcorr:  76.424 | pTtrue:  72.481\n",
      "Backup .csv file closed.\n",
      "All data transferred to array. Testing with 346083 jets.\n",
      "\n",
      "Data set lengths: 346083 / 346083 / 346083\n",
      "Directory already exists: ../../Files/Test/Train_B8/\n",
      "Directory already exists: ../../Files/Test/Train_B8/\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 662222 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 346083 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "36.869440942751126\n",
      "[20.54827641]\n",
      "[20.54827641 36.86944094]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 20.54827640546238\n",
      "lr_intercept 36.869440942751126\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training random forest regression estimator...\n",
      "\n",
      "----- Fitting Random Forest Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Random Tree Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor())])\n",
      "Feature Importance:\n",
      "jet_pt_raw 1.0\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training multilayer perceptron (neural net) regression estimator...\n",
      "\n",
      "----- Fitting Neural Network Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Multilayer Perceptron Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpregressor', MLPRegressor(max_iter=100))])\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "made directory\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 110078 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "49.530866297969624\n",
      "[2.34476268]\n",
      "[ 2.34476268 49.5308663 ]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 2.3447626807123987\n",
      "lr_intercept 49.530866297969624\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 1 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 233460 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "47.85385541882397\n",
      "[7.8384117]\n",
      "[ 7.8384117  47.85385542]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 7.838411701545253\n",
      "lr_intercept 47.85385541882397\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 1 features on 40_60 GeV...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 392700 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "44.23144448997472\n",
      "[14.33669254]\n",
      "[14.33669254 44.23144449]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 14.336692540084277\n",
      "lr_intercept 44.23144448997472\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 1 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 662222 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "36.869440942751126\n",
      "[20.54827641]\n",
      "[20.54827641 36.86944094]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 20.54827640546238\n",
      "lr_intercept 36.869440942751126\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 1 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "Directory already exists: ../../Files/Test/Train_B8/\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 662222 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 346083 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "36.86944094275113\n",
      "[23.27636144 -5.40911603 -4.40073538]\n",
      "[23.27636144 -5.40911603 -4.40073538 36.86944094]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 23.276361441028136\n",
      "jet_area -5.409116028922582\n",
      "jet_rho -4.4007353754849605\n",
      "lr_intercept 36.86944094275113\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training random forest regression estimator...\n",
      "\n",
      "----- Fitting Random Forest Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Random Tree Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor())])\n",
      "Feature Importance:\n",
      "jet_pt_raw 0.8863483219054875\n",
      "jet_area 0.02944342091096152\n",
      "jet_rho 0.08420825718355103\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training multilayer perceptron (neural net) regression estimator...\n",
      "\n",
      "----- Fitting Neural Network Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Multilayer Perceptron Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpregressor', MLPRegressor(max_iter=100))])\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "made directory\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 110078 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "49.530866297969624\n",
      "[ 3.0967889  -0.94010652 -1.14198482]\n",
      "[ 3.0967889  -0.94010652 -1.14198482 49.5308663 ]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 3.0967888982303142\n",
      "jet_area -0.9401065155648471\n",
      "jet_rho -1.1419848187460289\n",
      "lr_intercept 49.530866297969624\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 3 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 233460 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "47.85385541882397\n",
      "[ 9.41224198 -2.38967393 -2.8804257 ]\n",
      "[ 9.41224198 -2.38967393 -2.8804257  47.85385542]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 9.412241984511395\n",
      "jet_area -2.3896739267255342\n",
      "jet_rho -2.8804257023294153\n",
      "lr_intercept 47.85385541882397\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 3 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 392700 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "44.23144448997472\n",
      "[16.19122738 -3.46200646 -3.9301989 ]\n",
      "[16.19122738 -3.46200646 -3.9301989  44.23144449]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 16.191227382303673\n",
      "jet_area -3.4620064560618307\n",
      "jet_rho -3.930198895633465\n",
      "lr_intercept 44.23144448997472\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 3 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 662222 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "36.86944094275113\n",
      "[23.27636144 -5.40911603 -4.40073538]\n",
      "[23.27636144 -5.40911603 -4.40073538 36.86944094]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 23.276361441028136\n",
      "jet_area -5.409116028922582\n",
      "jet_rho -4.4007353754849605\n",
      "lr_intercept 36.86944094275113\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 3 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "Directory already exists: ../../Files/Test/Train_B8/\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 662222 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 346083 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "36.86944094275113\n",
      "[ 9.10334852e+00  5.83132988e+00 -1.51661798e+00 -1.86574300e-01\n",
      " -2.90752262e+00 -1.48134135e-02  4.34610274e+00  2.45156449e+00\n",
      "  1.65786553e+00  4.07113536e+00 -3.75904899e-03  1.90809153e-01]\n",
      "[ 9.10334852e+00  5.83132988e+00 -1.51661798e+00 -1.86574300e-01\n",
      " -2.90752262e+00 -1.48134135e-02  4.34610274e+00  2.45156449e+00\n",
      "  1.65786553e+00  4.07113536e+00 -3.75904899e-03  1.90809153e-01\n",
      "  3.68694409e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 9.103348520043447\n",
      "jet_pt_corr 5.83132987966874\n",
      "jet_mass -1.5166179780272753\n",
      "jet_area -0.18657429950772542\n",
      "jet_const_n -2.907522621469357\n",
      "const_pt_mean -0.014813413498743022\n",
      "const_1_pt 4.346102740889183\n",
      "const_2_pt 2.451564494653771\n",
      "const_3_pt 1.6578655320549298\n",
      "const_4_pt 4.071135355280868\n",
      "jet_y -0.0037590489865347\n",
      "jet_rho 0.19080915326730838\n",
      "lr_intercept 36.86944094275113\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training random forest regression estimator...\n",
      "\n",
      "----- Fitting Random Forest Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Tree Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor())])\n",
      "Feature Importance:\n",
      "jet_pt_raw 0.013610127625299716\n",
      "jet_pt_corr 0.8468343382590209\n",
      "jet_mass 0.006603486650936075\n",
      "jet_area 0.00344853512434212\n",
      "jet_const_n 0.002452494672047505\n",
      "const_pt_mean 0.0393520348956616\n",
      "const_1_pt 0.018084354761896064\n",
      "const_2_pt 0.02744873541532526\n",
      "const_3_pt 0.01218534212418874\n",
      "const_4_pt 0.01544369260643458\n",
      "jet_y 0.009802338209176725\n",
      "jet_rho 0.004734519655670848\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training multilayer perceptron (neural net) regression estimator...\n",
      "\n",
      "----- Fitting Neural Network Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multilayer Perceptron Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpregressor', MLPRegressor(max_iter=100))])\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "made directory\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 110078 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "49.530866297969624\n",
      "[ 0.6436735   1.69113654 -1.46033964  0.36315247  0.70720284  0.67318118\n",
      "  1.23113807  0.62824889  0.39390857  1.14376213  0.00897486  0.34533448]\n",
      "[ 6.43673504e-01  1.69113654e+00 -1.46033964e+00  3.63152471e-01\n",
      "  7.07202838e-01  6.73181177e-01  1.23113807e+00  6.28248890e-01\n",
      "  3.93908574e-01  1.14376213e+00  8.97486326e-03  3.45334482e-01\n",
      "  4.95308663e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 0.643673504108271\n",
      "jet_pt_corr 1.691136539454575\n",
      "jet_mass -1.4603396388218954\n",
      "jet_area 0.3631524713437222\n",
      "jet_const_n 0.7072028377921092\n",
      "const_pt_mean 0.6731811765358711\n",
      "const_1_pt 1.2311380675351995\n",
      "const_2_pt 0.6282488898637423\n",
      "const_3_pt 0.3939085736092549\n",
      "const_4_pt 1.1437621329104626\n",
      "jet_y 0.008974863264258726\n",
      "jet_rho 0.3453344815283822\n",
      "lr_intercept 49.530866297969624\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 12 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 233460 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "47.85385541882397\n",
      "[ 3.32368353  3.2994384  -2.79308388  0.30717306  0.50703024  0.94339929\n",
      "  2.6711417   1.37992014  0.96734284  2.5052477   0.00459357  0.25536155]\n",
      "[ 3.32368353e+00  3.29943840e+00 -2.79308388e+00  3.07173065e-01\n",
      "  5.07030239e-01  9.43399295e-01  2.67114170e+00  1.37992014e+00\n",
      "  9.67342840e-01  2.50524770e+00  4.59356504e-03  2.55361548e-01\n",
      "  4.78538554e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 3.3236835315935354\n",
      "jet_pt_corr 3.299438399565775\n",
      "jet_mass -2.7930838807592506\n",
      "jet_area 0.3071730647390714\n",
      "jet_const_n 0.5070302388708815\n",
      "const_pt_mean 0.9433992947583996\n",
      "const_1_pt 2.6711417008921514\n",
      "const_2_pt 1.3799201447892484\n",
      "const_3_pt 0.967342840430258\n",
      "const_4_pt 2.505247701894525\n",
      "jet_y 0.004593565036419723\n",
      "jet_rho 0.25536154762566143\n",
      "lr_intercept 47.85385541882397\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 12 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 392700 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "44.23144448997472\n",
      "[ 5.62261999e+00  5.33689497e+00 -2.63130949e+00  3.33333642e-01\n",
      " -9.78463873e-01  6.26126208e-01  3.53280827e+00  1.90197177e+00\n",
      "  1.36436275e+00  3.35979549e+00  3.32317845e-03  4.25403927e-01]\n",
      "[ 5.62261999e+00  5.33689497e+00 -2.63130949e+00  3.33333642e-01\n",
      " -9.78463873e-01  6.26126208e-01  3.53280827e+00  1.90197177e+00\n",
      "  1.36436275e+00  3.35979549e+00  3.32317845e-03  4.25403927e-01\n",
      "  4.42314445e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 5.622619992996499\n",
      "jet_pt_corr 5.3368949700125405\n",
      "jet_mass -2.6313094851805876\n",
      "jet_area 0.33333364173806307\n",
      "jet_const_n -0.9784638726694187\n",
      "const_pt_mean 0.6261262077449661\n",
      "const_1_pt 3.53280827092598\n",
      "const_2_pt 1.9019717680619028\n",
      "const_3_pt 1.3643627469075958\n",
      "const_4_pt 3.3597954919954005\n",
      "jet_y 0.0033231784485432715\n",
      "jet_rho 0.425403926928535\n",
      "lr_intercept 44.23144448997472\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 12 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 662222 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "36.86944094275113\n",
      "[ 9.10334852e+00  5.83132988e+00 -1.51661798e+00 -1.86574300e-01\n",
      " -2.90752262e+00 -1.48134135e-02  4.34610274e+00  2.45156449e+00\n",
      "  1.65786553e+00  4.07113536e+00 -3.75904899e-03  1.90809153e-01]\n",
      "[ 9.10334852e+00  5.83132988e+00 -1.51661798e+00 -1.86574300e-01\n",
      " -2.90752262e+00 -1.48134135e-02  4.34610274e+00  2.45156449e+00\n",
      "  1.65786553e+00  4.07113536e+00 -3.75904899e-03  1.90809153e-01\n",
      "  3.68694409e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 9.103348520043447\n",
      "jet_pt_corr 5.83132987966874\n",
      "jet_mass -1.5166179780272753\n",
      "jet_area -0.18657429950772542\n",
      "jet_const_n -2.907522621469357\n",
      "const_pt_mean -0.014813413498743022\n",
      "const_1_pt 4.346102740889183\n",
      "const_2_pt 2.451564494653771\n",
      "const_3_pt 1.6578655320549298\n",
      "const_4_pt 4.071135355280868\n",
      "jet_y -0.0037590489865347\n",
      "jet_rho 0.19080915326730838\n",
      "lr_intercept 36.86944094275113\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 12 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "Directory already exists: ../../Files/Test/Train_B8/\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 662222 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 346083 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "36.86944094275113\n",
      "[ 1.54467135e+01 -1.49613903e+00 -1.79660527e+00 -2.96258209e+00\n",
      " -4.48093513e-02  4.34716330e+00  2.45222061e+00  1.65838535e+00\n",
      "  4.07510976e+00 -3.81930404e-03 -1.18226120e+00]\n",
      "[ 1.54467135e+01 -1.49613903e+00 -1.79660527e+00 -2.96258209e+00\n",
      " -4.48093513e-02  4.34716330e+00  2.45222061e+00  1.65838535e+00\n",
      "  4.07510976e+00 -3.81930404e-03 -1.18226120e+00  3.68694409e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 15.446713535131074\n",
      "jet_mass -1.4961390258343663\n",
      "jet_area -1.7966052745752674\n",
      "jet_const_n -2.962582085605289\n",
      "const_pt_mean -0.04480935133205744\n",
      "const_1_pt 4.347163302033124\n",
      "const_2_pt 2.452220613051643\n",
      "const_3_pt 1.6583853509646405\n",
      "const_4_pt 4.075109755424085\n",
      "jet_y -0.0038193040399262666\n",
      "jet_rho -1.1822612021815584\n",
      "lr_intercept 36.86944094275113\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training random forest regression estimator...\n",
      "\n",
      "----- Fitting Random Forest Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Random Tree Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor())])\n",
      "Feature Importance:\n",
      "jet_pt_raw 0.7184129703994213\n",
      "jet_mass 0.007453798461363226\n",
      "jet_area 0.0043834385011227\n",
      "jet_const_n 0.0025250495435922104\n",
      "const_pt_mean 0.10517099501993186\n",
      "const_1_pt 0.023311778268996806\n",
      "const_2_pt 0.08643827114971282\n",
      "const_3_pt 0.018360630448656202\n",
      "const_4_pt 0.016234951332491917\n",
      "jet_y 0.011379606102670642\n",
      "jet_rho 0.006328510772040234\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training multilayer perceptron (neural net) regression estimator...\n",
      "\n",
      "----- Fitting Neural Network Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multilayer Perceptron Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpregressor', MLPRegressor(max_iter=100))])\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "made directory\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 110078 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "49.530866297969624\n",
      "[ 2.65189026 -1.45680145 -0.38233984  0.62764772  0.61853543  1.23077411\n",
      "  0.62797468  0.39399214  1.14319138  0.00890502 -0.48541555]\n",
      "[ 2.65189026e+00 -1.45680145e+00 -3.82339839e-01  6.27647719e-01\n",
      "  6.18535429e-01  1.23077411e+00  6.27974675e-01  3.93992137e-01\n",
      "  1.14319138e+00  8.90501601e-03 -4.85415548e-01  4.95308663e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 2.6518902610404993\n",
      "jet_mass -1.4568014549578254\n",
      "jet_area -0.3823398393194909\n",
      "jet_const_n 0.6276477190725993\n",
      "const_pt_mean 0.6185354288197442\n",
      "const_1_pt 1.2307741131424783\n",
      "const_2_pt 0.6279746754771576\n",
      "const_3_pt 0.3939921369027712\n",
      "const_4_pt 1.1431913804811502\n",
      "jet_y 0.00890501601088561\n",
      "jet_rho -0.4854155484781324\n",
      "lr_intercept 49.530866297969624\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 11 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 233460 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "47.85385541882397\n",
      "[ 7.02977707e+00 -2.78940184e+00 -8.31027997e-01  4.10873321e-01\n",
      "  8.65613473e-01  2.67222150e+00  1.38016430e+00  9.67606900e-01\n",
      "  2.50560911e+00  4.66009547e-03 -1.00668326e+00]\n",
      "[ 7.02977707e+00 -2.78940184e+00 -8.31027997e-01  4.10873321e-01\n",
      "  8.65613473e-01  2.67222150e+00  1.38016430e+00  9.67606900e-01\n",
      "  2.50560911e+00  4.66009547e-03 -1.00668326e+00  4.78538554e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 7.029777069186251\n",
      "jet_mass -2.789401838502414\n",
      "jet_area -0.831027996545726\n",
      "jet_const_n 0.410873321457096\n",
      "const_pt_mean 0.8656134733619917\n",
      "const_1_pt 2.6722215033124113\n",
      "const_2_pt 1.3801642958121196\n",
      "const_3_pt 0.9676069002412013\n",
      "const_4_pt 2.505609114711209\n",
      "jet_y 0.004660095467104001\n",
      "jet_rho -1.0066832583186325\n",
      "lr_intercept 47.85385541882397\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 11 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 392700 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "44.23144448997472\n",
      "[ 1.14024358e+01 -2.62601075e+00 -1.14134182e+00 -1.06143717e+00\n",
      "  5.50274304e-01  3.53443941e+00  1.90268664e+00  1.36497055e+00\n",
      "  3.36160934e+00  3.31106737e-03 -1.16001570e+00]\n",
      "[ 1.14024358e+01 -2.62601075e+00 -1.14134182e+00 -1.06143717e+00\n",
      "  5.50274304e-01  3.53443941e+00  1.90268664e+00  1.36497055e+00\n",
      "  3.36160934e+00  3.31106737e-03 -1.16001570e+00  4.42314445e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 11.402435835629882\n",
      "jet_mass -2.6260107532793175\n",
      "jet_area -1.141341818735891\n",
      "jet_const_n -1.0614371670725982\n",
      "const_pt_mean 0.5502743038252339\n",
      "const_1_pt 3.534439413626753\n",
      "const_2_pt 1.9026866434120977\n",
      "const_3_pt 1.3649705495993596\n",
      "const_4_pt 3.3616093442356276\n",
      "jet_y 0.0033110673710143373\n",
      "jet_rho -1.1600156967098645\n",
      "lr_intercept 44.23144448997472\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 11 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 662222 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "36.86944094275113\n",
      "[ 1.54467135e+01 -1.49613903e+00 -1.79660527e+00 -2.96258209e+00\n",
      " -4.48093513e-02  4.34716330e+00  2.45222061e+00  1.65838535e+00\n",
      "  4.07510976e+00 -3.81930404e-03 -1.18226120e+00]\n",
      "[ 1.54467135e+01 -1.49613903e+00 -1.79660527e+00 -2.96258209e+00\n",
      " -4.48093513e-02  4.34716330e+00  2.45222061e+00  1.65838535e+00\n",
      "  4.07510976e+00 -3.81930404e-03 -1.18226120e+00  3.68694409e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 15.446713535131074\n",
      "jet_mass -1.4961390258343663\n",
      "jet_area -1.7966052745752674\n",
      "jet_const_n -2.962582085605289\n",
      "const_pt_mean -0.04480935133205744\n",
      "const_1_pt 4.347163302033124\n",
      "const_2_pt 2.452220613051643\n",
      "const_3_pt 1.6583853509646405\n",
      "const_4_pt 4.075109755424085\n",
      "jet_y -0.0038193040399262666\n",
      "jet_rho -1.1822612021815584\n",
      "lr_intercept 36.86944094275113\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 11 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "Preparing to collect data from csv backup file...\n",
      "Jet: 10000 | pTraw: 43.547 | pTcorr:  5.432 | pTtrue:  14.729\n",
      "Jet: 20000 | pTraw: 82.627 | pTcorr:  12.726 | pTtrue:  15.588\n",
      "Jet: 30000 | pTraw: 76.739 | pTcorr:  14.064 | pTtrue:  14.165\n",
      "Jet: 40000 | pTraw: 59.168 | pTcorr:  6.541 | pTtrue:  12.355\n",
      "Jet: 50000 | pTraw: 54.278 | pTcorr:  12.428 | pTtrue:  18.832\n",
      "Jet: 60000 | pTraw: 67.572 | pTcorr: -4.960 | pTtrue:  12.560\n",
      "Jet: 70000 | pTraw: 132.175 | pTcorr:  78.733 | pTtrue:  81.798\n",
      "Jet: 80000 | pTraw: 70.122 | pTcorr:  9.749 | pTtrue:  16.238\n",
      "Jet: 90000 | pTraw: 64.244 | pTcorr:  17.094 | pTtrue:  15.462\n",
      "Jet: 100000 | pTraw: 73.307 | pTcorr:  17.883 | pTtrue:  10.912\n",
      "Jet: 110000 | pTraw: 66.748 | pTcorr:  8.992 | pTtrue:  15.471\n",
      "Jet: 120000 | pTraw: 67.486 | pTcorr:  14.432 | pTtrue:  10.273\n",
      "Jet: 130000 | pTraw: 74.749 | pTcorr:  28.616 | pTtrue:  14.863\n",
      "Jet: 140000 | pTraw: 56.962 | pTcorr:  17.479 | pTtrue:  21.327\n",
      "Jet: 150000 | pTraw: 73.798 | pTcorr:  18.813 | pTtrue:  11.260\n",
      "Jet: 160000 | pTraw: 94.344 | pTcorr:  37.047 | pTtrue:  40.006\n",
      "Jet: 170000 | pTraw: 84.183 | pTcorr:  6.478 | pTtrue:  11.404\n",
      "Jet: 180000 | pTraw: 89.917 | pTcorr:  31.487 | pTtrue:  28.775\n",
      "Jet: 190000 | pTraw: 110.521 | pTcorr:  56.273 | pTtrue:  55.501\n",
      "Jet: 200000 | pTraw: 131.259 | pTcorr:  80.748 | pTtrue:  58.019\n",
      "Jet: 210000 | pTraw: 66.483 | pTcorr:  20.187 | pTtrue:  15.298\n",
      "Jet: 220000 | pTraw: 73.187 | pTcorr:  19.253 | pTtrue:  21.710\n",
      "Jet: 230000 | pTraw: 104.390 | pTcorr:  64.581 | pTtrue:  63.423\n",
      "Jet: 240000 | pTraw: 66.176 | pTcorr:  1.826 | pTtrue:  12.048\n",
      "Jet: 250000 | pTraw: 97.108 | pTcorr:  24.676 | pTtrue:  30.091\n",
      "Jet: 260000 | pTraw: 82.545 | pTcorr:  33.145 | pTtrue:  17.847\n",
      "Jet: 270000 | pTraw: 59.999 | pTcorr:  7.190 | pTtrue:  16.806\n",
      "Jet: 280000 | pTraw: 54.919 | pTcorr:  8.448 | pTtrue:  15.172\n",
      "Jet: 290000 | pTraw: 138.373 | pTcorr:  74.857 | pTtrue:  77.186\n",
      "Jet: 300000 | pTraw: 66.926 | pTcorr:  26.006 | pTtrue:  18.630\n",
      "Jet: 310000 | pTraw: 74.193 | pTcorr:  10.665 | pTtrue:  11.014\n",
      "Jet: 320000 | pTraw: 96.691 | pTcorr:  43.631 | pTtrue:  37.068\n",
      "Jet: 330000 | pTraw: 60.759 | pTcorr:  4.547 | pTtrue:  10.031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jet: 340000 | pTraw: 90.546 | pTcorr:  29.082 | pTtrue:  22.914\n",
      "Jet: 350000 | pTraw: 49.950 | pTcorr:  5.784 | pTtrue:  16.411\n",
      "Jet: 360000 | pTraw: 122.188 | pTcorr:  66.395 | pTtrue:  72.610\n",
      "Jet: 370000 | pTraw: 58.720 | pTcorr:  10.820 | pTtrue:  11.590\n",
      "Jet: 380000 | pTraw: 88.082 | pTcorr:  26.026 | pTtrue:  21.689\n",
      "Jet: 390000 | pTraw: 73.409 | pTcorr:  32.013 | pTtrue:  16.243\n",
      "Jet: 400000 | pTraw: 84.979 | pTcorr:  30.218 | pTtrue:  24.153\n",
      "Jet: 410000 | pTraw: 55.423 | pTcorr:  4.442 | pTtrue:  12.450\n",
      "Jet: 420000 | pTraw: 72.110 | pTcorr:  21.566 | pTtrue:  10.494\n",
      "Jet: 430000 | pTraw: 87.773 | pTcorr:  30.601 | pTtrue:  27.341\n",
      "Jet: 440000 | pTraw: 129.844 | pTcorr:  71.192 | pTtrue:  76.652\n",
      "Jet: 450000 | pTraw: 93.670 | pTcorr:  35.533 | pTtrue:  23.622\n",
      "Jet: 460000 | pTraw: 54.216 | pTcorr:  0.096 | pTtrue:  12.090\n",
      "Jet: 470000 | pTraw: 98.066 | pTcorr:  44.776 | pTtrue:  42.222\n",
      "Jet: 480000 | pTraw: 113.780 | pTcorr:  76.748 | pTtrue:  78.121\n",
      "Jet: 490000 | pTraw: 85.929 | pTcorr:  21.153 | pTtrue:  12.987\n",
      "Jet: 500000 | pTraw: 66.959 | pTcorr:  16.304 | pTtrue:  18.809\n",
      "Jet: 510000 | pTraw: 96.010 | pTcorr:  32.183 | pTtrue:  19.055\n",
      "Jet: 520000 | pTraw: 94.175 | pTcorr:  32.019 | pTtrue:  33.514\n",
      "Jet: 530000 | pTraw: 71.251 | pTcorr:  18.367 | pTtrue:  13.622\n",
      "Jet: 540000 | pTraw: 55.059 | pTcorr:  3.575 | pTtrue:  12.442\n",
      "Jet: 550000 | pTraw: 58.310 | pTcorr:  5.031 | pTtrue:  21.485\n",
      "Jet: 560000 | pTraw: 101.636 | pTcorr:  48.295 | pTtrue:  26.777\n",
      "Jet: 570000 | pTraw: 87.788 | pTcorr:  37.209 | pTtrue:  25.651\n",
      "Jet: 580000 | pTraw: 102.073 | pTcorr:  36.744 | pTtrue:  39.509\n",
      "Jet: 590000 | pTraw: 56.483 | pTcorr:  18.885 | pTtrue:  11.374\n",
      "Jet: 600000 | pTraw: 72.014 | pTcorr:  20.510 | pTtrue:  15.974\n",
      "Backup .csv file closed.\n",
      "All data transferred to array. Testing with 600838 jets.\n",
      "\n",
      "Data set lengths: 600838 / 600838 / 600838\n",
      "Made: ../../Files/Test/Train_B4/\n",
      "Preparing to collect data from csv backup file...\n",
      "Jet: 10000 | pTraw: 107.742 | pTcorr:  50.822 | pTtrue:  45.286\n",
      "Jet: 20000 | pTraw: 122.660 | pTcorr:  72.529 | pTtrue:  67.071\n",
      "Jet: 30000 | pTraw: 96.010 | pTcorr:  50.174 | pTtrue:  55.664\n",
      "Jet: 40000 | pTraw: 91.125 | pTcorr:  44.373 | pTtrue:  46.685\n",
      "Jet: 50000 | pTraw: 86.715 | pTcorr:  18.833 | pTtrue:  41.730\n",
      "Jet: 60000 | pTraw: 144.433 | pTcorr:  88.443 | pTtrue:  83.773\n",
      "Jet: 70000 | pTraw: 108.127 | pTcorr:  46.880 | pTtrue:  39.898\n",
      "Jet: 80000 | pTraw: 121.729 | pTcorr:  48.660 | pTtrue:  48.081\n",
      "Jet: 90000 | pTraw: 74.983 | pTcorr:  5.626 | pTtrue:  19.261\n",
      "Jet: 100000 | pTraw: 82.241 | pTcorr:  26.027 | pTtrue:  25.855\n",
      "Jet: 110000 | pTraw: 90.286 | pTcorr:  41.616 | pTtrue:  39.725\n",
      "Jet: 120000 | pTraw: 86.430 | pTcorr:  26.711 | pTtrue:  20.453\n",
      "Jet: 130000 | pTraw: 101.810 | pTcorr:  51.686 | pTtrue:  53.662\n",
      "Jet: 140000 | pTraw: 77.618 | pTcorr:  18.793 | pTtrue:  11.427\n",
      "Jet: 150000 | pTraw: 103.331 | pTcorr:  60.636 | pTtrue:  64.947\n",
      "Jet: 160000 | pTraw: 78.679 | pTcorr:  10.813 | pTtrue:  22.533\n",
      "Jet: 170000 | pTraw: 161.976 | pTcorr:  97.371 | pTtrue:  83.485\n",
      "Jet: 180000 | pTraw: 136.107 | pTcorr:  83.283 | pTtrue:  80.122\n",
      "Jet: 190000 | pTraw: 133.738 | pTcorr:  78.417 | pTtrue:  88.906\n",
      "Jet: 200000 | pTraw: 132.209 | pTcorr:  71.976 | pTtrue:  48.525\n",
      "Jet: 210000 | pTraw: 139.977 | pTcorr:  92.165 | pTtrue:  88.935\n",
      "Jet: 220000 | pTraw: 93.447 | pTcorr:  27.021 | pTtrue:  37.411\n",
      "Jet: 230000 | pTraw: 84.283 | pTcorr:  16.625 | pTtrue:  20.892\n",
      "Jet: 240000 | pTraw: 83.793 | pTcorr:  28.231 | pTtrue:  31.189\n",
      "Jet: 250000 | pTraw: 117.749 | pTcorr:  71.726 | pTtrue:  77.783\n",
      "Jet: 260000 | pTraw: 120.946 | pTcorr:  63.078 | pTtrue:  70.887\n",
      "Jet: 270000 | pTraw: 94.825 | pTcorr:  33.920 | pTtrue:  35.052\n",
      "Jet: 280000 | pTraw: 117.375 | pTcorr:  54.033 | pTtrue:  35.625\n",
      "Jet: 290000 | pTraw: 148.642 | pTcorr:  93.947 | pTtrue:  82.160\n",
      "Jet: 300000 | pTraw: 90.225 | pTcorr:  39.652 | pTtrue:  42.481\n",
      "Jet: 310000 | pTraw: 85.886 | pTcorr:  31.571 | pTtrue:  25.779\n",
      "Jet: 320000 | pTraw: 101.264 | pTcorr:  54.473 | pTtrue:  65.375\n",
      "Jet: 330000 | pTraw: 67.308 | pTcorr:  12.063 | pTtrue:  16.893\n",
      "Jet: 340000 | pTraw: 124.594 | pTcorr:  76.424 | pTtrue:  72.481\n",
      "Backup .csv file closed.\n",
      "All data transferred to array. Testing with 346083 jets.\n",
      "\n",
      "Data set lengths: 346083 / 346083 / 346083\n",
      "Directory already exists: ../../Files/Test/Train_B4/\n",
      "Directory already exists: ../../Files/Test/Train_B4/\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 600838 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 346083 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "29.83765509000171\n",
      "[16.26520069]\n",
      "[16.26520069 29.83765509]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 16.265200691104486\n",
      "lr_intercept 29.83765509000171\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training random forest regression estimator...\n",
      "\n",
      "----- Fitting Random Forest Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Random Tree Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor())])\n",
      "Feature Importance:\n",
      "jet_pt_raw 1.0\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training multilayer perceptron (neural net) regression estimator...\n",
      "\n",
      "----- Fitting Neural Network Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Multilayer Perceptron Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpregressor', MLPRegressor(max_iter=100))])\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "made directory\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 85767 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "48.839646971985886\n",
      "[2.60984106]\n",
      "[ 2.60984106 48.83964697]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 2.6098410640933873\n",
      "lr_intercept 48.839646971985886\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 1 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 187185 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "45.27142191262098\n",
      "[7.8319755]\n",
      "[ 7.8319755  45.27142191]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 7.831975502447447\n",
      "lr_intercept 45.27142191262098\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 1 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 332618 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "39.18440181502299\n",
      "[12.88237979]\n",
      "[12.88237979 39.18440182]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 12.882379786807666\n",
      "lr_intercept 39.18440181502299\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 1 features on 40_60 GeV...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 600838 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "29.83765509000171\n",
      "[16.26520069]\n",
      "[16.26520069 29.83765509]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 16.265200691104486\n",
      "lr_intercept 29.83765509000171\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 1 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "Directory already exists: ../../Files/Test/Train_B4/\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 600838 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 346083 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "29.837655090001725\n",
      "[18.60603919 -4.27283538 -4.37625674]\n",
      "[18.60603919 -4.27283538 -4.37625674 29.83765509]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 18.606039190142617\n",
      "jet_area -4.272835382042292\n",
      "jet_rho -4.376256736435501\n",
      "lr_intercept 29.837655090001725\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training random forest regression estimator...\n",
      "\n",
      "----- Fitting Random Forest Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Random Tree Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor())])\n",
      "Feature Importance:\n",
      "jet_pt_raw 0.8627086140207707\n",
      "jet_area 0.02640924644015792\n",
      "jet_rho 0.11088213953907133\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training multilayer perceptron (neural net) regression estimator...\n",
      "\n",
      "----- Fitting Neural Network Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Multilayer Perceptron Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('mlpregressor', MLPRegressor(max_iter=100))])\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "made directory\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 85767 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "48.839646971985886\n",
      "[ 3.36305612 -0.4172165  -1.53950045]\n",
      "[ 3.36305612 -0.4172165  -1.53950045 48.83964697]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 3.363056119684406\n",
      "jet_area -0.41721650388585996\n",
      "jet_rho -1.5395004548918148\n",
      "lr_intercept 48.839646971985886\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 3 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 187185 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "45.27142191262098\n",
      "[ 9.11982812 -1.02535477 -3.25811824]\n",
      "[ 9.11982812 -1.02535477 -3.25811824 45.27142191]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 9.119828123119616\n",
      "jet_area -1.0253547659562896\n",
      "jet_rho -3.258118236076772\n",
      "lr_intercept 45.27142191262098\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 3 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 332618 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "39.18440181502299\n",
      "[14.27460447 -1.80569756 -4.10966663]\n",
      "[14.27460447 -1.80569756 -4.10966663 39.18440182]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 14.274604472977904\n",
      "jet_area -1.8056975564366118\n",
      "jet_rho -4.109666631339037\n",
      "lr_intercept 39.18440181502299\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 3 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 600838 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 86514 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "29.837655090001725\n",
      "[18.60603919 -4.27283538 -4.37625674]\n",
      "[18.60603919 -4.27283538 -4.37625674 29.83765509]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 18.606039190142617\n",
      "jet_area -4.272835382042292\n",
      "jet_rho -4.376256736435501\n",
      "lr_intercept 29.837655090001725\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Testing 3 features on 40_60 GeV...\n",
      "ML results .csv file closed.\n",
      "Test and save complete!\n",
      "\n",
      "Directory already exists: ../../Files/Test/Train_B4/\n",
      "\n",
      "Building training and testing selected feature arrays...\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 600838 \n",
      "\n",
      "Selecting data from master array...\n",
      "Data ready. Feature array length: 346083 \n",
      "\n",
      "\n",
      "Training linear regression estimator...\n",
      "\n",
      "----- Fitting Linear Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n",
      "\n",
      "Linear Regression Fit:\n",
      " Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('linearregression', LinearRegression())])\n",
      "29.837655090001707\n",
      "[ 7.57693831e+00  2.79877410e+00  1.65575434e+00 -7.26799082e-01\n",
      " -4.98687506e+00 -9.26125430e-01  4.06296205e+00  2.32587498e+00\n",
      "  1.68191862e+00  3.81413484e+00  8.94216414e-05 -2.63056771e-02]\n",
      "[ 7.57693831e+00  2.79877410e+00  1.65575434e+00 -7.26799082e-01\n",
      " -4.98687506e+00 -9.26125430e-01  4.06296205e+00  2.32587498e+00\n",
      "  1.68191862e+00  3.81413484e+00  8.94216414e-05 -2.63056771e-02\n",
      "  2.98376551e+01]\n",
      "Regression Coefficients:\n",
      "jet_pt_raw 7.576938312628683\n",
      "jet_pt_corr 2.7987741017737333\n",
      "jet_mass 1.6557543350115487\n",
      "jet_area -0.7267990815772334\n",
      "jet_const_n -4.98687506227767\n",
      "const_pt_mean -0.9261254300801546\n",
      "const_1_pt 4.062962050903362\n",
      "const_2_pt 2.3258749844017808\n",
      "const_3_pt 1.6819186153129215\n",
      "const_4_pt 3.814134837229693\n",
      "jet_y 8.9421641443479e-05\n",
      "jet_rho -0.026305677117852016\n",
      "lr_intercept 29.837655090001707\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "Writing coefficients to CSV...\n",
      "Coefficient CSV file complete.\n",
      "\n",
      "Training random forest regression estimator...\n",
      "\n",
      "----- Fitting Random Forest Regression Estimator -----\n",
      "\n",
      "\n",
      "Using StandardScaler. Data will be recentered and normalized.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m feature_bundle \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     (feature_label_1feat,  feature_index_1feat), \n\u001b[1;32m      3\u001b[0m     (feature_label_3feat,  feature_index_3feat),\n\u001b[1;32m      4\u001b[0m     (feature_label_12feat, feature_index_12feat),\n\u001b[1;32m      5\u001b[0m     (feature_label_11feat, feature_index_11feat)\n\u001b[1;32m      6\u001b[0m ]\n\u001b[0;32m----> 8\u001b[0m \u001b[43mFull_TrainTest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_file_bundle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# train_file_bundle\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_file_bundle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# test_file_bundle\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_bundle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# feature_bundle\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_bin_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# test_bin_array\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraintest_bin_array\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m# traintest_bin_array\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# output_directory\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m10.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# train_pt_min\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m90.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# train_pt_max\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_lr\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# use_lr\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_rf\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# use_rf\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_mlp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# use_mlp\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Research/CU Heavy Ions Group/Machine Learning/CU-Heavy-Ions-Jet-Reco-ML/Code/Macros_2022-02-03/../Scripts_Python/ML_Python_TrainTest.py:554\u001b[0m, in \u001b[0;36mFull_TrainTest\u001b[0;34m(train_file_bundle, test_file_bundle, feature_bundle, test_bin_array, traintest_bin_array, output_directory, train_pt_min, train_pt_max, use_lr, use_rf, use_mlp)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_rf:\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining random forest regression estimator...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 554\u001b[0m     rf_pipeline, rf_coeffs \u001b[38;5;241m=\u001b[39m \u001b[43mTrain_RandomForestRegression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train_select\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_scaler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(rf_pipeline))\n\u001b[1;32m    560\u001b[0m     Write_MLCoefficients_ToCSV(\n\u001b[1;32m    561\u001b[0m         output_feature_directory \u001b[38;5;241m+\u001b[39m output_csv_base \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_RF_Coeffs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    562\u001b[0m         rf_coeffs,\n\u001b[1;32m    563\u001b[0m         feature_label\n\u001b[1;32m    564\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/Research/CU Heavy Ions Group/Machine Learning/CU-Heavy-Ions-Jet-Reco-ML/Code/Macros_2022-02-03/../Scripts_Python/ML_Python_TrainTest.py:238\u001b[0m, in \u001b[0;36mTrain_RandomForestRegression\u001b[0;34m(X_train, y_train, features_labels, use_scaler)\u001b[0m\n\u001b[1;32m    233\u001b[0m rf_pipeline \u001b[38;5;241m=\u001b[39m make_pipeline(\n\u001b[1;32m    234\u001b[0m     scaler,\n\u001b[1;32m    235\u001b[0m     rf_estimator )\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Fits the regression model\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mrf_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRandom Tree Regression Fit:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, output)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# Outputs feature importances\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/tree/_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \n\u001b[1;32m   1316\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1342\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_bundle = [\n",
    "    (feature_label_1feat,  feature_index_1feat), \n",
    "    (feature_label_3feat,  feature_index_3feat),\n",
    "    (feature_label_12feat, feature_index_12feat),\n",
    "    (feature_label_11feat, feature_index_11feat)\n",
    "]\n",
    "\n",
    "Full_TrainTest(\n",
    "    train_file_bundle,  # train_file_bundle\n",
    "    test_file_bundle,   # test_file_bundle\n",
    "    feature_bundle,     # feature_bundle\n",
    "    test_bin_array,     # test_bin_array\n",
    "    traintest_bin_array,# traintest_bin_array\n",
    "    output_directory,   # output_directory\n",
    "    10.,       # train_pt_min\n",
    "    90.,       # train_pt_max\n",
    "    use_lr  = True,     # use_lr\n",
    "    use_rf  = True,     # use_rf\n",
    "    use_mlp = True      # use_mlp\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fff5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
